{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08077ea9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-16T07:20:21.405090Z",
     "iopub.status.busy": "2022-06-16T07:20:21.404289Z",
     "iopub.status.idle": "2022-06-16T07:20:21.419897Z",
     "shell.execute_reply": "2022-06-16T07:20:21.419072Z"
    },
    "papermill": {
     "duration": 0.033592,
     "end_time": "2022-06-16T07:20:21.422669",
     "exception": false,
     "start_time": "2022-06-16T07:20:21.389077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#os.remove('/kaggle/working/datasets/cityscapes.pth')\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#       print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4957cef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:20:21.458137Z",
     "iopub.status.busy": "2022-06-16T07:20:21.457819Z",
     "iopub.status.idle": "2022-06-16T07:20:23.614255Z",
     "shell.execute_reply": "2022-06-16T07:20:23.613461Z"
    },
    "papermill": {
     "duration": 2.17596,
     "end_time": "2022-06-16T07:20:23.616921",
     "exception": false,
     "start_time": "2022-06-16T07:20:21.440961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as functional\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce0010cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:20:23.651975Z",
     "iopub.status.busy": "2022-06-16T07:20:23.651618Z",
     "iopub.status.idle": "2022-06-16T07:20:24.046256Z",
     "shell.execute_reply": "2022-06-16T07:20:24.045511Z"
    },
    "papermill": {
     "duration": 0.414786,
     "end_time": "2022-06-16T07:20:24.048500",
     "exception": false,
     "start_time": "2022-06-16T07:20:23.633714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = glob('/kaggle/input/cityscapes-image-pairs/cityscapes_data/train/*')\n",
    "valid_path = glob('/kaggle/input/cityscapes-image-pairs/cityscapes_data/val/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46bd7a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:20:24.069265Z",
     "iopub.status.busy": "2022-06-16T07:20:24.069037Z",
     "iopub.status.idle": "2022-06-16T07:20:24.076801Z",
     "shell.execute_reply": "2022-06-16T07:20:24.076059Z"
    },
    "papermill": {
     "duration": 0.020116,
     "end_time": "2022-06-16T07:20:24.078604",
     "exception": false,
     "start_time": "2022-06-16T07:20:24.058488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Cityscapes(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None):\n",
    "        super(Cityscapes, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        #self.datasets = np.array(data)\n",
    "        #self.images, self.targets = np.array_split(self.datasets, 2, axis=2)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image_pair = plt.imread(self.data_path[item])\n",
    "        image, target = image_pair[:, :int(image_pair.shape[1] / 2)], image_pair[:, int(image_pair.shape[1] / 2):]\n",
    "        #image = self.images[item]\n",
    "        #target = self.targets[item]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f386d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:20:24.099513Z",
     "iopub.status.busy": "2022-06-16T07:20:24.098872Z",
     "iopub.status.idle": "2022-06-16T07:20:24.123295Z",
     "shell.execute_reply": "2022-06-16T07:20:24.122441Z"
    },
    "papermill": {
     "duration": 0.037292,
     "end_time": "2022-06-16T07:20:24.125372",
     "exception": false,
     "start_time": "2022-06-16T07:20:24.088080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, image_channel=3, mid_channel=64):\n",
    "        super(UNet, self).__init__()\n",
    "        self.two_conv_block = nn.Sequential(\n",
    "            nn.Conv2d(image_channel, mid_channel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channel, mid_channel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.down_sample_1 = DownSampleConvBlock(mid_channel, mid_channel * 2, mid_channel * 2)\n",
    "        self.down_sample_2 = DownSampleConvBlock(mid_channel * 2, mid_channel * 4, mid_channel * 4)\n",
    "        self.down_sample_3 = DownSampleConvBlock(mid_channel * 4, mid_channel * 8, mid_channel * 8)\n",
    "        self.down_sample_4 = DownSampleConvBlock(mid_channel * 8, mid_channel * 16, mid_channel * 16)\n",
    "        self.up_sample_1 = UpSampleConvBlock(mid_channel * 16, mid_channel * 8, mid_channel * 8)\n",
    "        self.up_sample_2 = UpSampleConvBlock(mid_channel * 8, mid_channel * 4, mid_channel * 4)\n",
    "        self.up_sample_3 = UpSampleConvBlock(mid_channel * 4, mid_channel * 2, mid_channel * 2)\n",
    "        self.up_sample_4 = UpSampleConvBlock(mid_channel * 2, mid_channel, mid_channel)\n",
    "        # 降维\n",
    "        self.conv1x1 = nn.Conv2d(mid_channel, image_channel, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(image_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.two_conv_block(x)\n",
    "        x2 = self.down_sample_1(x1)\n",
    "        x3 = self.down_sample_2(x2)\n",
    "        x4 = self.down_sample_3(x3)\n",
    "        x5 = self.down_sample_4(x4)\n",
    "        x_u1 = self.up_sample_1(x5, x4)\n",
    "        x_u2 = self.up_sample_2(x_u1, x3)\n",
    "        x_u3 = self.up_sample_3(x_u2, x2)\n",
    "        x_u4 = self.up_sample_4(x_u3, x1)\n",
    "        return self.bn(self.conv1x1(x_u4))\n",
    "\n",
    "\n",
    "class BasicConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1):\n",
    "        super(BasicConvBlock, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # the first conv block\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size, stride, padding, dilation),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # the second conv block\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size, stride, padding, dilation),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class DownSampleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, pool_size=2, kernel_size=3, stride=1, padding=1,\n",
    "                 dilation=1):\n",
    "        super(DownSampleConvBlock, self).__init__()\n",
    "        self.down_sample = nn.MaxPool2d(kernel_size=pool_size)\n",
    "        self.basic_conv_block = BasicConvBlock(in_channels, mid_channels, out_channels, kernel_size, stride, padding,\n",
    "                                               dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # down sample\n",
    "        x = self.down_sample(x)\n",
    "        # two conv block\n",
    "        x = self.basic_conv_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSampleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, up_size=2, kernel_size=3, stride=1, padding=1,\n",
    "                 dilation=1):\n",
    "        super(UpSampleConvBlock, self).__init__()\n",
    "        self.up_sample = nn.ConvTranspose2d(in_channels, mid_channels, kernel_size=up_size, stride=up_size,\n",
    "                                            dilation=dilation)\n",
    "        self.basic_conv_block = BasicConvBlock(in_channels, mid_channels, out_channels, kernel_size, stride, padding,\n",
    "                                               dilation)\n",
    "\n",
    "    def forward(self, x, skip_x):\n",
    "        # up sample\n",
    "        x = self.up_sample(x)\n",
    "        # concat x and skip_x in the dimension of channel\n",
    "        x = torch.cat([x, skip_x], dim=1)\n",
    "        # two conv block\n",
    "        x = self.basic_conv_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AdaptiveFeatureFusionModule(nn.Module):\n",
    "    \"\"\"Adaptive Feature Fusion Module(AFFM)\n",
    "\n",
    "    Fusion multiple-scale feature maps, the count of feature maps is not fixed,\n",
    "    the value of counts must equal the size of feature_maps, the number of layers\n",
    "    in AFFM is determined by the parameter of counts.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, counts):\n",
    "        super(AdaptiveFeatureFusionModule, self).__init__()\n",
    "        self.counts = counts\n",
    "        pass\n",
    "\n",
    "    def forward(self, feature_maps: tuple = None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e970e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:20:24.145706Z",
     "iopub.status.busy": "2022-06-16T07:20:24.145267Z",
     "iopub.status.idle": "2022-06-16T07:20:24.157547Z",
     "shell.execute_reply": "2022-06-16T07:20:24.156852Z"
    },
    "papermill": {
     "duration": 0.024522,
     "end_time": "2022-06-16T07:20:24.159287",
     "exception": false,
     "start_time": "2022-06-16T07:20:24.134765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coeff(predict, target, reduce_batch_first=False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    assert predict.size() == target.size()\n",
    "    if predict.dim() == 2 and reduce_batch_first:\n",
    "        raise ValueError(f'Dice: asked to reduce batch but got tensor without batch dimension (shape {predict.shape})')\n",
    "\n",
    "    if predict.dim() == 2 or reduce_batch_first:\n",
    "        inter = torch.dot(predict.reshape(-1), target.reshape(-1))\n",
    "        sets_sum = torch.sum(predict) + torch.sum(target)\n",
    "        if sets_sum.item() == 0:\n",
    "            sets_sum = 2 * inter\n",
    "        return (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "    else:\n",
    "        # compute and average metric for each batch element\n",
    "        dice = 0\n",
    "        for i in range(predict.shape[0]):\n",
    "            dice += dice_coeff(predict[i, ...], target[i, ...])\n",
    "        # return average dice loss value of a batch\n",
    "        return dice / predict.shape[0]\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(predict, target, reduce_batch_first=False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all classes\n",
    "    assert predict.size() == target.size()\n",
    "    dice = 0\n",
    "    for channel in range(predict.shape[1]):\n",
    "        dice += dice_coeff(predict[:, channel, ...], target[:, channel, ...], reduce_batch_first, epsilon)\n",
    "    return dice / predict.shape[1]\n",
    "\n",
    "\n",
    "def dice_loss(predict, target, multiclass=True, epsilon=1e-6):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    assert predict.size() == target.size()\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(predict, target, reduce_batch_first=True, epsilon=epsilon)\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, ep=1e-8):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.ep = ep\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        # the shape of predict must equal to the shape of target\n",
    "        value = dice_loss(predict, target, True, self.ep)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf305550",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:20:24.179635Z",
     "iopub.status.busy": "2022-06-16T07:20:24.179389Z",
     "iopub.status.idle": "2022-06-16T07:20:24.187868Z",
     "shell.execute_reply": "2022-06-16T07:20:24.187039Z"
    },
    "papermill": {
     "duration": 0.020507,
     "end_time": "2022-06-16T07:20:24.189866",
     "exception": false,
     "start_time": "2022-06-16T07:20:24.169359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(network_model, valid_loader, loss, device):\n",
    "    network_model.eval()\n",
    "    v_loss_total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for j, (v_x, v_l) in enumerate(valid_loader):\n",
    "            v_x = v_x.to(device)\n",
    "            v_l = v_l.to(device)\n",
    "            v_predict = network_model(v_x)\n",
    "            loss_value = loss(v_predict, v_l)\n",
    "            v_loss_total += loss_value.item()\n",
    "    val_avg_loss = v_loss_total / len(valid_loader)\n",
    "    return val_avg_loss\n",
    "\n",
    "\n",
    "class SearchBestModel(object):\n",
    "    def __init__(self, min_delta=0, verbose=True):\n",
    "        super(SearchBestModel, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "        elif self.best_score - val_loss >= self.min_delta:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print('performance reducing: counter {}'.format(self.counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2194f74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T07:20:24.209206Z",
     "iopub.status.busy": "2022-06-16T07:20:24.209028Z",
     "iopub.status.idle": "2022-06-16T07:20:24.219297Z",
     "shell.execute_reply": "2022-06-16T07:20:24.218674Z"
    },
    "papermill": {
     "duration": 0.021995,
     "end_time": "2022-06-16T07:20:24.220863",
     "exception": false,
     "start_time": "2022-06-16T07:20:24.198868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, optimizer, loss, epoch, device):\n",
    "    loss_change_list = []\n",
    "    valid_loss_change = []\n",
    "    save_best = {}\n",
    "    save_last = {}\n",
    "    search_best_model = SearchBestModel()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for index, (image, label) in enumerate(train_loader):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device).to(torch.float32)\n",
    "\n",
    "            segment_mask = model(image)\n",
    "            loss_value = loss(segment_mask, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss = total_loss + loss_value.item()\n",
    "\n",
    "            print('epoch {} batch {}/{} loss = {:.4f}'.format(i + 1, index + 1, len(train_loader), loss_value.item()))\n",
    "        # save train loss change history used for model analyse\n",
    "        loss_change_list.append(total_loss / len(train_loader))\n",
    "        # use the dataset for validation to validate the trained model\n",
    "        valid_avg_loss = validate(model, valid_loader, loss, device)\n",
    "        # save valid loss change history used for model analyse\n",
    "        valid_loss_change.append(valid_avg_loss)\n",
    "\n",
    "        print('epoch {} train loss = {:.4f} valid loss = {:.4f}'.format(i + 1, total_loss / len(train_loader), valid_avg_loss))\n",
    "\n",
    "        # see if satisfy the conditions of early stopping\n",
    "        search_best_model(valid_avg_loss)\n",
    "        # if satisfy the conditions of early stopping, break the training process\n",
    "        if search_best_model.counter > 0:\n",
    "            continue\n",
    "        # if not satisfy the conditions of early stopping, it shows that\n",
    "        # the model in this epoch is the best, save the params of current model.\n",
    "        save_best['model_state_dict'] = model.state_dict()\n",
    "        # save optimizer used for re-train\n",
    "        save_best['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        # save the epoch of current best model\n",
    "        save_best['epoch'] = i\n",
    "    # save loss change history of training and validation\n",
    "    save_last['train_loss_change'] = loss_change_list\n",
    "    save_last['valid_loss_change'] = valid_loss_change\n",
    "    save_last['model_state_dict'] = model.state_dict()\n",
    "    save_last['optimizer_state_dict'] = optimizer.state_dict()\n",
    "    save_last['trained_epoch'] = epoch\n",
    "    torch.save(save_best, './unet-best.pth')\n",
    "    torch.save(save_last, './unet-last.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc15a17d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-06-16T07:20:24.240155Z",
     "iopub.status.busy": "2022-06-16T07:20:24.239569Z",
     "iopub.status.idle": "2022-06-16T08:03:59.202907Z",
     "shell.execute_reply": "2022-06-16T08:03:59.202157Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2614.975274,
     "end_time": "2022-06-16T08:03:59.205028",
     "exception": false,
     "start_time": "2022-06-16T07:20:24.229754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch 1/185 loss = 1.1575\n",
      "epoch 1 batch 2/185 loss = 1.0625\n",
      "epoch 1 batch 3/185 loss = 1.0396\n",
      "epoch 1 batch 4/185 loss = 1.0104\n",
      "epoch 1 batch 5/185 loss = 0.9816\n",
      "epoch 1 batch 6/185 loss = 0.9446\n",
      "epoch 1 batch 7/185 loss = 0.9179\n",
      "epoch 1 batch 8/185 loss = 0.9086\n",
      "epoch 1 batch 9/185 loss = 0.9240\n",
      "epoch 1 batch 10/185 loss = 0.9196\n",
      "epoch 1 batch 11/185 loss = 0.9011\n",
      "epoch 1 batch 12/185 loss = 0.9009\n",
      "epoch 1 batch 13/185 loss = 0.8876\n",
      "epoch 1 batch 14/185 loss = 0.8810\n",
      "epoch 1 batch 15/185 loss = 0.8886\n",
      "epoch 1 batch 16/185 loss = 0.8580\n",
      "epoch 1 batch 17/185 loss = 0.8619\n",
      "epoch 1 batch 18/185 loss = 0.8686\n",
      "epoch 1 batch 19/185 loss = 0.8650\n",
      "epoch 1 batch 20/185 loss = 0.8424\n",
      "epoch 1 batch 21/185 loss = 0.8435\n",
      "epoch 1 batch 22/185 loss = 0.8552\n",
      "epoch 1 batch 23/185 loss = 0.8538\n",
      "epoch 1 batch 24/185 loss = 0.8516\n",
      "epoch 1 batch 25/185 loss = 0.8426\n",
      "epoch 1 batch 26/185 loss = 0.8351\n",
      "epoch 1 batch 27/185 loss = 0.8449\n",
      "epoch 1 batch 28/185 loss = 0.8201\n",
      "epoch 1 batch 29/185 loss = 0.8261\n",
      "epoch 1 batch 30/185 loss = 0.8388\n",
      "epoch 1 batch 31/185 loss = 0.8205\n",
      "epoch 1 batch 32/185 loss = 0.8283\n",
      "epoch 1 batch 33/185 loss = 0.8264\n",
      "epoch 1 batch 34/185 loss = 0.7878\n",
      "epoch 1 batch 35/185 loss = 0.7999\n",
      "epoch 1 batch 36/185 loss = 0.8205\n",
      "epoch 1 batch 37/185 loss = 0.8038\n",
      "epoch 1 batch 38/185 loss = 0.8116\n",
      "epoch 1 batch 39/185 loss = 0.7957\n",
      "epoch 1 batch 40/185 loss = 0.7840\n",
      "epoch 1 batch 41/185 loss = 0.8012\n",
      "epoch 1 batch 42/185 loss = 0.7876\n",
      "epoch 1 batch 43/185 loss = 0.7932\n",
      "epoch 1 batch 44/185 loss = 0.7877\n",
      "epoch 1 batch 45/185 loss = 0.7770\n",
      "epoch 1 batch 46/185 loss = 0.7810\n",
      "epoch 1 batch 47/185 loss = 0.7544\n",
      "epoch 1 batch 48/185 loss = 0.7660\n",
      "epoch 1 batch 49/185 loss = 0.7749\n",
      "epoch 1 batch 50/185 loss = 0.7764\n",
      "epoch 1 batch 51/185 loss = 0.7499\n",
      "epoch 1 batch 52/185 loss = 0.7585\n",
      "epoch 1 batch 53/185 loss = 0.7795\n",
      "epoch 1 batch 54/185 loss = 0.7569\n",
      "epoch 1 batch 55/185 loss = 0.7674\n",
      "epoch 1 batch 56/185 loss = 0.7443\n",
      "epoch 1 batch 57/185 loss = 0.7436\n",
      "epoch 1 batch 58/185 loss = 0.7413\n",
      "epoch 1 batch 59/185 loss = 0.7295\n",
      "epoch 1 batch 60/185 loss = 0.7462\n",
      "epoch 1 batch 61/185 loss = 0.7413\n",
      "epoch 1 batch 62/185 loss = 0.7405\n",
      "epoch 1 batch 63/185 loss = 0.7272\n",
      "epoch 1 batch 64/185 loss = 0.7305\n",
      "epoch 1 batch 65/185 loss = 0.7326\n",
      "epoch 1 batch 66/185 loss = 0.7251\n",
      "epoch 1 batch 67/185 loss = 0.7292\n",
      "epoch 1 batch 68/185 loss = 0.7297\n",
      "epoch 1 batch 69/185 loss = 0.7196\n",
      "epoch 1 batch 70/185 loss = 0.7219\n",
      "epoch 1 batch 71/185 loss = 0.7123\n",
      "epoch 1 batch 72/185 loss = 0.7063\n",
      "epoch 1 batch 73/185 loss = 0.7226\n",
      "epoch 1 batch 74/185 loss = 0.7090\n",
      "epoch 1 batch 75/185 loss = 0.7135\n",
      "epoch 1 batch 76/185 loss = 0.7232\n",
      "epoch 1 batch 77/185 loss = 0.7033\n",
      "epoch 1 batch 78/185 loss = 0.6976\n",
      "epoch 1 batch 79/185 loss = 0.7064\n",
      "epoch 1 batch 80/185 loss = 0.7010\n",
      "epoch 1 batch 81/185 loss = 0.6893\n",
      "epoch 1 batch 82/185 loss = 0.6855\n",
      "epoch 1 batch 83/185 loss = 0.6828\n",
      "epoch 1 batch 84/185 loss = 0.6876\n",
      "epoch 1 batch 85/185 loss = 0.6809\n",
      "epoch 1 batch 86/185 loss = 0.6748\n",
      "epoch 1 batch 87/185 loss = 0.6788\n",
      "epoch 1 batch 88/185 loss = 0.6904\n",
      "epoch 1 batch 89/185 loss = 0.6682\n",
      "epoch 1 batch 90/185 loss = 0.6802\n",
      "epoch 1 batch 91/185 loss = 0.6889\n",
      "epoch 1 batch 92/185 loss = 0.6593\n",
      "epoch 1 batch 93/185 loss = 0.6640\n",
      "epoch 1 batch 94/185 loss = 0.6603\n",
      "epoch 1 batch 95/185 loss = 0.6596\n",
      "epoch 1 batch 96/185 loss = 0.6567\n",
      "epoch 1 batch 97/185 loss = 0.6583\n",
      "epoch 1 batch 98/185 loss = 0.6571\n",
      "epoch 1 batch 99/185 loss = 0.6381\n",
      "epoch 1 batch 100/185 loss = 0.6516\n",
      "epoch 1 batch 101/185 loss = 0.6513\n",
      "epoch 1 batch 102/185 loss = 0.6477\n",
      "epoch 1 batch 103/185 loss = 0.6319\n",
      "epoch 1 batch 104/185 loss = 0.6436\n",
      "epoch 1 batch 105/185 loss = 0.6434\n",
      "epoch 1 batch 106/185 loss = 0.6367\n",
      "epoch 1 batch 107/185 loss = 0.6261\n",
      "epoch 1 batch 108/185 loss = 0.6337\n",
      "epoch 1 batch 109/185 loss = 0.6396\n",
      "epoch 1 batch 110/185 loss = 0.6328\n",
      "epoch 1 batch 111/185 loss = 0.6233\n",
      "epoch 1 batch 112/185 loss = 0.6428\n",
      "epoch 1 batch 113/185 loss = 0.6177\n",
      "epoch 1 batch 114/185 loss = 0.6146\n",
      "epoch 1 batch 115/185 loss = 0.6102\n",
      "epoch 1 batch 116/185 loss = 0.6026\n",
      "epoch 1 batch 117/185 loss = 0.6031\n",
      "epoch 1 batch 118/185 loss = 0.6153\n",
      "epoch 1 batch 119/185 loss = 0.6380\n",
      "epoch 1 batch 120/185 loss = 0.6142\n",
      "epoch 1 batch 121/185 loss = 0.6218\n",
      "epoch 1 batch 122/185 loss = 0.5967\n",
      "epoch 1 batch 123/185 loss = 0.6062\n",
      "epoch 1 batch 124/185 loss = 0.5985\n",
      "epoch 1 batch 125/185 loss = 0.5926\n",
      "epoch 1 batch 126/185 loss = 0.5894\n",
      "epoch 1 batch 127/185 loss = 0.6170\n",
      "epoch 1 batch 128/185 loss = 0.6015\n",
      "epoch 1 batch 129/185 loss = 0.5881\n",
      "epoch 1 batch 130/185 loss = 0.5974\n",
      "epoch 1 batch 131/185 loss = 0.5928\n",
      "epoch 1 batch 132/185 loss = 0.5836\n",
      "epoch 1 batch 133/185 loss = 0.5950\n",
      "epoch 1 batch 134/185 loss = 0.5914\n",
      "epoch 1 batch 135/185 loss = 0.5828\n",
      "epoch 1 batch 136/185 loss = 0.5796\n",
      "epoch 1 batch 137/185 loss = 0.5731\n",
      "epoch 1 batch 138/185 loss = 0.5846\n",
      "epoch 1 batch 139/185 loss = 0.5662\n",
      "epoch 1 batch 140/185 loss = 0.5706\n",
      "epoch 1 batch 141/185 loss = 0.5722\n",
      "epoch 1 batch 142/185 loss = 0.5699\n",
      "epoch 1 batch 143/185 loss = 0.5796\n",
      "epoch 1 batch 144/185 loss = 0.5837\n",
      "epoch 1 batch 145/185 loss = 0.6010\n",
      "epoch 1 batch 146/185 loss = 0.5472\n",
      "epoch 1 batch 147/185 loss = 0.5474\n",
      "epoch 1 batch 148/185 loss = 0.5568\n",
      "epoch 1 batch 149/185 loss = 0.5657\n",
      "epoch 1 batch 150/185 loss = 0.5677\n",
      "epoch 1 batch 151/185 loss = 0.5607\n",
      "epoch 1 batch 152/185 loss = 0.5576\n",
      "epoch 1 batch 153/185 loss = 0.5561\n",
      "epoch 1 batch 154/185 loss = 0.5464\n",
      "epoch 1 batch 155/185 loss = 0.5567\n",
      "epoch 1 batch 156/185 loss = 0.5585\n",
      "epoch 1 batch 157/185 loss = 0.5576\n",
      "epoch 1 batch 158/185 loss = 0.5495\n",
      "epoch 1 batch 159/185 loss = 0.5552\n",
      "epoch 1 batch 160/185 loss = 0.5376\n",
      "epoch 1 batch 161/185 loss = 0.5409\n",
      "epoch 1 batch 162/185 loss = 0.5337\n",
      "epoch 1 batch 163/185 loss = 0.5348\n",
      "epoch 1 batch 164/185 loss = 0.5331\n",
      "epoch 1 batch 165/185 loss = 0.5389\n",
      "epoch 1 batch 166/185 loss = 0.5355\n",
      "epoch 1 batch 167/185 loss = 0.5323\n",
      "epoch 1 batch 168/185 loss = 0.5339\n",
      "epoch 1 batch 169/185 loss = 0.5352\n",
      "epoch 1 batch 170/185 loss = 0.5331\n",
      "epoch 1 batch 171/185 loss = 0.5277\n",
      "epoch 1 batch 172/185 loss = 0.5242\n",
      "epoch 1 batch 173/185 loss = 0.5113\n",
      "epoch 1 batch 174/185 loss = 0.5318\n",
      "epoch 1 batch 175/185 loss = 0.5233\n",
      "epoch 1 batch 176/185 loss = 0.5362\n",
      "epoch 1 batch 177/185 loss = 0.5117\n",
      "epoch 1 batch 178/185 loss = 0.5183\n",
      "epoch 1 batch 179/185 loss = 0.5316\n",
      "epoch 1 batch 180/185 loss = 0.5187\n",
      "epoch 1 batch 181/185 loss = 0.5230\n",
      "epoch 1 batch 182/185 loss = 0.5034\n",
      "epoch 1 batch 183/185 loss = 0.4931\n",
      "epoch 1 batch 184/185 loss = 0.5038\n",
      "epoch 1 batch 185/185 loss = 0.4997\n",
      "epoch 1 train loss = 0.6863 valid loss = 0.5909\n",
      "epoch 2 batch 1/185 loss = 0.5052\n",
      "epoch 2 batch 2/185 loss = 0.5113\n",
      "epoch 2 batch 3/185 loss = 0.4900\n",
      "epoch 2 batch 4/185 loss = 0.5127\n",
      "epoch 2 batch 5/185 loss = 0.4899\n",
      "epoch 2 batch 6/185 loss = 0.4968\n",
      "epoch 2 batch 7/185 loss = 0.4785\n",
      "epoch 2 batch 8/185 loss = 0.4795\n",
      "epoch 2 batch 9/185 loss = 0.5007\n",
      "epoch 2 batch 10/185 loss = 0.4933\n",
      "epoch 2 batch 11/185 loss = 0.4674\n",
      "epoch 2 batch 12/185 loss = 0.4932\n",
      "epoch 2 batch 13/185 loss = 0.4778\n",
      "epoch 2 batch 14/185 loss = 0.4903\n",
      "epoch 2 batch 15/185 loss = 0.4849\n",
      "epoch 2 batch 16/185 loss = 0.4841\n",
      "epoch 2 batch 17/185 loss = 0.4807\n",
      "epoch 2 batch 18/185 loss = 0.4659\n",
      "epoch 2 batch 19/185 loss = 0.4757\n",
      "epoch 2 batch 20/185 loss = 0.4813\n",
      "epoch 2 batch 21/185 loss = 0.4691\n",
      "epoch 2 batch 22/185 loss = 0.4794\n",
      "epoch 2 batch 23/185 loss = 0.4672\n",
      "epoch 2 batch 24/185 loss = 0.4520\n",
      "epoch 2 batch 25/185 loss = 0.4619\n",
      "epoch 2 batch 26/185 loss = 0.4597\n",
      "epoch 2 batch 27/185 loss = 0.4544\n",
      "epoch 2 batch 28/185 loss = 0.4668\n",
      "epoch 2 batch 29/185 loss = 0.4453\n",
      "epoch 2 batch 30/185 loss = 0.4509\n",
      "epoch 2 batch 31/185 loss = 0.4626\n",
      "epoch 2 batch 32/185 loss = 0.4519\n",
      "epoch 2 batch 33/185 loss = 0.4455\n",
      "epoch 2 batch 34/185 loss = 0.4385\n",
      "epoch 2 batch 35/185 loss = 0.4437\n",
      "epoch 2 batch 36/185 loss = 0.4402\n",
      "epoch 2 batch 37/185 loss = 0.4420\n",
      "epoch 2 batch 38/185 loss = 0.4255\n",
      "epoch 2 batch 39/185 loss = 0.4215\n",
      "epoch 2 batch 40/185 loss = 0.4326\n",
      "epoch 2 batch 41/185 loss = 0.4365\n",
      "epoch 2 batch 42/185 loss = 0.4314\n",
      "epoch 2 batch 43/185 loss = 0.4415\n",
      "epoch 2 batch 44/185 loss = 0.4417\n",
      "epoch 2 batch 45/185 loss = 0.4426\n",
      "epoch 2 batch 46/185 loss = 0.4213\n",
      "epoch 2 batch 47/185 loss = 0.4400\n",
      "epoch 2 batch 48/185 loss = 0.4248\n",
      "epoch 2 batch 49/185 loss = 0.4292\n",
      "epoch 2 batch 50/185 loss = 0.4353\n",
      "epoch 2 batch 51/185 loss = 0.4165\n",
      "epoch 2 batch 52/185 loss = 0.4276\n",
      "epoch 2 batch 53/185 loss = 0.4297\n",
      "epoch 2 batch 54/185 loss = 0.4088\n",
      "epoch 2 batch 55/185 loss = 0.4069\n",
      "epoch 2 batch 56/185 loss = 0.4205\n",
      "epoch 2 batch 57/185 loss = 0.4133\n",
      "epoch 2 batch 58/185 loss = 0.4165\n",
      "epoch 2 batch 59/185 loss = 0.4074\n",
      "epoch 2 batch 60/185 loss = 0.4050\n",
      "epoch 2 batch 61/185 loss = 0.4079\n",
      "epoch 2 batch 62/185 loss = 0.3949\n",
      "epoch 2 batch 63/185 loss = 0.4103\n",
      "epoch 2 batch 64/185 loss = 0.4054\n",
      "epoch 2 batch 65/185 loss = 0.4042\n",
      "epoch 2 batch 66/185 loss = 0.4093\n",
      "epoch 2 batch 67/185 loss = 0.3892\n",
      "epoch 2 batch 68/185 loss = 0.3968\n",
      "epoch 2 batch 69/185 loss = 0.4157\n",
      "epoch 2 batch 70/185 loss = 0.4127\n",
      "epoch 2 batch 71/185 loss = 0.4030\n",
      "epoch 2 batch 72/185 loss = 0.3936\n",
      "epoch 2 batch 73/185 loss = 0.4047\n",
      "epoch 2 batch 74/185 loss = 0.3881\n",
      "epoch 2 batch 75/185 loss = 0.3974\n",
      "epoch 2 batch 76/185 loss = 0.3994\n",
      "epoch 2 batch 77/185 loss = 0.4038\n",
      "epoch 2 batch 78/185 loss = 0.3985\n",
      "epoch 2 batch 79/185 loss = 0.3889\n",
      "epoch 2 batch 80/185 loss = 0.3819\n",
      "epoch 2 batch 81/185 loss = 0.3781\n",
      "epoch 2 batch 82/185 loss = 0.3793\n",
      "epoch 2 batch 83/185 loss = 0.3919\n",
      "epoch 2 batch 84/185 loss = 0.3788\n",
      "epoch 2 batch 85/185 loss = 0.3767\n",
      "epoch 2 batch 86/185 loss = 0.3763\n",
      "epoch 2 batch 87/185 loss = 0.3833\n",
      "epoch 2 batch 88/185 loss = 0.3814\n",
      "epoch 2 batch 89/185 loss = 0.3820\n",
      "epoch 2 batch 90/185 loss = 0.3806\n",
      "epoch 2 batch 91/185 loss = 0.3652\n",
      "epoch 2 batch 92/185 loss = 0.3746\n",
      "epoch 2 batch 93/185 loss = 0.3683\n",
      "epoch 2 batch 94/185 loss = 0.3595\n",
      "epoch 2 batch 95/185 loss = 0.3687\n",
      "epoch 2 batch 96/185 loss = 0.3791\n",
      "epoch 2 batch 97/185 loss = 0.3605\n",
      "epoch 2 batch 98/185 loss = 0.3586\n",
      "epoch 2 batch 99/185 loss = 0.3575\n",
      "epoch 2 batch 100/185 loss = 0.3618\n",
      "epoch 2 batch 101/185 loss = 0.3675\n",
      "epoch 2 batch 102/185 loss = 0.3620\n",
      "epoch 2 batch 103/185 loss = 0.3597\n",
      "epoch 2 batch 104/185 loss = 0.3545\n",
      "epoch 2 batch 105/185 loss = 0.3735\n",
      "epoch 2 batch 106/185 loss = 0.3607\n",
      "epoch 2 batch 107/185 loss = 0.3585\n",
      "epoch 2 batch 108/185 loss = 0.3582\n",
      "epoch 2 batch 109/185 loss = 0.3499\n",
      "epoch 2 batch 110/185 loss = 0.3427\n",
      "epoch 2 batch 111/185 loss = 0.3407\n",
      "epoch 2 batch 112/185 loss = 0.3483\n",
      "epoch 2 batch 113/185 loss = 0.3443\n",
      "epoch 2 batch 114/185 loss = 0.3423\n",
      "epoch 2 batch 115/185 loss = 0.3552\n",
      "epoch 2 batch 116/185 loss = 0.3390\n",
      "epoch 2 batch 117/185 loss = 0.3358\n",
      "epoch 2 batch 118/185 loss = 0.3464\n",
      "epoch 2 batch 119/185 loss = 0.3516\n",
      "epoch 2 batch 120/185 loss = 0.3510\n",
      "epoch 2 batch 121/185 loss = 0.3381\n",
      "epoch 2 batch 122/185 loss = 0.3382\n",
      "epoch 2 batch 123/185 loss = 0.3374\n",
      "epoch 2 batch 124/185 loss = 0.3543\n",
      "epoch 2 batch 125/185 loss = 0.3330\n",
      "epoch 2 batch 126/185 loss = 0.3278\n",
      "epoch 2 batch 127/185 loss = 0.3369\n",
      "epoch 2 batch 128/185 loss = 0.3348\n",
      "epoch 2 batch 129/185 loss = 0.3281\n",
      "epoch 2 batch 130/185 loss = 0.3391\n",
      "epoch 2 batch 131/185 loss = 0.3171\n",
      "epoch 2 batch 132/185 loss = 0.3260\n",
      "epoch 2 batch 133/185 loss = 0.3385\n",
      "epoch 2 batch 134/185 loss = 0.3212\n",
      "epoch 2 batch 135/185 loss = 0.3378\n",
      "epoch 2 batch 136/185 loss = 0.3221\n",
      "epoch 2 batch 137/185 loss = 0.3303\n",
      "epoch 2 batch 138/185 loss = 0.3322\n",
      "epoch 2 batch 139/185 loss = 0.3265\n",
      "epoch 2 batch 140/185 loss = 0.3277\n",
      "epoch 2 batch 141/185 loss = 0.3160\n",
      "epoch 2 batch 142/185 loss = 0.3285\n",
      "epoch 2 batch 143/185 loss = 0.3203\n",
      "epoch 2 batch 144/185 loss = 0.3328\n",
      "epoch 2 batch 145/185 loss = 0.3146\n",
      "epoch 2 batch 146/185 loss = 0.3133\n",
      "epoch 2 batch 147/185 loss = 0.3148\n",
      "epoch 2 batch 148/185 loss = 0.3281\n",
      "epoch 2 batch 149/185 loss = 0.3116\n",
      "epoch 2 batch 150/185 loss = 0.3149\n",
      "epoch 2 batch 151/185 loss = 0.3219\n",
      "epoch 2 batch 152/185 loss = 0.3147\n",
      "epoch 2 batch 153/185 loss = 0.3010\n",
      "epoch 2 batch 154/185 loss = 0.3226\n",
      "epoch 2 batch 155/185 loss = 0.3172\n",
      "epoch 2 batch 156/185 loss = 0.3070\n",
      "epoch 2 batch 157/185 loss = 0.3193\n",
      "epoch 2 batch 158/185 loss = 0.2950\n",
      "epoch 2 batch 159/185 loss = 0.3144\n",
      "epoch 2 batch 160/185 loss = 0.2992\n",
      "epoch 2 batch 161/185 loss = 0.2995\n",
      "epoch 2 batch 162/185 loss = 0.2921\n",
      "epoch 2 batch 163/185 loss = 0.3093\n",
      "epoch 2 batch 164/185 loss = 0.2993\n",
      "epoch 2 batch 165/185 loss = 0.2914\n",
      "epoch 2 batch 166/185 loss = 0.3033\n",
      "epoch 2 batch 167/185 loss = 0.2994\n",
      "epoch 2 batch 168/185 loss = 0.2957\n",
      "epoch 2 batch 169/185 loss = 0.2841\n",
      "epoch 2 batch 170/185 loss = 0.2945\n",
      "epoch 2 batch 171/185 loss = 0.2923\n",
      "epoch 2 batch 172/185 loss = 0.2896\n",
      "epoch 2 batch 173/185 loss = 0.2869\n",
      "epoch 2 batch 174/185 loss = 0.2915\n",
      "epoch 2 batch 175/185 loss = 0.2981\n",
      "epoch 2 batch 176/185 loss = 0.2814\n",
      "epoch 2 batch 177/185 loss = 0.2939\n",
      "epoch 2 batch 178/185 loss = 0.2926\n",
      "epoch 2 batch 179/185 loss = 0.2865\n",
      "epoch 2 batch 180/185 loss = 0.2825\n",
      "epoch 2 batch 181/185 loss = 0.2828\n",
      "epoch 2 batch 182/185 loss = 0.2697\n",
      "epoch 2 batch 183/185 loss = 0.2752\n",
      "epoch 2 batch 184/185 loss = 0.2730\n",
      "epoch 2 batch 185/185 loss = 0.2818\n",
      "epoch 2 train loss = 0.3783 valid loss = 0.2776\n",
      "epoch 3 batch 1/185 loss = 0.2851\n",
      "epoch 3 batch 2/185 loss = 0.2758\n",
      "epoch 3 batch 3/185 loss = 0.2840\n",
      "epoch 3 batch 4/185 loss = 0.2799\n",
      "epoch 3 batch 5/185 loss = 0.2717\n",
      "epoch 3 batch 6/185 loss = 0.2708\n",
      "epoch 3 batch 7/185 loss = 0.2792\n",
      "epoch 3 batch 8/185 loss = 0.2670\n",
      "epoch 3 batch 9/185 loss = 0.2709\n",
      "epoch 3 batch 10/185 loss = 0.2756\n",
      "epoch 3 batch 11/185 loss = 0.2552\n",
      "epoch 3 batch 12/185 loss = 0.2613\n",
      "epoch 3 batch 13/185 loss = 0.2634\n",
      "epoch 3 batch 14/185 loss = 0.2748\n",
      "epoch 3 batch 15/185 loss = 0.2680\n",
      "epoch 3 batch 16/185 loss = 0.2640\n",
      "epoch 3 batch 17/185 loss = 0.2493\n",
      "epoch 3 batch 18/185 loss = 0.2525\n",
      "epoch 3 batch 19/185 loss = 0.2695\n",
      "epoch 3 batch 20/185 loss = 0.2534\n",
      "epoch 3 batch 21/185 loss = 0.2455\n",
      "epoch 3 batch 22/185 loss = 0.2594\n",
      "epoch 3 batch 23/185 loss = 0.2522\n",
      "epoch 3 batch 24/185 loss = 0.2629\n",
      "epoch 3 batch 25/185 loss = 0.2610\n",
      "epoch 3 batch 26/185 loss = 0.2521\n",
      "epoch 3 batch 27/185 loss = 0.2596\n",
      "epoch 3 batch 28/185 loss = 0.2561\n",
      "epoch 3 batch 29/185 loss = 0.2556\n",
      "epoch 3 batch 30/185 loss = 0.2395\n",
      "epoch 3 batch 31/185 loss = 0.2513\n",
      "epoch 3 batch 32/185 loss = 0.2446\n",
      "epoch 3 batch 33/185 loss = 0.2539\n",
      "epoch 3 batch 34/185 loss = 0.2429\n",
      "epoch 3 batch 35/185 loss = 0.2597\n",
      "epoch 3 batch 36/185 loss = 0.2487\n",
      "epoch 3 batch 37/185 loss = 0.2371\n",
      "epoch 3 batch 38/185 loss = 0.2488\n",
      "epoch 3 batch 39/185 loss = 0.2560\n",
      "epoch 3 batch 40/185 loss = 0.2426\n",
      "epoch 3 batch 41/185 loss = 0.2378\n",
      "epoch 3 batch 42/185 loss = 0.2504\n",
      "epoch 3 batch 43/185 loss = 0.2335\n",
      "epoch 3 batch 44/185 loss = 0.2308\n",
      "epoch 3 batch 45/185 loss = 0.2342\n",
      "epoch 3 batch 46/185 loss = 0.2526\n",
      "epoch 3 batch 47/185 loss = 0.2296\n",
      "epoch 3 batch 48/185 loss = 0.2414\n",
      "epoch 3 batch 49/185 loss = 0.2263\n",
      "epoch 3 batch 50/185 loss = 0.2422\n",
      "epoch 3 batch 51/185 loss = 0.2353\n",
      "epoch 3 batch 52/185 loss = 0.2428\n",
      "epoch 3 batch 53/185 loss = 0.2443\n",
      "epoch 3 batch 54/185 loss = 0.2360\n",
      "epoch 3 batch 55/185 loss = 0.2312\n",
      "epoch 3 batch 56/185 loss = 0.2384\n",
      "epoch 3 batch 57/185 loss = 0.2334\n",
      "epoch 3 batch 58/185 loss = 0.2430\n",
      "epoch 3 batch 59/185 loss = 0.2254\n",
      "epoch 3 batch 60/185 loss = 0.2275\n",
      "epoch 3 batch 61/185 loss = 0.2277\n",
      "epoch 3 batch 62/185 loss = 0.2319\n",
      "epoch 3 batch 63/185 loss = 0.2319\n",
      "epoch 3 batch 64/185 loss = 0.2270\n",
      "epoch 3 batch 65/185 loss = 0.2270\n",
      "epoch 3 batch 66/185 loss = 0.2267\n",
      "epoch 3 batch 67/185 loss = 0.2221\n",
      "epoch 3 batch 68/185 loss = 0.2178\n",
      "epoch 3 batch 69/185 loss = 0.2293\n",
      "epoch 3 batch 70/185 loss = 0.2153\n",
      "epoch 3 batch 71/185 loss = 0.2219\n",
      "epoch 3 batch 72/185 loss = 0.2067\n",
      "epoch 3 batch 73/185 loss = 0.2174\n",
      "epoch 3 batch 74/185 loss = 0.2202\n",
      "epoch 3 batch 75/185 loss = 0.2137\n",
      "epoch 3 batch 76/185 loss = 0.2166\n",
      "epoch 3 batch 77/185 loss = 0.2147\n",
      "epoch 3 batch 78/185 loss = 0.2288\n",
      "epoch 3 batch 79/185 loss = 0.2285\n",
      "epoch 3 batch 80/185 loss = 0.2227\n",
      "epoch 3 batch 81/185 loss = 0.2189\n",
      "epoch 3 batch 82/185 loss = 0.2113\n",
      "epoch 3 batch 83/185 loss = 0.2105\n",
      "epoch 3 batch 84/185 loss = 0.2248\n",
      "epoch 3 batch 85/185 loss = 0.2169\n",
      "epoch 3 batch 86/185 loss = 0.2144\n",
      "epoch 3 batch 87/185 loss = 0.2022\n",
      "epoch 3 batch 88/185 loss = 0.2090\n",
      "epoch 3 batch 89/185 loss = 0.2070\n",
      "epoch 3 batch 90/185 loss = 0.2148\n",
      "epoch 3 batch 91/185 loss = 0.2120\n",
      "epoch 3 batch 92/185 loss = 0.2069\n",
      "epoch 3 batch 93/185 loss = 0.2132\n",
      "epoch 3 batch 94/185 loss = 0.2001\n",
      "epoch 3 batch 95/185 loss = 0.1972\n",
      "epoch 3 batch 96/185 loss = 0.2005\n",
      "epoch 3 batch 97/185 loss = 0.2035\n",
      "epoch 3 batch 98/185 loss = 0.1974\n",
      "epoch 3 batch 99/185 loss = 0.1943\n",
      "epoch 3 batch 100/185 loss = 0.2067\n",
      "epoch 3 batch 101/185 loss = 0.1964\n",
      "epoch 3 batch 102/185 loss = 0.1945\n",
      "epoch 3 batch 103/185 loss = 0.1871\n",
      "epoch 3 batch 104/185 loss = 0.1979\n",
      "epoch 3 batch 105/185 loss = 0.2084\n",
      "epoch 3 batch 106/185 loss = 0.1964\n",
      "epoch 3 batch 107/185 loss = 0.1994\n",
      "epoch 3 batch 108/185 loss = 0.1909\n",
      "epoch 3 batch 109/185 loss = 0.1896\n",
      "epoch 3 batch 110/185 loss = 0.1907\n",
      "epoch 3 batch 111/185 loss = 0.1894\n",
      "epoch 3 batch 112/185 loss = 0.1885\n",
      "epoch 3 batch 113/185 loss = 0.1993\n",
      "epoch 3 batch 114/185 loss = 0.2001\n",
      "epoch 3 batch 115/185 loss = 0.1942\n",
      "epoch 3 batch 116/185 loss = 0.1863\n",
      "epoch 3 batch 117/185 loss = 0.1996\n",
      "epoch 3 batch 118/185 loss = 0.1937\n",
      "epoch 3 batch 119/185 loss = 0.1879\n",
      "epoch 3 batch 120/185 loss = 0.1903\n",
      "epoch 3 batch 121/185 loss = 0.1979\n",
      "epoch 3 batch 122/185 loss = 0.1871\n",
      "epoch 3 batch 123/185 loss = 0.1857\n",
      "epoch 3 batch 124/185 loss = 0.1934\n",
      "epoch 3 batch 125/185 loss = 0.1896\n",
      "epoch 3 batch 126/185 loss = 0.1811\n",
      "epoch 3 batch 127/185 loss = 0.1929\n",
      "epoch 3 batch 128/185 loss = 0.1806\n",
      "epoch 3 batch 129/185 loss = 0.1868\n",
      "epoch 3 batch 130/185 loss = 0.1812\n",
      "epoch 3 batch 131/185 loss = 0.1864\n",
      "epoch 3 batch 132/185 loss = 0.1842\n",
      "epoch 3 batch 133/185 loss = 0.1813\n",
      "epoch 3 batch 134/185 loss = 0.1739\n",
      "epoch 3 batch 135/185 loss = 0.1817\n",
      "epoch 3 batch 136/185 loss = 0.1719\n",
      "epoch 3 batch 137/185 loss = 0.1818\n",
      "epoch 3 batch 138/185 loss = 0.1791\n",
      "epoch 3 batch 139/185 loss = 0.1683\n",
      "epoch 3 batch 140/185 loss = 0.1674\n",
      "epoch 3 batch 141/185 loss = 0.1736\n",
      "epoch 3 batch 142/185 loss = 0.1838\n",
      "epoch 3 batch 143/185 loss = 0.1775\n",
      "epoch 3 batch 144/185 loss = 0.1692\n",
      "epoch 3 batch 145/185 loss = 0.1718\n",
      "epoch 3 batch 146/185 loss = 0.1605\n",
      "epoch 3 batch 147/185 loss = 0.1807\n",
      "epoch 3 batch 148/185 loss = 0.1704\n",
      "epoch 3 batch 149/185 loss = 0.1686\n",
      "epoch 3 batch 150/185 loss = 0.1697\n",
      "epoch 3 batch 151/185 loss = 0.1730\n",
      "epoch 3 batch 152/185 loss = 0.1674\n",
      "epoch 3 batch 153/185 loss = 0.1793\n",
      "epoch 3 batch 154/185 loss = 0.1716\n",
      "epoch 3 batch 155/185 loss = 0.1746\n",
      "epoch 3 batch 156/185 loss = 0.1644\n",
      "epoch 3 batch 157/185 loss = 0.1638\n",
      "epoch 3 batch 158/185 loss = 0.1730\n",
      "epoch 3 batch 159/185 loss = 0.1677\n",
      "epoch 3 batch 160/185 loss = 0.1611\n",
      "epoch 3 batch 161/185 loss = 0.1587\n",
      "epoch 3 batch 162/185 loss = 0.1613\n",
      "epoch 3 batch 163/185 loss = 0.1692\n",
      "epoch 3 batch 164/185 loss = 0.1579\n",
      "epoch 3 batch 165/185 loss = 0.1618\n",
      "epoch 3 batch 166/185 loss = 0.1554\n",
      "epoch 3 batch 167/185 loss = 0.1561\n",
      "epoch 3 batch 168/185 loss = 0.1638\n",
      "epoch 3 batch 169/185 loss = 0.1514\n",
      "epoch 3 batch 170/185 loss = 0.1579\n",
      "epoch 3 batch 171/185 loss = 0.1544\n",
      "epoch 3 batch 172/185 loss = 0.1591\n",
      "epoch 3 batch 173/185 loss = 0.1496\n",
      "epoch 3 batch 174/185 loss = 0.1664\n",
      "epoch 3 batch 175/185 loss = 0.1540\n",
      "epoch 3 batch 176/185 loss = 0.1515\n",
      "epoch 3 batch 177/185 loss = 0.1629\n",
      "epoch 3 batch 178/185 loss = 0.1645\n",
      "epoch 3 batch 179/185 loss = 0.1544\n",
      "epoch 3 batch 180/185 loss = 0.1490\n",
      "epoch 3 batch 181/185 loss = 0.1571\n",
      "epoch 3 batch 182/185 loss = 0.1531\n",
      "epoch 3 batch 183/185 loss = 0.1617\n",
      "epoch 3 batch 184/185 loss = 0.1399\n",
      "epoch 3 batch 185/185 loss = 0.1485\n",
      "epoch 3 train loss = 0.2088 valid loss = 0.1489\n",
      "epoch 4 batch 1/185 loss = 0.1515\n",
      "epoch 4 batch 2/185 loss = 0.1458\n",
      "epoch 4 batch 3/185 loss = 0.1540\n",
      "epoch 4 batch 4/185 loss = 0.1576\n",
      "epoch 4 batch 5/185 loss = 0.1465\n",
      "epoch 4 batch 6/185 loss = 0.1498\n",
      "epoch 4 batch 7/185 loss = 0.1436\n",
      "epoch 4 batch 8/185 loss = 0.1432\n",
      "epoch 4 batch 9/185 loss = 0.1468\n",
      "epoch 4 batch 10/185 loss = 0.1383\n",
      "epoch 4 batch 11/185 loss = 0.1448\n",
      "epoch 4 batch 12/185 loss = 0.1404\n",
      "epoch 4 batch 13/185 loss = 0.1445\n",
      "epoch 4 batch 14/185 loss = 0.1514\n",
      "epoch 4 batch 15/185 loss = 0.1392\n",
      "epoch 4 batch 16/185 loss = 0.1507\n",
      "epoch 4 batch 17/185 loss = 0.1420\n",
      "epoch 4 batch 18/185 loss = 0.1402\n",
      "epoch 4 batch 19/185 loss = 0.1406\n",
      "epoch 4 batch 20/185 loss = 0.1377\n",
      "epoch 4 batch 21/185 loss = 0.1379\n",
      "epoch 4 batch 22/185 loss = 0.1472\n",
      "epoch 4 batch 23/185 loss = 0.1403\n",
      "epoch 4 batch 24/185 loss = 0.1308\n",
      "epoch 4 batch 25/185 loss = 0.1356\n",
      "epoch 4 batch 26/185 loss = 0.1397\n",
      "epoch 4 batch 27/185 loss = 0.1412\n",
      "epoch 4 batch 28/185 loss = 0.1467\n",
      "epoch 4 batch 29/185 loss = 0.1368\n",
      "epoch 4 batch 30/185 loss = 0.1371\n",
      "epoch 4 batch 31/185 loss = 0.1374\n",
      "epoch 4 batch 32/185 loss = 0.1388\n",
      "epoch 4 batch 33/185 loss = 0.1360\n",
      "epoch 4 batch 34/185 loss = 0.1359\n",
      "epoch 4 batch 35/185 loss = 0.1310\n",
      "epoch 4 batch 36/185 loss = 0.1376\n",
      "epoch 4 batch 37/185 loss = 0.1374\n",
      "epoch 4 batch 38/185 loss = 0.1363\n",
      "epoch 4 batch 39/185 loss = 0.1407\n",
      "epoch 4 batch 40/185 loss = 0.1289\n",
      "epoch 4 batch 41/185 loss = 0.1339\n",
      "epoch 4 batch 42/185 loss = 0.1317\n",
      "epoch 4 batch 43/185 loss = 0.1354\n",
      "epoch 4 batch 44/185 loss = 0.1249\n",
      "epoch 4 batch 45/185 loss = 0.1304\n",
      "epoch 4 batch 46/185 loss = 0.1311\n",
      "epoch 4 batch 47/185 loss = 0.1396\n",
      "epoch 4 batch 48/185 loss = 0.1302\n",
      "epoch 4 batch 49/185 loss = 0.1320\n",
      "epoch 4 batch 50/185 loss = 0.1261\n",
      "epoch 4 batch 51/185 loss = 0.1251\n",
      "epoch 4 batch 52/185 loss = 0.1284\n",
      "epoch 4 batch 53/185 loss = 0.1292\n",
      "epoch 4 batch 54/185 loss = 0.1289\n",
      "epoch 4 batch 55/185 loss = 0.1252\n",
      "epoch 4 batch 56/185 loss = 0.1262\n",
      "epoch 4 batch 57/185 loss = 0.1216\n",
      "epoch 4 batch 58/185 loss = 0.1166\n",
      "epoch 4 batch 59/185 loss = 0.1211\n",
      "epoch 4 batch 60/185 loss = 0.1300\n",
      "epoch 4 batch 61/185 loss = 0.1299\n",
      "epoch 4 batch 62/185 loss = 0.1313\n",
      "epoch 4 batch 63/185 loss = 0.1248\n",
      "epoch 4 batch 64/185 loss = 0.1202\n",
      "epoch 4 batch 65/185 loss = 0.1257\n",
      "epoch 4 batch 66/185 loss = 0.1139\n",
      "epoch 4 batch 67/185 loss = 0.1201\n",
      "epoch 4 batch 68/185 loss = 0.1261\n",
      "epoch 4 batch 69/185 loss = 0.1199\n",
      "epoch 4 batch 70/185 loss = 0.1254\n",
      "epoch 4 batch 71/185 loss = 0.1274\n",
      "epoch 4 batch 72/185 loss = 0.1119\n",
      "epoch 4 batch 73/185 loss = 0.1285\n",
      "epoch 4 batch 74/185 loss = 0.1292\n",
      "epoch 4 batch 75/185 loss = 0.1182\n",
      "epoch 4 batch 76/185 loss = 0.1244\n",
      "epoch 4 batch 77/185 loss = 0.1169\n",
      "epoch 4 batch 78/185 loss = 0.1194\n",
      "epoch 4 batch 79/185 loss = 0.1147\n",
      "epoch 4 batch 80/185 loss = 0.1158\n",
      "epoch 4 batch 81/185 loss = 0.1099\n",
      "epoch 4 batch 82/185 loss = 0.1189\n",
      "epoch 4 batch 83/185 loss = 0.1201\n",
      "epoch 4 batch 84/185 loss = 0.1131\n",
      "epoch 4 batch 85/185 loss = 0.1110\n",
      "epoch 4 batch 86/185 loss = 0.1128\n",
      "epoch 4 batch 87/185 loss = 0.1140\n",
      "epoch 4 batch 88/185 loss = 0.1105\n",
      "epoch 4 batch 89/185 loss = 0.1082\n",
      "epoch 4 batch 90/185 loss = 0.1082\n",
      "epoch 4 batch 91/185 loss = 0.1130\n",
      "epoch 4 batch 92/185 loss = 0.1162\n",
      "epoch 4 batch 93/185 loss = 0.1205\n",
      "epoch 4 batch 94/185 loss = 0.1169\n",
      "epoch 4 batch 95/185 loss = 0.1070\n",
      "epoch 4 batch 96/185 loss = 0.1103\n",
      "epoch 4 batch 97/185 loss = 0.1133\n",
      "epoch 4 batch 98/185 loss = 0.1109\n",
      "epoch 4 batch 99/185 loss = 0.1059\n",
      "epoch 4 batch 100/185 loss = 0.1044\n",
      "epoch 4 batch 101/185 loss = 0.1061\n",
      "epoch 4 batch 102/185 loss = 0.1101\n",
      "epoch 4 batch 103/185 loss = 0.1049\n",
      "epoch 4 batch 104/185 loss = 0.1090\n",
      "epoch 4 batch 105/185 loss = 0.1112\n",
      "epoch 4 batch 106/185 loss = 0.1010\n",
      "epoch 4 batch 107/185 loss = 0.1066\n",
      "epoch 4 batch 108/185 loss = 0.1071\n",
      "epoch 4 batch 109/185 loss = 0.1064\n",
      "epoch 4 batch 110/185 loss = 0.1029\n",
      "epoch 4 batch 111/185 loss = 0.1081\n",
      "epoch 4 batch 112/185 loss = 0.1049\n",
      "epoch 4 batch 113/185 loss = 0.0975\n",
      "epoch 4 batch 114/185 loss = 0.1027\n",
      "epoch 4 batch 115/185 loss = 0.0978\n",
      "epoch 4 batch 116/185 loss = 0.1046\n",
      "epoch 4 batch 117/185 loss = 0.0965\n",
      "epoch 4 batch 118/185 loss = 0.1166\n",
      "epoch 4 batch 119/185 loss = 0.1020\n",
      "epoch 4 batch 120/185 loss = 0.0990\n",
      "epoch 4 batch 121/185 loss = 0.0910\n",
      "epoch 4 batch 122/185 loss = 0.1002\n",
      "epoch 4 batch 123/185 loss = 0.0983\n",
      "epoch 4 batch 124/185 loss = 0.0960\n",
      "epoch 4 batch 125/185 loss = 0.1052\n",
      "epoch 4 batch 126/185 loss = 0.1014\n",
      "epoch 4 batch 127/185 loss = 0.0989\n",
      "epoch 4 batch 128/185 loss = 0.1058\n",
      "epoch 4 batch 129/185 loss = 0.0957\n",
      "epoch 4 batch 130/185 loss = 0.0978\n",
      "epoch 4 batch 131/185 loss = 0.1002\n",
      "epoch 4 batch 132/185 loss = 0.0918\n",
      "epoch 4 batch 133/185 loss = 0.0999\n",
      "epoch 4 batch 134/185 loss = 0.1000\n",
      "epoch 4 batch 135/185 loss = 0.1009\n",
      "epoch 4 batch 136/185 loss = 0.0965\n",
      "epoch 4 batch 137/185 loss = 0.0913\n",
      "epoch 4 batch 138/185 loss = 0.0940\n",
      "epoch 4 batch 139/185 loss = 0.0887\n",
      "epoch 4 batch 140/185 loss = 0.0994\n",
      "epoch 4 batch 141/185 loss = 0.0916\n",
      "epoch 4 batch 142/185 loss = 0.0873\n",
      "epoch 4 batch 143/185 loss = 0.0913\n",
      "epoch 4 batch 144/185 loss = 0.0910\n",
      "epoch 4 batch 145/185 loss = 0.0954\n",
      "epoch 4 batch 146/185 loss = 0.0894\n",
      "epoch 4 batch 147/185 loss = 0.0892\n",
      "epoch 4 batch 148/185 loss = 0.0890\n",
      "epoch 4 batch 149/185 loss = 0.0895\n",
      "epoch 4 batch 150/185 loss = 0.0917\n",
      "epoch 4 batch 151/185 loss = 0.0915\n",
      "epoch 4 batch 152/185 loss = 0.1015\n",
      "epoch 4 batch 153/185 loss = 0.1000\n",
      "epoch 4 batch 154/185 loss = 0.0953\n",
      "epoch 4 batch 155/185 loss = 0.0851\n",
      "epoch 4 batch 156/185 loss = 0.0840\n",
      "epoch 4 batch 157/185 loss = 0.0898\n",
      "epoch 4 batch 158/185 loss = 0.0921\n",
      "epoch 4 batch 159/185 loss = 0.0901\n",
      "epoch 4 batch 160/185 loss = 0.0884\n",
      "epoch 4 batch 161/185 loss = 0.0940\n",
      "epoch 4 batch 162/185 loss = 0.0835\n",
      "epoch 4 batch 163/185 loss = 0.0891\n",
      "epoch 4 batch 164/185 loss = 0.0859\n",
      "epoch 4 batch 165/185 loss = 0.0902\n",
      "epoch 4 batch 166/185 loss = 0.0851\n",
      "epoch 4 batch 167/185 loss = 0.0785\n",
      "epoch 4 batch 168/185 loss = 0.0790\n",
      "epoch 4 batch 169/185 loss = 0.0857\n",
      "epoch 4 batch 170/185 loss = 0.0915\n",
      "epoch 4 batch 171/185 loss = 0.0860\n",
      "epoch 4 batch 172/185 loss = 0.0797\n",
      "epoch 4 batch 173/185 loss = 0.0791\n",
      "epoch 4 batch 174/185 loss = 0.0833\n",
      "epoch 4 batch 175/185 loss = 0.0854\n",
      "epoch 4 batch 176/185 loss = 0.0876\n",
      "epoch 4 batch 177/185 loss = 0.0788\n",
      "epoch 4 batch 178/185 loss = 0.0840\n",
      "epoch 4 batch 179/185 loss = 0.0906\n",
      "epoch 4 batch 180/185 loss = 0.0752\n",
      "epoch 4 batch 181/185 loss = 0.0808\n",
      "epoch 4 batch 182/185 loss = 0.0875\n",
      "epoch 4 batch 183/185 loss = 0.0793\n",
      "epoch 4 batch 184/185 loss = 0.0789\n",
      "epoch 4 batch 185/185 loss = 0.0799\n",
      "epoch 4 train loss = 0.1129 valid loss = 0.0718\n",
      "epoch 5 batch 1/185 loss = 0.0786\n",
      "epoch 5 batch 2/185 loss = 0.0757\n",
      "epoch 5 batch 3/185 loss = 0.0841\n",
      "epoch 5 batch 4/185 loss = 0.0798\n",
      "epoch 5 batch 5/185 loss = 0.0894\n",
      "epoch 5 batch 6/185 loss = 0.0779\n",
      "epoch 5 batch 7/185 loss = 0.0840\n",
      "epoch 5 batch 8/185 loss = 0.0776\n",
      "epoch 5 batch 9/185 loss = 0.0738\n",
      "epoch 5 batch 10/185 loss = 0.0775\n",
      "epoch 5 batch 11/185 loss = 0.0775\n",
      "epoch 5 batch 12/185 loss = 0.0827\n",
      "epoch 5 batch 13/185 loss = 0.0817\n",
      "epoch 5 batch 14/185 loss = 0.0776\n",
      "epoch 5 batch 15/185 loss = 0.0810\n",
      "epoch 5 batch 16/185 loss = 0.0703\n",
      "epoch 5 batch 17/185 loss = 0.0765\n",
      "epoch 5 batch 18/185 loss = 0.0757\n",
      "epoch 5 batch 19/185 loss = 0.0795\n",
      "epoch 5 batch 20/185 loss = 0.0746\n",
      "epoch 5 batch 21/185 loss = 0.0721\n",
      "epoch 5 batch 22/185 loss = 0.0747\n",
      "epoch 5 batch 23/185 loss = 0.0799\n",
      "epoch 5 batch 24/185 loss = 0.0756\n",
      "epoch 5 batch 25/185 loss = 0.0727\n",
      "epoch 5 batch 26/185 loss = 0.0738\n",
      "epoch 5 batch 27/185 loss = 0.0689\n",
      "epoch 5 batch 28/185 loss = 0.0741\n",
      "epoch 5 batch 29/185 loss = 0.0672\n",
      "epoch 5 batch 30/185 loss = 0.0722\n",
      "epoch 5 batch 31/185 loss = 0.0758\n",
      "epoch 5 batch 32/185 loss = 0.0660\n",
      "epoch 5 batch 33/185 loss = 0.0723\n",
      "epoch 5 batch 34/185 loss = 0.0714\n",
      "epoch 5 batch 35/185 loss = 0.0678\n",
      "epoch 5 batch 36/185 loss = 0.0682\n",
      "epoch 5 batch 37/185 loss = 0.0664\n",
      "epoch 5 batch 38/185 loss = 0.0811\n",
      "epoch 5 batch 39/185 loss = 0.0694\n",
      "epoch 5 batch 40/185 loss = 0.0667\n",
      "epoch 5 batch 41/185 loss = 0.0655\n",
      "epoch 5 batch 42/185 loss = 0.0692\n",
      "epoch 5 batch 43/185 loss = 0.0658\n",
      "epoch 5 batch 44/185 loss = 0.0663\n",
      "epoch 5 batch 45/185 loss = 0.0658\n",
      "epoch 5 batch 46/185 loss = 0.0689\n",
      "epoch 5 batch 47/185 loss = 0.0780\n",
      "epoch 5 batch 48/185 loss = 0.0719\n",
      "epoch 5 batch 49/185 loss = 0.0672\n",
      "epoch 5 batch 50/185 loss = 0.0661\n",
      "epoch 5 batch 51/185 loss = 0.0647\n",
      "epoch 5 batch 52/185 loss = 0.0640\n",
      "epoch 5 batch 53/185 loss = 0.0674\n",
      "epoch 5 batch 54/185 loss = 0.0645\n",
      "epoch 5 batch 55/185 loss = 0.0667\n",
      "epoch 5 batch 56/185 loss = 0.0654\n",
      "epoch 5 batch 57/185 loss = 0.0667\n",
      "epoch 5 batch 58/185 loss = 0.0622\n",
      "epoch 5 batch 59/185 loss = 0.0639\n",
      "epoch 5 batch 60/185 loss = 0.0705\n",
      "epoch 5 batch 61/185 loss = 0.0633\n",
      "epoch 5 batch 62/185 loss = 0.0646\n",
      "epoch 5 batch 63/185 loss = 0.0610\n",
      "epoch 5 batch 64/185 loss = 0.0788\n",
      "epoch 5 batch 65/185 loss = 0.0632\n",
      "epoch 5 batch 66/185 loss = 0.0729\n",
      "epoch 5 batch 67/185 loss = 0.0614\n",
      "epoch 5 batch 68/185 loss = 0.0649\n",
      "epoch 5 batch 69/185 loss = 0.0646\n",
      "epoch 5 batch 70/185 loss = 0.0664\n",
      "epoch 5 batch 71/185 loss = 0.0701\n",
      "epoch 5 batch 72/185 loss = 0.0643\n",
      "epoch 5 batch 73/185 loss = 0.0623\n",
      "epoch 5 batch 74/185 loss = 0.0630\n",
      "epoch 5 batch 75/185 loss = 0.0650\n",
      "epoch 5 batch 76/185 loss = 0.0642\n",
      "epoch 5 batch 77/185 loss = 0.0597\n",
      "epoch 5 batch 78/185 loss = 0.0611\n",
      "epoch 5 batch 79/185 loss = 0.0696\n",
      "epoch 5 batch 80/185 loss = 0.0635\n",
      "epoch 5 batch 81/185 loss = 0.0608\n",
      "epoch 5 batch 82/185 loss = 0.0644\n",
      "epoch 5 batch 83/185 loss = 0.0655\n",
      "epoch 5 batch 84/185 loss = 0.0645\n",
      "epoch 5 batch 85/185 loss = 0.0563\n",
      "epoch 5 batch 86/185 loss = 0.0627\n",
      "epoch 5 batch 87/185 loss = 0.0539\n",
      "epoch 5 batch 88/185 loss = 0.0571\n",
      "epoch 5 batch 89/185 loss = 0.0591\n",
      "epoch 5 batch 90/185 loss = 0.0635\n",
      "epoch 5 batch 91/185 loss = 0.0628\n",
      "epoch 5 batch 92/185 loss = 0.0608\n",
      "epoch 5 batch 93/185 loss = 0.0579\n",
      "epoch 5 batch 94/185 loss = 0.0568\n",
      "epoch 5 batch 95/185 loss = 0.0585\n",
      "epoch 5 batch 96/185 loss = 0.0628\n",
      "epoch 5 batch 97/185 loss = 0.0621\n",
      "epoch 5 batch 98/185 loss = 0.0567\n",
      "epoch 5 batch 99/185 loss = 0.0567\n",
      "epoch 5 batch 100/185 loss = 0.0536\n",
      "epoch 5 batch 101/185 loss = 0.0565\n",
      "epoch 5 batch 102/185 loss = 0.0588\n",
      "epoch 5 batch 103/185 loss = 0.0584\n",
      "epoch 5 batch 104/185 loss = 0.0545\n",
      "epoch 5 batch 105/185 loss = 0.0536\n",
      "epoch 5 batch 106/185 loss = 0.0521\n",
      "epoch 5 batch 107/185 loss = 0.0542\n",
      "epoch 5 batch 108/185 loss = 0.0599\n",
      "epoch 5 batch 109/185 loss = 0.0565\n",
      "epoch 5 batch 110/185 loss = 0.0632\n",
      "epoch 5 batch 111/185 loss = 0.0543\n",
      "epoch 5 batch 112/185 loss = 0.0525\n",
      "epoch 5 batch 113/185 loss = 0.0590\n",
      "epoch 5 batch 114/185 loss = 0.0521\n",
      "epoch 5 batch 115/185 loss = 0.0587\n",
      "epoch 5 batch 116/185 loss = 0.0477\n",
      "epoch 5 batch 117/185 loss = 0.0570\n",
      "epoch 5 batch 118/185 loss = 0.0536\n",
      "epoch 5 batch 119/185 loss = 0.0519\n",
      "epoch 5 batch 120/185 loss = 0.0481\n",
      "epoch 5 batch 121/185 loss = 0.0534\n",
      "epoch 5 batch 122/185 loss = 0.0580\n",
      "epoch 5 batch 123/185 loss = 0.0544\n",
      "epoch 5 batch 124/185 loss = 0.0513\n",
      "epoch 5 batch 125/185 loss = 0.0615\n",
      "epoch 5 batch 126/185 loss = 0.0583\n",
      "epoch 5 batch 127/185 loss = 0.0540\n",
      "epoch 5 batch 128/185 loss = 0.0504\n",
      "epoch 5 batch 129/185 loss = 0.0547\n",
      "epoch 5 batch 130/185 loss = 0.0516\n",
      "epoch 5 batch 131/185 loss = 0.0495\n",
      "epoch 5 batch 132/185 loss = 0.0483\n",
      "epoch 5 batch 133/185 loss = 0.0524\n",
      "epoch 5 batch 134/185 loss = 0.0505\n",
      "epoch 5 batch 135/185 loss = 0.0496\n",
      "epoch 5 batch 136/185 loss = 0.0537\n",
      "epoch 5 batch 137/185 loss = 0.0484\n",
      "epoch 5 batch 138/185 loss = 0.0537\n",
      "epoch 5 batch 139/185 loss = 0.0502\n",
      "epoch 5 batch 140/185 loss = 0.0527\n",
      "epoch 5 batch 141/185 loss = 0.0521\n",
      "epoch 5 batch 142/185 loss = 0.0518\n",
      "epoch 5 batch 143/185 loss = 0.0522\n",
      "epoch 5 batch 144/185 loss = 0.0439\n",
      "epoch 5 batch 145/185 loss = 0.0511\n",
      "epoch 5 batch 146/185 loss = 0.0515\n",
      "epoch 5 batch 147/185 loss = 0.0551\n",
      "epoch 5 batch 148/185 loss = 0.0459\n",
      "epoch 5 batch 149/185 loss = 0.0498\n",
      "epoch 5 batch 150/185 loss = 0.0453\n",
      "epoch 5 batch 151/185 loss = 0.0515\n",
      "epoch 5 batch 152/185 loss = 0.0523\n",
      "epoch 5 batch 153/185 loss = 0.0519\n",
      "epoch 5 batch 154/185 loss = 0.0480\n",
      "epoch 5 batch 155/185 loss = 0.0475\n",
      "epoch 5 batch 156/185 loss = 0.0475\n",
      "epoch 5 batch 157/185 loss = 0.0480\n",
      "epoch 5 batch 158/185 loss = 0.0412\n",
      "epoch 5 batch 159/185 loss = 0.0463\n",
      "epoch 5 batch 160/185 loss = 0.0434\n",
      "epoch 5 batch 161/185 loss = 0.0486\n",
      "epoch 5 batch 162/185 loss = 0.0465\n",
      "epoch 5 batch 163/185 loss = 0.0442\n",
      "epoch 5 batch 164/185 loss = 0.0467\n",
      "epoch 5 batch 165/185 loss = 0.0495\n",
      "epoch 5 batch 166/185 loss = 0.0436\n",
      "epoch 5 batch 167/185 loss = 0.0459\n",
      "epoch 5 batch 168/185 loss = 0.0477\n",
      "epoch 5 batch 169/185 loss = 0.0431\n",
      "epoch 5 batch 170/185 loss = 0.0470\n",
      "epoch 5 batch 171/185 loss = 0.0460\n",
      "epoch 5 batch 172/185 loss = 0.0433\n",
      "epoch 5 batch 173/185 loss = 0.0406\n",
      "epoch 5 batch 174/185 loss = 0.0482\n",
      "epoch 5 batch 175/185 loss = 0.0469\n",
      "epoch 5 batch 176/185 loss = 0.0429\n",
      "epoch 5 batch 177/185 loss = 0.0440\n",
      "epoch 5 batch 178/185 loss = 0.0467\n",
      "epoch 5 batch 179/185 loss = 0.0417\n",
      "epoch 5 batch 180/185 loss = 0.0427\n",
      "epoch 5 batch 181/185 loss = 0.0397\n",
      "epoch 5 batch 182/185 loss = 0.0424\n",
      "epoch 5 batch 183/185 loss = 0.0458\n",
      "epoch 5 batch 184/185 loss = 0.0382\n",
      "epoch 5 batch 185/185 loss = 0.0492\n",
      "epoch 5 train loss = 0.0600 valid loss = 0.0427\n",
      "epoch 6 batch 1/185 loss = 0.0398\n",
      "epoch 6 batch 2/185 loss = 0.0411\n",
      "epoch 6 batch 3/185 loss = 0.0436\n",
      "epoch 6 batch 4/185 loss = 0.0416\n",
      "epoch 6 batch 5/185 loss = 0.0394\n",
      "epoch 6 batch 6/185 loss = 0.0444\n",
      "epoch 6 batch 7/185 loss = 0.0399\n",
      "epoch 6 batch 8/185 loss = 0.0403\n",
      "epoch 6 batch 9/185 loss = 0.0447\n",
      "epoch 6 batch 10/185 loss = 0.0397\n",
      "epoch 6 batch 11/185 loss = 0.0420\n",
      "epoch 6 batch 12/185 loss = 0.0401\n",
      "epoch 6 batch 13/185 loss = 0.0499\n",
      "epoch 6 batch 14/185 loss = 0.0424\n",
      "epoch 6 batch 15/185 loss = 0.0406\n",
      "epoch 6 batch 16/185 loss = 0.0429\n",
      "epoch 6 batch 17/185 loss = 0.0443\n",
      "epoch 6 batch 18/185 loss = 0.0413\n",
      "epoch 6 batch 19/185 loss = 0.0406\n",
      "epoch 6 batch 20/185 loss = 0.0386\n",
      "epoch 6 batch 21/185 loss = 0.0400\n",
      "epoch 6 batch 22/185 loss = 0.0460\n",
      "epoch 6 batch 23/185 loss = 0.0386\n",
      "epoch 6 batch 24/185 loss = 0.0391\n",
      "epoch 6 batch 25/185 loss = 0.0416\n",
      "epoch 6 batch 26/185 loss = 0.0395\n",
      "epoch 6 batch 27/185 loss = 0.0403\n",
      "epoch 6 batch 28/185 loss = 0.0390\n",
      "epoch 6 batch 29/185 loss = 0.0421\n",
      "epoch 6 batch 30/185 loss = 0.0370\n",
      "epoch 6 batch 31/185 loss = 0.0406\n",
      "epoch 6 batch 32/185 loss = 0.0413\n",
      "epoch 6 batch 33/185 loss = 0.0392\n",
      "epoch 6 batch 34/185 loss = 0.0389\n",
      "epoch 6 batch 35/185 loss = 0.0417\n",
      "epoch 6 batch 36/185 loss = 0.0382\n",
      "epoch 6 batch 37/185 loss = 0.0399\n",
      "epoch 6 batch 38/185 loss = 0.0377\n",
      "epoch 6 batch 39/185 loss = 0.0396\n",
      "epoch 6 batch 40/185 loss = 0.0364\n",
      "epoch 6 batch 41/185 loss = 0.0427\n",
      "epoch 6 batch 42/185 loss = 0.0353\n",
      "epoch 6 batch 43/185 loss = 0.0415\n",
      "epoch 6 batch 44/185 loss = 0.0388\n",
      "epoch 6 batch 45/185 loss = 0.0425\n",
      "epoch 6 batch 46/185 loss = 0.0344\n",
      "epoch 6 batch 47/185 loss = 0.0387\n",
      "epoch 6 batch 48/185 loss = 0.0369\n",
      "epoch 6 batch 49/185 loss = 0.0332\n",
      "epoch 6 batch 50/185 loss = 0.0385\n",
      "epoch 6 batch 51/185 loss = 0.0345\n",
      "epoch 6 batch 52/185 loss = 0.0372\n",
      "epoch 6 batch 53/185 loss = 0.0378\n",
      "epoch 6 batch 54/185 loss = 0.0383\n",
      "epoch 6 batch 55/185 loss = 0.0362\n",
      "epoch 6 batch 56/185 loss = 0.0337\n",
      "epoch 6 batch 57/185 loss = 0.0400\n",
      "epoch 6 batch 58/185 loss = 0.0328\n",
      "epoch 6 batch 59/185 loss = 0.0369\n",
      "epoch 6 batch 60/185 loss = 0.0383\n",
      "epoch 6 batch 61/185 loss = 0.0345\n",
      "epoch 6 batch 62/185 loss = 0.0364\n",
      "epoch 6 batch 63/185 loss = 0.0299\n",
      "epoch 6 batch 64/185 loss = 0.0353\n",
      "epoch 6 batch 65/185 loss = 0.0334\n",
      "epoch 6 batch 66/185 loss = 0.0354\n",
      "epoch 6 batch 67/185 loss = 0.0369\n",
      "epoch 6 batch 68/185 loss = 0.0331\n",
      "epoch 6 batch 69/185 loss = 0.0331\n",
      "epoch 6 batch 70/185 loss = 0.0327\n",
      "epoch 6 batch 71/185 loss = 0.0326\n",
      "epoch 6 batch 72/185 loss = 0.0366\n",
      "epoch 6 batch 73/185 loss = 0.0359\n",
      "epoch 6 batch 74/185 loss = 0.0305\n",
      "epoch 6 batch 75/185 loss = 0.0316\n",
      "epoch 6 batch 76/185 loss = 0.0394\n",
      "epoch 6 batch 77/185 loss = 0.0359\n",
      "epoch 6 batch 78/185 loss = 0.0362\n",
      "epoch 6 batch 79/185 loss = 0.0322\n",
      "epoch 6 batch 80/185 loss = 0.0341\n",
      "epoch 6 batch 81/185 loss = 0.0311\n",
      "epoch 6 batch 82/185 loss = 0.0315\n",
      "epoch 6 batch 83/185 loss = 0.0335\n",
      "epoch 6 batch 84/185 loss = 0.0289\n",
      "epoch 6 batch 85/185 loss = 0.0333\n",
      "epoch 6 batch 86/185 loss = 0.0311\n",
      "epoch 6 batch 87/185 loss = 0.0356\n",
      "epoch 6 batch 88/185 loss = 0.0352\n",
      "epoch 6 batch 89/185 loss = 0.0354\n",
      "epoch 6 batch 90/185 loss = 0.0350\n",
      "epoch 6 batch 91/185 loss = 0.0292\n",
      "epoch 6 batch 92/185 loss = 0.0319\n",
      "epoch 6 batch 93/185 loss = 0.0274\n",
      "epoch 6 batch 94/185 loss = 0.0295\n",
      "epoch 6 batch 95/185 loss = 0.0286\n",
      "epoch 6 batch 96/185 loss = 0.0334\n",
      "epoch 6 batch 97/185 loss = 0.0369\n",
      "epoch 6 batch 98/185 loss = 0.0323\n",
      "epoch 6 batch 99/185 loss = 0.0349\n",
      "epoch 6 batch 100/185 loss = 0.0287\n",
      "epoch 6 batch 101/185 loss = 0.0297\n",
      "epoch 6 batch 102/185 loss = 0.0269\n",
      "epoch 6 batch 103/185 loss = 0.0314\n",
      "epoch 6 batch 104/185 loss = 0.0288\n",
      "epoch 6 batch 105/185 loss = 0.0306\n",
      "epoch 6 batch 106/185 loss = 0.0317\n",
      "epoch 6 batch 107/185 loss = 0.0291\n",
      "epoch 6 batch 108/185 loss = 0.0306\n",
      "epoch 6 batch 109/185 loss = 0.0321\n",
      "epoch 6 batch 110/185 loss = 0.0286\n",
      "epoch 6 batch 111/185 loss = 0.0272\n",
      "epoch 6 batch 112/185 loss = 0.0309\n",
      "epoch 6 batch 113/185 loss = 0.0323\n",
      "epoch 6 batch 114/185 loss = 0.0333\n",
      "epoch 6 batch 115/185 loss = 0.0357\n",
      "epoch 6 batch 116/185 loss = 0.0321\n",
      "epoch 6 batch 117/185 loss = 0.0317\n",
      "epoch 6 batch 118/185 loss = 0.0318\n",
      "epoch 6 batch 119/185 loss = 0.0283\n",
      "epoch 6 batch 120/185 loss = 0.0264\n",
      "epoch 6 batch 121/185 loss = 0.0277\n",
      "epoch 6 batch 122/185 loss = 0.0297\n",
      "epoch 6 batch 123/185 loss = 0.0318\n",
      "epoch 6 batch 124/185 loss = 0.0291\n",
      "epoch 6 batch 125/185 loss = 0.0263\n",
      "epoch 6 batch 126/185 loss = 0.0318\n",
      "epoch 6 batch 127/185 loss = 0.0298\n",
      "epoch 6 batch 128/185 loss = 0.0310\n",
      "epoch 6 batch 129/185 loss = 0.0252\n",
      "epoch 6 batch 130/185 loss = 0.0265\n",
      "epoch 6 batch 131/185 loss = 0.0332\n",
      "epoch 6 batch 132/185 loss = 0.0263\n",
      "epoch 6 batch 133/185 loss = 0.0256\n",
      "epoch 6 batch 134/185 loss = 0.0274\n",
      "epoch 6 batch 135/185 loss = 0.0251\n",
      "epoch 6 batch 136/185 loss = 0.0240\n",
      "epoch 6 batch 137/185 loss = 0.0253\n",
      "epoch 6 batch 138/185 loss = 0.0274\n",
      "epoch 6 batch 139/185 loss = 0.0281\n",
      "epoch 6 batch 140/185 loss = 0.0288\n",
      "epoch 6 batch 141/185 loss = 0.0260\n",
      "epoch 6 batch 142/185 loss = 0.0257\n",
      "epoch 6 batch 143/185 loss = 0.0273\n",
      "epoch 6 batch 144/185 loss = 0.0256\n",
      "epoch 6 batch 145/185 loss = 0.0290\n",
      "epoch 6 batch 146/185 loss = 0.0257\n",
      "epoch 6 batch 147/185 loss = 0.0249\n",
      "epoch 6 batch 148/185 loss = 0.0265\n",
      "epoch 6 batch 149/185 loss = 0.0240\n",
      "epoch 6 batch 150/185 loss = 0.0222\n",
      "epoch 6 batch 151/185 loss = 0.0221\n",
      "epoch 6 batch 152/185 loss = 0.0283\n",
      "epoch 6 batch 153/185 loss = 0.0293\n",
      "epoch 6 batch 154/185 loss = 0.0279\n",
      "epoch 6 batch 155/185 loss = 0.0266\n",
      "epoch 6 batch 156/185 loss = 0.0306\n",
      "epoch 6 batch 157/185 loss = 0.0227\n",
      "epoch 6 batch 158/185 loss = 0.0253\n",
      "epoch 6 batch 159/185 loss = 0.0246\n",
      "epoch 6 batch 160/185 loss = 0.0217\n",
      "epoch 6 batch 161/185 loss = 0.0279\n",
      "epoch 6 batch 162/185 loss = 0.0253\n",
      "epoch 6 batch 163/185 loss = 0.0244\n",
      "epoch 6 batch 164/185 loss = 0.0230\n",
      "epoch 6 batch 165/185 loss = 0.0220\n",
      "epoch 6 batch 166/185 loss = 0.0260\n",
      "epoch 6 batch 167/185 loss = 0.0289\n",
      "epoch 6 batch 168/185 loss = 0.0274\n",
      "epoch 6 batch 169/185 loss = 0.0235\n",
      "epoch 6 batch 170/185 loss = 0.0227\n",
      "epoch 6 batch 171/185 loss = 0.0290\n",
      "epoch 6 batch 172/185 loss = 0.0267\n",
      "epoch 6 batch 173/185 loss = 0.0271\n",
      "epoch 6 batch 174/185 loss = 0.0258\n",
      "epoch 6 batch 175/185 loss = 0.0247\n",
      "epoch 6 batch 176/185 loss = 0.0251\n",
      "epoch 6 batch 177/185 loss = 0.0251\n",
      "epoch 6 batch 178/185 loss = 0.0218\n",
      "epoch 6 batch 179/185 loss = 0.0248\n",
      "epoch 6 batch 180/185 loss = 0.0257\n",
      "epoch 6 batch 181/185 loss = 0.0239\n",
      "epoch 6 batch 182/185 loss = 0.0233\n",
      "epoch 6 batch 183/185 loss = 0.0298\n",
      "epoch 6 batch 184/185 loss = 0.0220\n",
      "epoch 6 batch 185/185 loss = 0.0269\n",
      "epoch 6 train loss = 0.0326 valid loss = 0.0287\n",
      "epoch 7 batch 1/185 loss = 0.0229\n",
      "epoch 7 batch 2/185 loss = 0.0229\n",
      "epoch 7 batch 3/185 loss = 0.0218\n",
      "epoch 7 batch 4/185 loss = 0.0244\n",
      "epoch 7 batch 5/185 loss = 0.0256\n",
      "epoch 7 batch 6/185 loss = 0.0243\n",
      "epoch 7 batch 7/185 loss = 0.0242\n",
      "epoch 7 batch 8/185 loss = 0.0218\n",
      "epoch 7 batch 9/185 loss = 0.0238\n",
      "epoch 7 batch 10/185 loss = 0.0199\n",
      "epoch 7 batch 11/185 loss = 0.0227\n",
      "epoch 7 batch 12/185 loss = 0.0254\n",
      "epoch 7 batch 13/185 loss = 0.0231\n",
      "epoch 7 batch 14/185 loss = 0.0210\n",
      "epoch 7 batch 15/185 loss = 0.0243\n",
      "epoch 7 batch 16/185 loss = 0.0245\n",
      "epoch 7 batch 17/185 loss = 0.0255\n",
      "epoch 7 batch 18/185 loss = 0.0210\n",
      "epoch 7 batch 19/185 loss = 0.0244\n",
      "epoch 7 batch 20/185 loss = 0.0243\n",
      "epoch 7 batch 21/185 loss = 0.0192\n",
      "epoch 7 batch 22/185 loss = 0.0215\n",
      "epoch 7 batch 23/185 loss = 0.0239\n",
      "epoch 7 batch 24/185 loss = 0.0241\n",
      "epoch 7 batch 25/185 loss = 0.0231\n",
      "epoch 7 batch 26/185 loss = 0.0244\n",
      "epoch 7 batch 27/185 loss = 0.0212\n",
      "epoch 7 batch 28/185 loss = 0.0214\n",
      "epoch 7 batch 29/185 loss = 0.0234\n",
      "epoch 7 batch 30/185 loss = 0.0226\n",
      "epoch 7 batch 31/185 loss = 0.0232\n",
      "epoch 7 batch 32/185 loss = 0.0186\n",
      "epoch 7 batch 33/185 loss = 0.0224\n",
      "epoch 7 batch 34/185 loss = 0.0217\n",
      "epoch 7 batch 35/185 loss = 0.0219\n",
      "epoch 7 batch 36/185 loss = 0.0269\n",
      "epoch 7 batch 37/185 loss = 0.0210\n",
      "epoch 7 batch 38/185 loss = 0.0193\n",
      "epoch 7 batch 39/185 loss = 0.0204\n",
      "epoch 7 batch 40/185 loss = 0.0255\n",
      "epoch 7 batch 41/185 loss = 0.0218\n",
      "epoch 7 batch 42/185 loss = 0.0175\n",
      "epoch 7 batch 43/185 loss = 0.0200\n",
      "epoch 7 batch 44/185 loss = 0.0248\n",
      "epoch 7 batch 45/185 loss = 0.0206\n",
      "epoch 7 batch 46/185 loss = 0.0211\n",
      "epoch 7 batch 47/185 loss = 0.0194\n",
      "epoch 7 batch 48/185 loss = 0.0239\n",
      "epoch 7 batch 49/185 loss = 0.0178\n",
      "epoch 7 batch 50/185 loss = 0.0210\n",
      "epoch 7 batch 51/185 loss = 0.0209\n",
      "epoch 7 batch 52/185 loss = 0.0194\n",
      "epoch 7 batch 53/185 loss = 0.0197\n",
      "epoch 7 batch 54/185 loss = 0.0223\n",
      "epoch 7 batch 55/185 loss = 0.0215\n",
      "epoch 7 batch 56/185 loss = 0.0165\n",
      "epoch 7 batch 57/185 loss = 0.0198\n",
      "epoch 7 batch 58/185 loss = 0.0202\n",
      "epoch 7 batch 59/185 loss = 0.0216\n",
      "epoch 7 batch 60/185 loss = 0.0229\n",
      "epoch 7 batch 61/185 loss = 0.0227\n",
      "epoch 7 batch 62/185 loss = 0.0198\n",
      "epoch 7 batch 63/185 loss = 0.0224\n",
      "epoch 7 batch 64/185 loss = 0.0215\n",
      "epoch 7 batch 65/185 loss = 0.0242\n",
      "epoch 7 batch 66/185 loss = 0.0229\n",
      "epoch 7 batch 67/185 loss = 0.0194\n",
      "epoch 7 batch 68/185 loss = 0.0188\n",
      "epoch 7 batch 69/185 loss = 0.0175\n",
      "epoch 7 batch 70/185 loss = 0.0198\n",
      "epoch 7 batch 71/185 loss = 0.0215\n",
      "epoch 7 batch 72/185 loss = 0.0221\n",
      "epoch 7 batch 73/185 loss = 0.0225\n",
      "epoch 7 batch 74/185 loss = 0.0240\n",
      "epoch 7 batch 75/185 loss = 0.0198\n",
      "epoch 7 batch 76/185 loss = 0.0179\n",
      "epoch 7 batch 77/185 loss = 0.0284\n",
      "epoch 7 batch 78/185 loss = 0.0183\n",
      "epoch 7 batch 79/185 loss = 0.0228\n",
      "epoch 7 batch 80/185 loss = 0.0187\n",
      "epoch 7 batch 81/185 loss = 0.0182\n",
      "epoch 7 batch 82/185 loss = 0.0189\n",
      "epoch 7 batch 83/185 loss = 0.0218\n",
      "epoch 7 batch 84/185 loss = 0.0207\n",
      "epoch 7 batch 85/185 loss = 0.0195\n",
      "epoch 7 batch 86/185 loss = 0.0167\n",
      "epoch 7 batch 87/185 loss = 0.0219\n",
      "epoch 7 batch 88/185 loss = 0.0198\n",
      "epoch 7 batch 89/185 loss = 0.0192\n",
      "epoch 7 batch 90/185 loss = 0.0177\n",
      "epoch 7 batch 91/185 loss = 0.0190\n",
      "epoch 7 batch 92/185 loss = 0.0187\n",
      "epoch 7 batch 93/185 loss = 0.0214\n",
      "epoch 7 batch 94/185 loss = 0.0172\n",
      "epoch 7 batch 95/185 loss = 0.0172\n",
      "epoch 7 batch 96/185 loss = 0.0177\n",
      "epoch 7 batch 97/185 loss = 0.0193\n",
      "epoch 7 batch 98/185 loss = 0.0209\n",
      "epoch 7 batch 99/185 loss = 0.0201\n",
      "epoch 7 batch 100/185 loss = 0.0209\n",
      "epoch 7 batch 101/185 loss = 0.0166\n",
      "epoch 7 batch 102/185 loss = 0.0156\n",
      "epoch 7 batch 103/185 loss = 0.0186\n",
      "epoch 7 batch 104/185 loss = 0.0196\n",
      "epoch 7 batch 105/185 loss = 0.0160\n",
      "epoch 7 batch 106/185 loss = 0.0174\n",
      "epoch 7 batch 107/185 loss = 0.0160\n",
      "epoch 7 batch 108/185 loss = 0.0181\n",
      "epoch 7 batch 109/185 loss = 0.0194\n",
      "epoch 7 batch 110/185 loss = 0.0202\n",
      "epoch 7 batch 111/185 loss = 0.0166\n",
      "epoch 7 batch 112/185 loss = 0.0196\n",
      "epoch 7 batch 113/185 loss = 0.0173\n",
      "epoch 7 batch 114/185 loss = 0.0155\n",
      "epoch 7 batch 115/185 loss = 0.0186\n",
      "epoch 7 batch 116/185 loss = 0.0209\n",
      "epoch 7 batch 117/185 loss = 0.0157\n",
      "epoch 7 batch 118/185 loss = 0.0215\n",
      "epoch 7 batch 119/185 loss = 0.0201\n",
      "epoch 7 batch 120/185 loss = 0.0183\n",
      "epoch 7 batch 121/185 loss = 0.0184\n",
      "epoch 7 batch 122/185 loss = 0.0150\n",
      "epoch 7 batch 123/185 loss = 0.0194\n",
      "epoch 7 batch 124/185 loss = 0.0173\n",
      "epoch 7 batch 125/185 loss = 0.0185\n",
      "epoch 7 batch 126/185 loss = 0.0227\n",
      "epoch 7 batch 127/185 loss = 0.0202\n",
      "epoch 7 batch 128/185 loss = 0.0169\n",
      "epoch 7 batch 129/185 loss = 0.0190\n",
      "epoch 7 batch 130/185 loss = 0.0157\n",
      "epoch 7 batch 131/185 loss = 0.0147\n",
      "epoch 7 batch 132/185 loss = 0.0152\n",
      "epoch 7 batch 133/185 loss = 0.0193\n",
      "epoch 7 batch 134/185 loss = 0.0179\n",
      "epoch 7 batch 135/185 loss = 0.0198\n",
      "epoch 7 batch 136/185 loss = 0.0206\n",
      "epoch 7 batch 137/185 loss = 0.0171\n",
      "epoch 7 batch 138/185 loss = 0.0220\n",
      "epoch 7 batch 139/185 loss = 0.0159\n",
      "epoch 7 batch 140/185 loss = 0.0197\n",
      "epoch 7 batch 141/185 loss = 0.0149\n",
      "epoch 7 batch 142/185 loss = 0.0188\n",
      "epoch 7 batch 143/185 loss = 0.0182\n",
      "epoch 7 batch 144/185 loss = 0.0171\n",
      "epoch 7 batch 145/185 loss = 0.0202\n",
      "epoch 7 batch 146/185 loss = 0.0177\n",
      "epoch 7 batch 147/185 loss = 0.0174\n",
      "epoch 7 batch 148/185 loss = 0.0163\n",
      "epoch 7 batch 149/185 loss = 0.0187\n",
      "epoch 7 batch 150/185 loss = 0.0163\n",
      "epoch 7 batch 151/185 loss = 0.0238\n",
      "epoch 7 batch 152/185 loss = 0.0192\n",
      "epoch 7 batch 153/185 loss = 0.0190\n",
      "epoch 7 batch 154/185 loss = 0.0169\n",
      "epoch 7 batch 155/185 loss = 0.0161\n",
      "epoch 7 batch 156/185 loss = 0.0131\n",
      "epoch 7 batch 157/185 loss = 0.0200\n",
      "epoch 7 batch 158/185 loss = 0.0196\n",
      "epoch 7 batch 159/185 loss = 0.0175\n",
      "epoch 7 batch 160/185 loss = 0.0158\n",
      "epoch 7 batch 161/185 loss = 0.0154\n",
      "epoch 7 batch 162/185 loss = 0.0160\n",
      "epoch 7 batch 163/185 loss = 0.0203\n",
      "epoch 7 batch 164/185 loss = 0.0182\n",
      "epoch 7 batch 165/185 loss = 0.0167\n",
      "epoch 7 batch 166/185 loss = 0.0199\n",
      "epoch 7 batch 167/185 loss = 0.0162\n",
      "epoch 7 batch 168/185 loss = 0.0135\n",
      "epoch 7 batch 169/185 loss = 0.0181\n",
      "epoch 7 batch 170/185 loss = 0.0129\n",
      "epoch 7 batch 171/185 loss = 0.0151\n",
      "epoch 7 batch 172/185 loss = 0.0174\n",
      "epoch 7 batch 173/185 loss = 0.0149\n",
      "epoch 7 batch 174/185 loss = 0.0155\n",
      "epoch 7 batch 175/185 loss = 0.0190\n",
      "epoch 7 batch 176/185 loss = 0.0160\n",
      "epoch 7 batch 177/185 loss = 0.0138\n",
      "epoch 7 batch 178/185 loss = 0.0174\n",
      "epoch 7 batch 179/185 loss = 0.0165\n",
      "epoch 7 batch 180/185 loss = 0.0152\n",
      "epoch 7 batch 181/185 loss = 0.0157\n",
      "epoch 7 batch 182/185 loss = 0.0153\n",
      "epoch 7 batch 183/185 loss = 0.0165\n",
      "epoch 7 batch 184/185 loss = 0.0160\n",
      "epoch 7 batch 185/185 loss = 0.0161\n",
      "epoch 7 train loss = 0.0196 valid loss = 0.0170\n",
      "epoch 8 batch 1/185 loss = 0.0146\n",
      "epoch 8 batch 2/185 loss = 0.0150\n",
      "epoch 8 batch 3/185 loss = 0.0154\n",
      "epoch 8 batch 4/185 loss = 0.0139\n",
      "epoch 8 batch 5/185 loss = 0.0145\n",
      "epoch 8 batch 6/185 loss = 0.0133\n",
      "epoch 8 batch 7/185 loss = 0.0133\n",
      "epoch 8 batch 8/185 loss = 0.0184\n",
      "epoch 8 batch 9/185 loss = 0.0157\n",
      "epoch 8 batch 10/185 loss = 0.0198\n",
      "epoch 8 batch 11/185 loss = 0.0191\n",
      "epoch 8 batch 12/185 loss = 0.0155\n",
      "epoch 8 batch 13/185 loss = 0.0152\n",
      "epoch 8 batch 14/185 loss = 0.0143\n",
      "epoch 8 batch 15/185 loss = 0.0167\n",
      "epoch 8 batch 16/185 loss = 0.0159\n",
      "epoch 8 batch 17/185 loss = 0.0151\n",
      "epoch 8 batch 18/185 loss = 0.0158\n",
      "epoch 8 batch 19/185 loss = 0.0133\n",
      "epoch 8 batch 20/185 loss = 0.0166\n",
      "epoch 8 batch 21/185 loss = 0.0145\n",
      "epoch 8 batch 22/185 loss = 0.0180\n",
      "epoch 8 batch 23/185 loss = 0.0120\n",
      "epoch 8 batch 24/185 loss = 0.0171\n",
      "epoch 8 batch 25/185 loss = 0.0151\n",
      "epoch 8 batch 26/185 loss = 0.0142\n",
      "epoch 8 batch 27/185 loss = 0.0141\n",
      "epoch 8 batch 28/185 loss = 0.0173\n",
      "epoch 8 batch 29/185 loss = 0.0161\n",
      "epoch 8 batch 30/185 loss = 0.0154\n",
      "epoch 8 batch 31/185 loss = 0.0138\n",
      "epoch 8 batch 32/185 loss = 0.0113\n",
      "epoch 8 batch 33/185 loss = 0.0140\n",
      "epoch 8 batch 34/185 loss = 0.0147\n",
      "epoch 8 batch 35/185 loss = 0.0134\n",
      "epoch 8 batch 36/185 loss = 0.0129\n",
      "epoch 8 batch 37/185 loss = 0.0138\n",
      "epoch 8 batch 38/185 loss = 0.0150\n",
      "epoch 8 batch 39/185 loss = 0.0149\n",
      "epoch 8 batch 40/185 loss = 0.0194\n",
      "epoch 8 batch 41/185 loss = 0.0162\n",
      "epoch 8 batch 42/185 loss = 0.0176\n",
      "epoch 8 batch 43/185 loss = 0.0166\n",
      "epoch 8 batch 44/185 loss = 0.0145\n",
      "epoch 8 batch 45/185 loss = 0.0165\n",
      "epoch 8 batch 46/185 loss = 0.0135\n",
      "epoch 8 batch 47/185 loss = 0.0166\n",
      "epoch 8 batch 48/185 loss = 0.0121\n",
      "epoch 8 batch 49/185 loss = 0.0112\n",
      "epoch 8 batch 50/185 loss = 0.0137\n",
      "epoch 8 batch 51/185 loss = 0.0144\n",
      "epoch 8 batch 52/185 loss = 0.0155\n",
      "epoch 8 batch 53/185 loss = 0.0132\n",
      "epoch 8 batch 54/185 loss = 0.0114\n",
      "epoch 8 batch 55/185 loss = 0.0176\n",
      "epoch 8 batch 56/185 loss = 0.0152\n",
      "epoch 8 batch 57/185 loss = 0.0133\n",
      "epoch 8 batch 58/185 loss = 0.0135\n",
      "epoch 8 batch 59/185 loss = 0.0161\n",
      "epoch 8 batch 60/185 loss = 0.0122\n",
      "epoch 8 batch 61/185 loss = 0.0145\n",
      "epoch 8 batch 62/185 loss = 0.0161\n",
      "epoch 8 batch 63/185 loss = 0.0145\n",
      "epoch 8 batch 64/185 loss = 0.0123\n",
      "epoch 8 batch 65/185 loss = 0.0144\n",
      "epoch 8 batch 66/185 loss = 0.0152\n",
      "epoch 8 batch 67/185 loss = 0.0166\n",
      "epoch 8 batch 68/185 loss = 0.0151\n",
      "epoch 8 batch 69/185 loss = 0.0113\n",
      "epoch 8 batch 70/185 loss = 0.0144\n",
      "epoch 8 batch 71/185 loss = 0.0149\n",
      "epoch 8 batch 72/185 loss = 0.0129\n",
      "epoch 8 batch 73/185 loss = 0.0136\n",
      "epoch 8 batch 74/185 loss = 0.0124\n",
      "epoch 8 batch 75/185 loss = 0.0132\n",
      "epoch 8 batch 76/185 loss = 0.0132\n",
      "epoch 8 batch 77/185 loss = 0.0097\n",
      "epoch 8 batch 78/185 loss = 0.0138\n",
      "epoch 8 batch 79/185 loss = 0.0159\n",
      "epoch 8 batch 80/185 loss = 0.0154\n",
      "epoch 8 batch 81/185 loss = 0.0150\n",
      "epoch 8 batch 82/185 loss = 0.0121\n",
      "epoch 8 batch 83/185 loss = 0.0154\n",
      "epoch 8 batch 84/185 loss = 0.0152\n",
      "epoch 8 batch 85/185 loss = 0.0169\n",
      "epoch 8 batch 86/185 loss = 0.0140\n",
      "epoch 8 batch 87/185 loss = 0.0176\n",
      "epoch 8 batch 88/185 loss = 0.0138\n",
      "epoch 8 batch 89/185 loss = 0.0162\n",
      "epoch 8 batch 90/185 loss = 0.0115\n",
      "epoch 8 batch 91/185 loss = 0.0109\n",
      "epoch 8 batch 92/185 loss = 0.0127\n",
      "epoch 8 batch 93/185 loss = 0.0119\n",
      "epoch 8 batch 94/185 loss = 0.0149\n",
      "epoch 8 batch 95/185 loss = 0.0139\n",
      "epoch 8 batch 96/185 loss = 0.0160\n",
      "epoch 8 batch 97/185 loss = 0.0118\n",
      "epoch 8 batch 98/185 loss = 0.0129\n",
      "epoch 8 batch 99/185 loss = 0.0134\n",
      "epoch 8 batch 100/185 loss = 0.0117\n",
      "epoch 8 batch 101/185 loss = 0.0163\n",
      "epoch 8 batch 102/185 loss = 0.0141\n",
      "epoch 8 batch 103/185 loss = 0.0145\n",
      "epoch 8 batch 104/185 loss = 0.0137\n",
      "epoch 8 batch 105/185 loss = 0.0111\n",
      "epoch 8 batch 106/185 loss = 0.0156\n",
      "epoch 8 batch 107/185 loss = 0.0117\n",
      "epoch 8 batch 108/185 loss = 0.0127\n",
      "epoch 8 batch 109/185 loss = 0.0112\n",
      "epoch 8 batch 110/185 loss = 0.0100\n",
      "epoch 8 batch 111/185 loss = 0.0121\n",
      "epoch 8 batch 112/185 loss = 0.0131\n",
      "epoch 8 batch 113/185 loss = 0.0122\n",
      "epoch 8 batch 114/185 loss = 0.0106\n",
      "epoch 8 batch 115/185 loss = 0.0122\n",
      "epoch 8 batch 116/185 loss = 0.0139\n",
      "epoch 8 batch 117/185 loss = 0.0152\n",
      "epoch 8 batch 118/185 loss = 0.0127\n",
      "epoch 8 batch 119/185 loss = 0.0106\n",
      "epoch 8 batch 120/185 loss = 0.0144\n",
      "epoch 8 batch 121/185 loss = 0.0129\n",
      "epoch 8 batch 122/185 loss = 0.0147\n",
      "epoch 8 batch 123/185 loss = 0.0126\n",
      "epoch 8 batch 124/185 loss = 0.0141\n",
      "epoch 8 batch 125/185 loss = 0.0148\n",
      "epoch 8 batch 126/185 loss = 0.0101\n",
      "epoch 8 batch 127/185 loss = 0.0152\n",
      "epoch 8 batch 128/185 loss = 0.0153\n",
      "epoch 8 batch 129/185 loss = 0.0146\n",
      "epoch 8 batch 130/185 loss = 0.0116\n",
      "epoch 8 batch 131/185 loss = 0.0151\n",
      "epoch 8 batch 132/185 loss = 0.0136\n",
      "epoch 8 batch 133/185 loss = 0.0135\n",
      "epoch 8 batch 134/185 loss = 0.0136\n",
      "epoch 8 batch 135/185 loss = 0.0153\n",
      "epoch 8 batch 136/185 loss = 0.0115\n",
      "epoch 8 batch 137/185 loss = 0.0143\n",
      "epoch 8 batch 138/185 loss = 0.0150\n",
      "epoch 8 batch 139/185 loss = 0.0129\n",
      "epoch 8 batch 140/185 loss = 0.0136\n",
      "epoch 8 batch 141/185 loss = 0.0134\n",
      "epoch 8 batch 142/185 loss = 0.0138\n",
      "epoch 8 batch 143/185 loss = 0.0142\n",
      "epoch 8 batch 144/185 loss = 0.0139\n",
      "epoch 8 batch 145/185 loss = 0.0126\n",
      "epoch 8 batch 146/185 loss = 0.0127\n",
      "epoch 8 batch 147/185 loss = 0.0134\n",
      "epoch 8 batch 148/185 loss = 0.0122\n",
      "epoch 8 batch 149/185 loss = 0.0154\n",
      "epoch 8 batch 150/185 loss = 0.0140\n",
      "epoch 8 batch 151/185 loss = 0.0146\n",
      "epoch 8 batch 152/185 loss = 0.0118\n",
      "epoch 8 batch 153/185 loss = 0.0128\n",
      "epoch 8 batch 154/185 loss = 0.0164\n",
      "epoch 8 batch 155/185 loss = 0.0157\n",
      "epoch 8 batch 156/185 loss = 0.0123\n",
      "epoch 8 batch 157/185 loss = 0.0154\n",
      "epoch 8 batch 158/185 loss = 0.0152\n",
      "epoch 8 batch 159/185 loss = 0.0168\n",
      "epoch 8 batch 160/185 loss = 0.0141\n",
      "epoch 8 batch 161/185 loss = 0.0116\n",
      "epoch 8 batch 162/185 loss = 0.0117\n",
      "epoch 8 batch 163/185 loss = 0.0124\n",
      "epoch 8 batch 164/185 loss = 0.0128\n",
      "epoch 8 batch 165/185 loss = 0.0138\n",
      "epoch 8 batch 166/185 loss = 0.0109\n",
      "epoch 8 batch 167/185 loss = 0.0143\n",
      "epoch 8 batch 168/185 loss = 0.0112\n",
      "epoch 8 batch 169/185 loss = 0.0152\n",
      "epoch 8 batch 170/185 loss = 0.0135\n",
      "epoch 8 batch 171/185 loss = 0.0118\n",
      "epoch 8 batch 172/185 loss = 0.0129\n",
      "epoch 8 batch 173/185 loss = 0.0140\n",
      "epoch 8 batch 174/185 loss = 0.0173\n",
      "epoch 8 batch 175/185 loss = 0.0120\n",
      "epoch 8 batch 176/185 loss = 0.0189\n",
      "epoch 8 batch 177/185 loss = 0.0168\n",
      "epoch 8 batch 178/185 loss = 0.0141\n",
      "epoch 8 batch 179/185 loss = 0.0123\n",
      "epoch 8 batch 180/185 loss = 0.0098\n",
      "epoch 8 batch 181/185 loss = 0.0130\n",
      "epoch 8 batch 182/185 loss = 0.0126\n",
      "epoch 8 batch 183/185 loss = 0.0145\n",
      "epoch 8 batch 184/185 loss = 0.0146\n",
      "epoch 8 batch 185/185 loss = 0.0119\n",
      "epoch 8 train loss = 0.0141 valid loss = 0.0140\n",
      "epoch 9 batch 1/185 loss = 0.0115\n",
      "epoch 9 batch 2/185 loss = 0.0128\n",
      "epoch 9 batch 3/185 loss = 0.0140\n",
      "epoch 9 batch 4/185 loss = 0.0118\n",
      "epoch 9 batch 5/185 loss = 0.0171\n",
      "epoch 9 batch 6/185 loss = 0.0115\n",
      "epoch 9 batch 7/185 loss = 0.0111\n",
      "epoch 9 batch 8/185 loss = 0.0111\n",
      "epoch 9 batch 9/185 loss = 0.0118\n",
      "epoch 9 batch 10/185 loss = 0.0147\n",
      "epoch 9 batch 11/185 loss = 0.0136\n",
      "epoch 9 batch 12/185 loss = 0.0125\n",
      "epoch 9 batch 13/185 loss = 0.0113\n",
      "epoch 9 batch 14/185 loss = 0.0130\n",
      "epoch 9 batch 15/185 loss = 0.0125\n",
      "epoch 9 batch 16/185 loss = 0.0125\n",
      "epoch 9 batch 17/185 loss = 0.0101\n",
      "epoch 9 batch 18/185 loss = 0.0125\n",
      "epoch 9 batch 19/185 loss = 0.0124\n",
      "epoch 9 batch 20/185 loss = 0.0149\n",
      "epoch 9 batch 21/185 loss = 0.0160\n",
      "epoch 9 batch 22/185 loss = 0.0113\n",
      "epoch 9 batch 23/185 loss = 0.0108\n",
      "epoch 9 batch 24/185 loss = 0.0113\n",
      "epoch 9 batch 25/185 loss = 0.0120\n",
      "epoch 9 batch 26/185 loss = 0.0126\n",
      "epoch 9 batch 27/185 loss = 0.0118\n",
      "epoch 9 batch 28/185 loss = 0.0118\n",
      "epoch 9 batch 29/185 loss = 0.0100\n",
      "epoch 9 batch 30/185 loss = 0.0099\n",
      "epoch 9 batch 31/185 loss = 0.0119\n",
      "epoch 9 batch 32/185 loss = 0.0113\n",
      "epoch 9 batch 33/185 loss = 0.0107\n",
      "epoch 9 batch 34/185 loss = 0.0117\n",
      "epoch 9 batch 35/185 loss = 0.0119\n",
      "epoch 9 batch 36/185 loss = 0.0155\n",
      "epoch 9 batch 37/185 loss = 0.0139\n",
      "epoch 9 batch 38/185 loss = 0.0114\n",
      "epoch 9 batch 39/185 loss = 0.0097\n",
      "epoch 9 batch 40/185 loss = 0.0119\n",
      "epoch 9 batch 41/185 loss = 0.0099\n",
      "epoch 9 batch 42/185 loss = 0.0101\n",
      "epoch 9 batch 43/185 loss = 0.0123\n",
      "epoch 9 batch 44/185 loss = 0.0154\n",
      "epoch 9 batch 45/185 loss = 0.0157\n",
      "epoch 9 batch 46/185 loss = 0.0114\n",
      "epoch 9 batch 47/185 loss = 0.0114\n",
      "epoch 9 batch 48/185 loss = 0.0128\n",
      "epoch 9 batch 49/185 loss = 0.0151\n",
      "epoch 9 batch 50/185 loss = 0.0127\n",
      "epoch 9 batch 51/185 loss = 0.0123\n",
      "epoch 9 batch 52/185 loss = 0.0099\n",
      "epoch 9 batch 53/185 loss = 0.0127\n",
      "epoch 9 batch 54/185 loss = 0.0116\n",
      "epoch 9 batch 55/185 loss = 0.0132\n",
      "epoch 9 batch 56/185 loss = 0.0153\n",
      "epoch 9 batch 57/185 loss = 0.0146\n",
      "epoch 9 batch 58/185 loss = 0.0138\n",
      "epoch 9 batch 59/185 loss = 0.0117\n",
      "epoch 9 batch 60/185 loss = 0.0134\n",
      "epoch 9 batch 61/185 loss = 0.0133\n",
      "epoch 9 batch 62/185 loss = 0.0102\n",
      "epoch 9 batch 63/185 loss = 0.0110\n",
      "epoch 9 batch 64/185 loss = 0.0140\n",
      "epoch 9 batch 65/185 loss = 0.0124\n",
      "epoch 9 batch 66/185 loss = 0.0142\n",
      "epoch 9 batch 67/185 loss = 0.0127\n",
      "epoch 9 batch 68/185 loss = 0.0125\n",
      "epoch 9 batch 69/185 loss = 0.0134\n",
      "epoch 9 batch 70/185 loss = 0.0128\n",
      "epoch 9 batch 71/185 loss = 0.0110\n",
      "epoch 9 batch 72/185 loss = 0.0098\n",
      "epoch 9 batch 73/185 loss = 0.0132\n",
      "epoch 9 batch 74/185 loss = 0.0086\n",
      "epoch 9 batch 75/185 loss = 0.0104\n",
      "epoch 9 batch 76/185 loss = 0.0125\n",
      "epoch 9 batch 77/185 loss = 0.0108\n",
      "epoch 9 batch 78/185 loss = 0.0137\n",
      "epoch 9 batch 79/185 loss = 0.0118\n",
      "epoch 9 batch 80/185 loss = 0.0106\n",
      "epoch 9 batch 81/185 loss = 0.0102\n",
      "epoch 9 batch 82/185 loss = 0.0116\n",
      "epoch 9 batch 83/185 loss = 0.0130\n",
      "epoch 9 batch 84/185 loss = 0.0095\n",
      "epoch 9 batch 85/185 loss = 0.0119\n",
      "epoch 9 batch 86/185 loss = 0.0121\n",
      "epoch 9 batch 87/185 loss = 0.0099\n",
      "epoch 9 batch 88/185 loss = 0.0101\n",
      "epoch 9 batch 89/185 loss = 0.0127\n",
      "epoch 9 batch 90/185 loss = 0.0118\n",
      "epoch 9 batch 91/185 loss = 0.0106\n",
      "epoch 9 batch 92/185 loss = 0.0154\n",
      "epoch 9 batch 93/185 loss = 0.0106\n",
      "epoch 9 batch 94/185 loss = 0.0103\n",
      "epoch 9 batch 95/185 loss = 0.0107\n",
      "epoch 9 batch 96/185 loss = 0.0109\n",
      "epoch 9 batch 97/185 loss = 0.0143\n",
      "epoch 9 batch 98/185 loss = 0.0107\n",
      "epoch 9 batch 99/185 loss = 0.0136\n",
      "epoch 9 batch 100/185 loss = 0.0148\n",
      "epoch 9 batch 101/185 loss = 0.0114\n",
      "epoch 9 batch 102/185 loss = 0.0147\n",
      "epoch 9 batch 103/185 loss = 0.0107\n",
      "epoch 9 batch 104/185 loss = 0.0123\n",
      "epoch 9 batch 105/185 loss = 0.0123\n",
      "epoch 9 batch 106/185 loss = 0.0091\n",
      "epoch 9 batch 107/185 loss = 0.0127\n",
      "epoch 9 batch 108/185 loss = 0.0096\n",
      "epoch 9 batch 109/185 loss = 0.0109\n",
      "epoch 9 batch 110/185 loss = 0.0119\n",
      "epoch 9 batch 111/185 loss = 0.0123\n",
      "epoch 9 batch 112/185 loss = 0.0103\n",
      "epoch 9 batch 113/185 loss = 0.0120\n",
      "epoch 9 batch 114/185 loss = 0.0088\n",
      "epoch 9 batch 115/185 loss = 0.0136\n",
      "epoch 9 batch 116/185 loss = 0.0094\n",
      "epoch 9 batch 117/185 loss = 0.0092\n",
      "epoch 9 batch 118/185 loss = 0.0139\n",
      "epoch 9 batch 119/185 loss = 0.0138\n",
      "epoch 9 batch 120/185 loss = 0.0111\n",
      "epoch 9 batch 121/185 loss = 0.0096\n",
      "epoch 9 batch 122/185 loss = 0.0115\n",
      "epoch 9 batch 123/185 loss = 0.0130\n",
      "epoch 9 batch 124/185 loss = 0.0119\n",
      "epoch 9 batch 125/185 loss = 0.0153\n",
      "epoch 9 batch 126/185 loss = 0.0145\n",
      "epoch 9 batch 127/185 loss = 0.0112\n",
      "epoch 9 batch 128/185 loss = 0.0114\n",
      "epoch 9 batch 129/185 loss = 0.0138\n",
      "epoch 9 batch 130/185 loss = 0.0114\n",
      "epoch 9 batch 131/185 loss = 0.0110\n",
      "epoch 9 batch 132/185 loss = 0.0133\n",
      "epoch 9 batch 133/185 loss = 0.0128\n",
      "epoch 9 batch 134/185 loss = 0.0093\n",
      "epoch 9 batch 135/185 loss = 0.0124\n",
      "epoch 9 batch 136/185 loss = 0.0133\n",
      "epoch 9 batch 137/185 loss = 0.0124\n",
      "epoch 9 batch 138/185 loss = 0.0149\n",
      "epoch 9 batch 139/185 loss = 0.0121\n",
      "epoch 9 batch 140/185 loss = 0.0108\n",
      "epoch 9 batch 141/185 loss = 0.0125\n",
      "epoch 9 batch 142/185 loss = 0.0108\n",
      "epoch 9 batch 143/185 loss = 0.0123\n",
      "epoch 9 batch 144/185 loss = 0.0109\n",
      "epoch 9 batch 145/185 loss = 0.0105\n",
      "epoch 9 batch 146/185 loss = 0.0088\n",
      "epoch 9 batch 147/185 loss = 0.0148\n",
      "epoch 9 batch 148/185 loss = 0.0107\n",
      "epoch 9 batch 149/185 loss = 0.0107\n",
      "epoch 9 batch 150/185 loss = 0.0114\n",
      "epoch 9 batch 151/185 loss = 0.0101\n",
      "epoch 9 batch 152/185 loss = 0.0121\n",
      "epoch 9 batch 153/185 loss = 0.0112\n",
      "epoch 9 batch 154/185 loss = 0.0140\n",
      "epoch 9 batch 155/185 loss = 0.0135\n",
      "epoch 9 batch 156/185 loss = 0.0146\n",
      "epoch 9 batch 157/185 loss = 0.0122\n",
      "epoch 9 batch 158/185 loss = 0.0147\n",
      "epoch 9 batch 159/185 loss = 0.0106\n",
      "epoch 9 batch 160/185 loss = 0.0097\n",
      "epoch 9 batch 161/185 loss = 0.0138\n",
      "epoch 9 batch 162/185 loss = 0.0133\n",
      "epoch 9 batch 163/185 loss = 0.0115\n",
      "epoch 9 batch 164/185 loss = 0.0123\n",
      "epoch 9 batch 165/185 loss = 0.0110\n",
      "epoch 9 batch 166/185 loss = 0.0126\n",
      "epoch 9 batch 167/185 loss = 0.0110\n",
      "epoch 9 batch 168/185 loss = 0.0126\n",
      "epoch 9 batch 169/185 loss = 0.0110\n",
      "epoch 9 batch 170/185 loss = 0.0106\n",
      "epoch 9 batch 171/185 loss = 0.0124\n",
      "epoch 9 batch 172/185 loss = 0.0094\n",
      "epoch 9 batch 173/185 loss = 0.0116\n",
      "epoch 9 batch 174/185 loss = 0.0120\n",
      "epoch 9 batch 175/185 loss = 0.0129\n",
      "epoch 9 batch 176/185 loss = 0.0117\n",
      "epoch 9 batch 177/185 loss = 0.0111\n",
      "epoch 9 batch 178/185 loss = 0.0128\n",
      "epoch 9 batch 179/185 loss = 0.0100\n",
      "epoch 9 batch 180/185 loss = 0.0159\n",
      "epoch 9 batch 181/185 loss = 0.0114\n",
      "epoch 9 batch 182/185 loss = 0.0132\n",
      "epoch 9 batch 183/185 loss = 0.0096\n",
      "epoch 9 batch 184/185 loss = 0.0127\n",
      "epoch 9 batch 185/185 loss = 0.0120\n",
      "epoch 9 train loss = 0.0120 valid loss = 0.0133\n",
      "epoch 10 batch 1/185 loss = 0.0118\n",
      "epoch 10 batch 2/185 loss = 0.0132\n",
      "epoch 10 batch 3/185 loss = 0.0109\n",
      "epoch 10 batch 4/185 loss = 0.0122\n",
      "epoch 10 batch 5/185 loss = 0.0134\n",
      "epoch 10 batch 6/185 loss = 0.0087\n",
      "epoch 10 batch 7/185 loss = 0.0115\n",
      "epoch 10 batch 8/185 loss = 0.0119\n",
      "epoch 10 batch 9/185 loss = 0.0117\n",
      "epoch 10 batch 10/185 loss = 0.0116\n",
      "epoch 10 batch 11/185 loss = 0.0108\n",
      "epoch 10 batch 12/185 loss = 0.0106\n",
      "epoch 10 batch 13/185 loss = 0.0118\n",
      "epoch 10 batch 14/185 loss = 0.0113\n",
      "epoch 10 batch 15/185 loss = 0.0092\n",
      "epoch 10 batch 16/185 loss = 0.0117\n",
      "epoch 10 batch 17/185 loss = 0.0104\n",
      "epoch 10 batch 18/185 loss = 0.0086\n",
      "epoch 10 batch 19/185 loss = 0.0134\n",
      "epoch 10 batch 20/185 loss = 0.0087\n",
      "epoch 10 batch 21/185 loss = 0.0111\n",
      "epoch 10 batch 22/185 loss = 0.0091\n",
      "epoch 10 batch 23/185 loss = 0.0093\n",
      "epoch 10 batch 24/185 loss = 0.0092\n",
      "epoch 10 batch 25/185 loss = 0.0113\n",
      "epoch 10 batch 26/185 loss = 0.0102\n",
      "epoch 10 batch 27/185 loss = 0.0100\n",
      "epoch 10 batch 28/185 loss = 0.0081\n",
      "epoch 10 batch 29/185 loss = 0.0108\n",
      "epoch 10 batch 30/185 loss = 0.0132\n",
      "epoch 10 batch 31/185 loss = 0.0123\n",
      "epoch 10 batch 32/185 loss = 0.0109\n",
      "epoch 10 batch 33/185 loss = 0.0113\n",
      "epoch 10 batch 34/185 loss = 0.0117\n",
      "epoch 10 batch 35/185 loss = 0.0110\n",
      "epoch 10 batch 36/185 loss = 0.0151\n",
      "epoch 10 batch 37/185 loss = 0.0117\n",
      "epoch 10 batch 38/185 loss = 0.0111\n",
      "epoch 10 batch 39/185 loss = 0.0122\n",
      "epoch 10 batch 40/185 loss = 0.0095\n",
      "epoch 10 batch 41/185 loss = 0.0095\n",
      "epoch 10 batch 42/185 loss = 0.0071\n",
      "epoch 10 batch 43/185 loss = 0.0123\n",
      "epoch 10 batch 44/185 loss = 0.0119\n",
      "epoch 10 batch 45/185 loss = 0.0114\n",
      "epoch 10 batch 46/185 loss = 0.0089\n",
      "epoch 10 batch 47/185 loss = 0.0106\n",
      "epoch 10 batch 48/185 loss = 0.0136\n",
      "epoch 10 batch 49/185 loss = 0.0107\n",
      "epoch 10 batch 50/185 loss = 0.0109\n",
      "epoch 10 batch 51/185 loss = 0.0093\n",
      "epoch 10 batch 52/185 loss = 0.0103\n",
      "epoch 10 batch 53/185 loss = 0.0111\n",
      "epoch 10 batch 54/185 loss = 0.0123\n",
      "epoch 10 batch 55/185 loss = 0.0086\n",
      "epoch 10 batch 56/185 loss = 0.0117\n",
      "epoch 10 batch 57/185 loss = 0.0098\n",
      "epoch 10 batch 58/185 loss = 0.0121\n",
      "epoch 10 batch 59/185 loss = 0.0091\n",
      "epoch 10 batch 60/185 loss = 0.0133\n",
      "epoch 10 batch 61/185 loss = 0.0141\n",
      "epoch 10 batch 62/185 loss = 0.0104\n",
      "epoch 10 batch 63/185 loss = 0.0120\n",
      "epoch 10 batch 64/185 loss = 0.0104\n",
      "epoch 10 batch 65/185 loss = 0.0105\n",
      "epoch 10 batch 66/185 loss = 0.0136\n",
      "epoch 10 batch 67/185 loss = 0.0132\n",
      "epoch 10 batch 68/185 loss = 0.0115\n",
      "epoch 10 batch 69/185 loss = 0.0133\n",
      "epoch 10 batch 70/185 loss = 0.0110\n",
      "epoch 10 batch 71/185 loss = 0.0097\n",
      "epoch 10 batch 72/185 loss = 0.0135\n",
      "epoch 10 batch 73/185 loss = 0.0135\n",
      "epoch 10 batch 74/185 loss = 0.0119\n",
      "epoch 10 batch 75/185 loss = 0.0090\n",
      "epoch 10 batch 76/185 loss = 0.0103\n",
      "epoch 10 batch 77/185 loss = 0.0111\n",
      "epoch 10 batch 78/185 loss = 0.0095\n",
      "epoch 10 batch 79/185 loss = 0.0124\n",
      "epoch 10 batch 80/185 loss = 0.0100\n",
      "epoch 10 batch 81/185 loss = 0.0121\n",
      "epoch 10 batch 82/185 loss = 0.0094\n",
      "epoch 10 batch 83/185 loss = 0.0123\n",
      "epoch 10 batch 84/185 loss = 0.0103\n",
      "epoch 10 batch 85/185 loss = 0.0105\n",
      "epoch 10 batch 86/185 loss = 0.0168\n",
      "epoch 10 batch 87/185 loss = 0.0139\n",
      "epoch 10 batch 88/185 loss = 0.0118\n",
      "epoch 10 batch 89/185 loss = 0.0128\n",
      "epoch 10 batch 90/185 loss = 0.0118\n",
      "epoch 10 batch 91/185 loss = 0.0127\n",
      "epoch 10 batch 92/185 loss = 0.0107\n",
      "epoch 10 batch 93/185 loss = 0.0113\n",
      "epoch 10 batch 94/185 loss = 0.0119\n",
      "epoch 10 batch 95/185 loss = 0.0115\n",
      "epoch 10 batch 96/185 loss = 0.0135\n",
      "epoch 10 batch 97/185 loss = 0.0090\n",
      "epoch 10 batch 98/185 loss = 0.0109\n",
      "epoch 10 batch 99/185 loss = 0.0086\n",
      "epoch 10 batch 100/185 loss = 0.0118\n",
      "epoch 10 batch 101/185 loss = 0.0114\n",
      "epoch 10 batch 102/185 loss = 0.0110\n",
      "epoch 10 batch 103/185 loss = 0.0098\n",
      "epoch 10 batch 104/185 loss = 0.0113\n",
      "epoch 10 batch 105/185 loss = 0.0139\n",
      "epoch 10 batch 106/185 loss = 0.0120\n",
      "epoch 10 batch 107/185 loss = 0.0113\n",
      "epoch 10 batch 108/185 loss = 0.0116\n",
      "epoch 10 batch 109/185 loss = 0.0121\n",
      "epoch 10 batch 110/185 loss = 0.0133\n",
      "epoch 10 batch 111/185 loss = 0.0109\n",
      "epoch 10 batch 112/185 loss = 0.0097\n",
      "epoch 10 batch 113/185 loss = 0.0116\n",
      "epoch 10 batch 114/185 loss = 0.0110\n",
      "epoch 10 batch 115/185 loss = 0.0136\n",
      "epoch 10 batch 116/185 loss = 0.0095\n",
      "epoch 10 batch 117/185 loss = 0.0129\n",
      "epoch 10 batch 118/185 loss = 0.0131\n",
      "epoch 10 batch 119/185 loss = 0.0085\n",
      "epoch 10 batch 120/185 loss = 0.0107\n",
      "epoch 10 batch 121/185 loss = 0.0131\n",
      "epoch 10 batch 122/185 loss = 0.0118\n",
      "epoch 10 batch 123/185 loss = 0.0092\n",
      "epoch 10 batch 124/185 loss = 0.0117\n",
      "epoch 10 batch 125/185 loss = 0.0101\n",
      "epoch 10 batch 126/185 loss = 0.0113\n",
      "epoch 10 batch 127/185 loss = 0.0136\n",
      "epoch 10 batch 128/185 loss = 0.0124\n",
      "epoch 10 batch 129/185 loss = 0.0143\n",
      "epoch 10 batch 130/185 loss = 0.0111\n",
      "epoch 10 batch 131/185 loss = 0.0097\n",
      "epoch 10 batch 132/185 loss = 0.0102\n",
      "epoch 10 batch 133/185 loss = 0.0142\n",
      "epoch 10 batch 134/185 loss = 0.0127\n",
      "epoch 10 batch 135/185 loss = 0.0114\n",
      "epoch 10 batch 136/185 loss = 0.0121\n",
      "epoch 10 batch 137/185 loss = 0.0110\n",
      "epoch 10 batch 138/185 loss = 0.0114\n",
      "epoch 10 batch 139/185 loss = 0.0116\n",
      "epoch 10 batch 140/185 loss = 0.0101\n",
      "epoch 10 batch 141/185 loss = 0.0129\n",
      "epoch 10 batch 142/185 loss = 0.0133\n",
      "epoch 10 batch 143/185 loss = 0.0106\n",
      "epoch 10 batch 144/185 loss = 0.0120\n",
      "epoch 10 batch 145/185 loss = 0.0097\n",
      "epoch 10 batch 146/185 loss = 0.0103\n",
      "epoch 10 batch 147/185 loss = 0.0102\n",
      "epoch 10 batch 148/185 loss = 0.0134\n",
      "epoch 10 batch 149/185 loss = 0.0100\n",
      "epoch 10 batch 150/185 loss = 0.0135\n",
      "epoch 10 batch 151/185 loss = 0.0136\n",
      "epoch 10 batch 152/185 loss = 0.0108\n",
      "epoch 10 batch 153/185 loss = 0.0115\n",
      "epoch 10 batch 154/185 loss = 0.0100\n",
      "epoch 10 batch 155/185 loss = 0.0137\n",
      "epoch 10 batch 156/185 loss = 0.0113\n",
      "epoch 10 batch 157/185 loss = 0.0102\n",
      "epoch 10 batch 158/185 loss = 0.0088\n",
      "epoch 10 batch 159/185 loss = 0.0109\n",
      "epoch 10 batch 160/185 loss = 0.0120\n",
      "epoch 10 batch 161/185 loss = 0.0124\n",
      "epoch 10 batch 162/185 loss = 0.0126\n",
      "epoch 10 batch 163/185 loss = 0.0104\n",
      "epoch 10 batch 164/185 loss = 0.0097\n",
      "epoch 10 batch 165/185 loss = 0.0130\n",
      "epoch 10 batch 166/185 loss = 0.0112\n",
      "epoch 10 batch 167/185 loss = 0.0098\n",
      "epoch 10 batch 168/185 loss = 0.0106\n",
      "epoch 10 batch 169/185 loss = 0.0106\n",
      "epoch 10 batch 170/185 loss = 0.0095\n",
      "epoch 10 batch 171/185 loss = 0.0105\n",
      "epoch 10 batch 172/185 loss = 0.0121\n",
      "epoch 10 batch 173/185 loss = 0.0133\n",
      "epoch 10 batch 174/185 loss = 0.0093\n",
      "epoch 10 batch 175/185 loss = 0.0096\n",
      "epoch 10 batch 176/185 loss = 0.0109\n",
      "epoch 10 batch 177/185 loss = 0.0086\n",
      "epoch 10 batch 178/185 loss = 0.0138\n",
      "epoch 10 batch 179/185 loss = 0.0117\n",
      "epoch 10 batch 180/185 loss = 0.0112\n",
      "epoch 10 batch 181/185 loss = 0.0087\n",
      "epoch 10 batch 182/185 loss = 0.0111\n",
      "epoch 10 batch 183/185 loss = 0.0106\n",
      "epoch 10 batch 184/185 loss = 0.0095\n",
      "epoch 10 batch 185/185 loss = 0.0090\n",
      "epoch 10 train loss = 0.0113 valid loss = 0.0119\n",
      "epoch 11 batch 1/185 loss = 0.0105\n",
      "epoch 11 batch 2/185 loss = 0.0122\n",
      "epoch 11 batch 3/185 loss = 0.0114\n",
      "epoch 11 batch 4/185 loss = 0.0105\n",
      "epoch 11 batch 5/185 loss = 0.0105\n",
      "epoch 11 batch 6/185 loss = 0.0107\n",
      "epoch 11 batch 7/185 loss = 0.0098\n",
      "epoch 11 batch 8/185 loss = 0.0069\n",
      "epoch 11 batch 9/185 loss = 0.0099\n",
      "epoch 11 batch 10/185 loss = 0.0103\n",
      "epoch 11 batch 11/185 loss = 0.0128\n",
      "epoch 11 batch 12/185 loss = 0.0098\n",
      "epoch 11 batch 13/185 loss = 0.0091\n",
      "epoch 11 batch 14/185 loss = 0.0104\n",
      "epoch 11 batch 15/185 loss = 0.0131\n",
      "epoch 11 batch 16/185 loss = 0.0095\n",
      "epoch 11 batch 17/185 loss = 0.0101\n",
      "epoch 11 batch 18/185 loss = 0.0100\n",
      "epoch 11 batch 19/185 loss = 0.0108\n",
      "epoch 11 batch 20/185 loss = 0.0110\n",
      "epoch 11 batch 21/185 loss = 0.0108\n",
      "epoch 11 batch 22/185 loss = 0.0114\n",
      "epoch 11 batch 23/185 loss = 0.0113\n",
      "epoch 11 batch 24/185 loss = 0.0109\n",
      "epoch 11 batch 25/185 loss = 0.0080\n",
      "epoch 11 batch 26/185 loss = 0.0098\n",
      "epoch 11 batch 27/185 loss = 0.0119\n",
      "epoch 11 batch 28/185 loss = 0.0134\n",
      "epoch 11 batch 29/185 loss = 0.0116\n",
      "epoch 11 batch 30/185 loss = 0.0111\n",
      "epoch 11 batch 31/185 loss = 0.0107\n",
      "epoch 11 batch 32/185 loss = 0.0143\n",
      "epoch 11 batch 33/185 loss = 0.0115\n",
      "epoch 11 batch 34/185 loss = 0.0090\n",
      "epoch 11 batch 35/185 loss = 0.0121\n",
      "epoch 11 batch 36/185 loss = 0.0100\n",
      "epoch 11 batch 37/185 loss = 0.0101\n",
      "epoch 11 batch 38/185 loss = 0.0101\n",
      "epoch 11 batch 39/185 loss = 0.0099\n",
      "epoch 11 batch 40/185 loss = 0.0120\n",
      "epoch 11 batch 41/185 loss = 0.0113\n",
      "epoch 11 batch 42/185 loss = 0.0103\n",
      "epoch 11 batch 43/185 loss = 0.0139\n",
      "epoch 11 batch 44/185 loss = 0.0109\n",
      "epoch 11 batch 45/185 loss = 0.0108\n",
      "epoch 11 batch 46/185 loss = 0.0083\n",
      "epoch 11 batch 47/185 loss = 0.0098\n",
      "epoch 11 batch 48/185 loss = 0.0131\n",
      "epoch 11 batch 49/185 loss = 0.0091\n",
      "epoch 11 batch 50/185 loss = 0.0124\n",
      "epoch 11 batch 51/185 loss = 0.0111\n",
      "epoch 11 batch 52/185 loss = 0.0097\n",
      "epoch 11 batch 53/185 loss = 0.0106\n",
      "epoch 11 batch 54/185 loss = 0.0113\n",
      "epoch 11 batch 55/185 loss = 0.0113\n",
      "epoch 11 batch 56/185 loss = 0.0139\n",
      "epoch 11 batch 57/185 loss = 0.0079\n",
      "epoch 11 batch 58/185 loss = 0.0108\n",
      "epoch 11 batch 59/185 loss = 0.0124\n",
      "epoch 11 batch 60/185 loss = 0.0116\n",
      "epoch 11 batch 61/185 loss = 0.0100\n",
      "epoch 11 batch 62/185 loss = 0.0130\n",
      "epoch 11 batch 63/185 loss = 0.0117\n",
      "epoch 11 batch 64/185 loss = 0.0108\n",
      "epoch 11 batch 65/185 loss = 0.0117\n",
      "epoch 11 batch 66/185 loss = 0.0088\n",
      "epoch 11 batch 67/185 loss = 0.0093\n",
      "epoch 11 batch 68/185 loss = 0.0114\n",
      "epoch 11 batch 69/185 loss = 0.0101\n",
      "epoch 11 batch 70/185 loss = 0.0101\n",
      "epoch 11 batch 71/185 loss = 0.0108\n",
      "epoch 11 batch 72/185 loss = 0.0109\n",
      "epoch 11 batch 73/185 loss = 0.0131\n",
      "epoch 11 batch 74/185 loss = 0.0090\n",
      "epoch 11 batch 75/185 loss = 0.0106\n",
      "epoch 11 batch 76/185 loss = 0.0092\n",
      "epoch 11 batch 77/185 loss = 0.0113\n",
      "epoch 11 batch 78/185 loss = 0.0108\n",
      "epoch 11 batch 79/185 loss = 0.0111\n",
      "epoch 11 batch 80/185 loss = 0.0113\n",
      "epoch 11 batch 81/185 loss = 0.0142\n",
      "epoch 11 batch 82/185 loss = 0.0100\n",
      "epoch 11 batch 83/185 loss = 0.0109\n",
      "epoch 11 batch 84/185 loss = 0.0131\n",
      "epoch 11 batch 85/185 loss = 0.0116\n",
      "epoch 11 batch 86/185 loss = 0.0115\n",
      "epoch 11 batch 87/185 loss = 0.0105\n",
      "epoch 11 batch 88/185 loss = 0.0101\n",
      "epoch 11 batch 89/185 loss = 0.0097\n",
      "epoch 11 batch 90/185 loss = 0.0121\n",
      "epoch 11 batch 91/185 loss = 0.0095\n",
      "epoch 11 batch 92/185 loss = 0.0103\n",
      "epoch 11 batch 93/185 loss = 0.0127\n",
      "epoch 11 batch 94/185 loss = 0.0094\n",
      "epoch 11 batch 95/185 loss = 0.0104\n",
      "epoch 11 batch 96/185 loss = 0.0102\n",
      "epoch 11 batch 97/185 loss = 0.0096\n",
      "epoch 11 batch 98/185 loss = 0.0114\n",
      "epoch 11 batch 99/185 loss = 0.0110\n",
      "epoch 11 batch 100/185 loss = 0.0129\n",
      "epoch 11 batch 101/185 loss = 0.0115\n",
      "epoch 11 batch 102/185 loss = 0.0116\n",
      "epoch 11 batch 103/185 loss = 0.0110\n",
      "epoch 11 batch 104/185 loss = 0.0109\n",
      "epoch 11 batch 105/185 loss = 0.0144\n",
      "epoch 11 batch 106/185 loss = 0.0088\n",
      "epoch 11 batch 107/185 loss = 0.0102\n",
      "epoch 11 batch 108/185 loss = 0.0121\n",
      "epoch 11 batch 109/185 loss = 0.0135\n",
      "epoch 11 batch 110/185 loss = 0.0095\n",
      "epoch 11 batch 111/185 loss = 0.0130\n",
      "epoch 11 batch 112/185 loss = 0.0137\n",
      "epoch 11 batch 113/185 loss = 0.0094\n",
      "epoch 11 batch 114/185 loss = 0.0087\n",
      "epoch 11 batch 115/185 loss = 0.0087\n",
      "epoch 11 batch 116/185 loss = 0.0112\n",
      "epoch 11 batch 117/185 loss = 0.0090\n",
      "epoch 11 batch 118/185 loss = 0.0129\n",
      "epoch 11 batch 119/185 loss = 0.0084\n",
      "epoch 11 batch 120/185 loss = 0.0084\n",
      "epoch 11 batch 121/185 loss = 0.0101\n",
      "epoch 11 batch 122/185 loss = 0.0102\n",
      "epoch 11 batch 123/185 loss = 0.0112\n",
      "epoch 11 batch 124/185 loss = 0.0124\n",
      "epoch 11 batch 125/185 loss = 0.0116\n",
      "epoch 11 batch 126/185 loss = 0.0124\n",
      "epoch 11 batch 127/185 loss = 0.0118\n",
      "epoch 11 batch 128/185 loss = 0.0118\n",
      "epoch 11 batch 129/185 loss = 0.0108\n",
      "epoch 11 batch 130/185 loss = 0.0102\n",
      "epoch 11 batch 131/185 loss = 0.0100\n",
      "epoch 11 batch 132/185 loss = 0.0114\n",
      "epoch 11 batch 133/185 loss = 0.0087\n",
      "epoch 11 batch 134/185 loss = 0.0097\n",
      "epoch 11 batch 135/185 loss = 0.0145\n",
      "epoch 11 batch 136/185 loss = 0.0094\n",
      "epoch 11 batch 137/185 loss = 0.0084\n",
      "epoch 11 batch 138/185 loss = 0.0105\n",
      "epoch 11 batch 139/185 loss = 0.0126\n",
      "epoch 11 batch 140/185 loss = 0.0103\n",
      "epoch 11 batch 141/185 loss = 0.0130\n",
      "epoch 11 batch 142/185 loss = 0.0107\n",
      "epoch 11 batch 143/185 loss = 0.0133\n",
      "epoch 11 batch 144/185 loss = 0.0097\n",
      "epoch 11 batch 145/185 loss = 0.0078\n",
      "epoch 11 batch 146/185 loss = 0.0102\n",
      "epoch 11 batch 147/185 loss = 0.0111\n",
      "epoch 11 batch 148/185 loss = 0.0087\n",
      "epoch 11 batch 149/185 loss = 0.0089\n",
      "epoch 11 batch 150/185 loss = 0.0111\n",
      "epoch 11 batch 151/185 loss = 0.0119\n",
      "epoch 11 batch 152/185 loss = 0.0115\n",
      "epoch 11 batch 153/185 loss = 0.0104\n",
      "epoch 11 batch 154/185 loss = 0.0123\n",
      "epoch 11 batch 155/185 loss = 0.0108\n",
      "epoch 11 batch 156/185 loss = 0.0128\n",
      "epoch 11 batch 157/185 loss = 0.0108\n",
      "epoch 11 batch 158/185 loss = 0.0115\n",
      "epoch 11 batch 159/185 loss = 0.0136\n",
      "epoch 11 batch 160/185 loss = 0.0100\n",
      "epoch 11 batch 161/185 loss = 0.0165\n",
      "epoch 11 batch 162/185 loss = 0.0110\n",
      "epoch 11 batch 163/185 loss = 0.0093\n",
      "epoch 11 batch 164/185 loss = 0.0108\n",
      "epoch 11 batch 165/185 loss = 0.0133\n",
      "epoch 11 batch 166/185 loss = 0.0096\n",
      "epoch 11 batch 167/185 loss = 0.0145\n",
      "epoch 11 batch 168/185 loss = 0.0107\n",
      "epoch 11 batch 169/185 loss = 0.0101\n",
      "epoch 11 batch 170/185 loss = 0.0120\n",
      "epoch 11 batch 171/185 loss = 0.0130\n",
      "epoch 11 batch 172/185 loss = 0.0117\n",
      "epoch 11 batch 173/185 loss = 0.0116\n",
      "epoch 11 batch 174/185 loss = 0.0138\n",
      "epoch 11 batch 175/185 loss = 0.0114\n",
      "epoch 11 batch 176/185 loss = 0.0115\n",
      "epoch 11 batch 177/185 loss = 0.0107\n",
      "epoch 11 batch 178/185 loss = 0.0094\n",
      "epoch 11 batch 179/185 loss = 0.0102\n",
      "epoch 11 batch 180/185 loss = 0.0107\n",
      "epoch 11 batch 181/185 loss = 0.0103\n",
      "epoch 11 batch 182/185 loss = 0.0129\n",
      "epoch 11 batch 183/185 loss = 0.0129\n",
      "epoch 11 batch 184/185 loss = 0.0113\n",
      "epoch 11 batch 185/185 loss = 0.0112\n",
      "epoch 11 train loss = 0.0110 valid loss = 0.0133\n",
      "performance reducing: counter 1\n",
      "epoch 12 batch 1/185 loss = 0.0118\n",
      "epoch 12 batch 2/185 loss = 0.0101\n",
      "epoch 12 batch 3/185 loss = 0.0106\n",
      "epoch 12 batch 4/185 loss = 0.0113\n",
      "epoch 12 batch 5/185 loss = 0.0109\n",
      "epoch 12 batch 6/185 loss = 0.0101\n",
      "epoch 12 batch 7/185 loss = 0.0096\n",
      "epoch 12 batch 8/185 loss = 0.0108\n",
      "epoch 12 batch 9/185 loss = 0.0107\n",
      "epoch 12 batch 10/185 loss = 0.0107\n",
      "epoch 12 batch 11/185 loss = 0.0098\n",
      "epoch 12 batch 12/185 loss = 0.0088\n",
      "epoch 12 batch 13/185 loss = 0.0122\n",
      "epoch 12 batch 14/185 loss = 0.0102\n",
      "epoch 12 batch 15/185 loss = 0.0112\n",
      "epoch 12 batch 16/185 loss = 0.0097\n",
      "epoch 12 batch 17/185 loss = 0.0090\n",
      "epoch 12 batch 18/185 loss = 0.0165\n",
      "epoch 12 batch 19/185 loss = 0.0103\n",
      "epoch 12 batch 20/185 loss = 0.0120\n",
      "epoch 12 batch 21/185 loss = 0.0122\n",
      "epoch 12 batch 22/185 loss = 0.0115\n",
      "epoch 12 batch 23/185 loss = 0.0097\n",
      "epoch 12 batch 24/185 loss = 0.0101\n",
      "epoch 12 batch 25/185 loss = 0.0112\n",
      "epoch 12 batch 26/185 loss = 0.0122\n",
      "epoch 12 batch 27/185 loss = 0.0101\n",
      "epoch 12 batch 28/185 loss = 0.0125\n",
      "epoch 12 batch 29/185 loss = 0.0102\n",
      "epoch 12 batch 30/185 loss = 0.0094\n",
      "epoch 12 batch 31/185 loss = 0.0126\n",
      "epoch 12 batch 32/185 loss = 0.0145\n",
      "epoch 12 batch 33/185 loss = 0.0090\n",
      "epoch 12 batch 34/185 loss = 0.0155\n",
      "epoch 12 batch 35/185 loss = 0.0089\n",
      "epoch 12 batch 36/185 loss = 0.0119\n",
      "epoch 12 batch 37/185 loss = 0.0109\n",
      "epoch 12 batch 38/185 loss = 0.0111\n",
      "epoch 12 batch 39/185 loss = 0.0090\n",
      "epoch 12 batch 40/185 loss = 0.0116\n",
      "epoch 12 batch 41/185 loss = 0.0102\n",
      "epoch 12 batch 42/185 loss = 0.0102\n",
      "epoch 12 batch 43/185 loss = 0.0131\n",
      "epoch 12 batch 44/185 loss = 0.0137\n",
      "epoch 12 batch 45/185 loss = 0.0131\n",
      "epoch 12 batch 46/185 loss = 0.0101\n",
      "epoch 12 batch 47/185 loss = 0.0083\n",
      "epoch 12 batch 48/185 loss = 0.0099\n",
      "epoch 12 batch 49/185 loss = 0.0112\n",
      "epoch 12 batch 50/185 loss = 0.0112\n",
      "epoch 12 batch 51/185 loss = 0.0093\n",
      "epoch 12 batch 52/185 loss = 0.0116\n",
      "epoch 12 batch 53/185 loss = 0.0102\n",
      "epoch 12 batch 54/185 loss = 0.0101\n",
      "epoch 12 batch 55/185 loss = 0.0122\n",
      "epoch 12 batch 56/185 loss = 0.0103\n",
      "epoch 12 batch 57/185 loss = 0.0097\n",
      "epoch 12 batch 58/185 loss = 0.0078\n",
      "epoch 12 batch 59/185 loss = 0.0096\n",
      "epoch 12 batch 60/185 loss = 0.0126\n",
      "epoch 12 batch 61/185 loss = 0.0103\n",
      "epoch 12 batch 62/185 loss = 0.0101\n",
      "epoch 12 batch 63/185 loss = 0.0114\n",
      "epoch 12 batch 64/185 loss = 0.0107\n",
      "epoch 12 batch 65/185 loss = 0.0099\n",
      "epoch 12 batch 66/185 loss = 0.0095\n",
      "epoch 12 batch 67/185 loss = 0.0125\n",
      "epoch 12 batch 68/185 loss = 0.0102\n",
      "epoch 12 batch 69/185 loss = 0.0141\n",
      "epoch 12 batch 70/185 loss = 0.0162\n",
      "epoch 12 batch 71/185 loss = 0.0100\n",
      "epoch 12 batch 72/185 loss = 0.0118\n",
      "epoch 12 batch 73/185 loss = 0.0092\n",
      "epoch 12 batch 74/185 loss = 0.0117\n",
      "epoch 12 batch 75/185 loss = 0.0094\n",
      "epoch 12 batch 76/185 loss = 0.0116\n",
      "epoch 12 batch 77/185 loss = 0.0105\n",
      "epoch 12 batch 78/185 loss = 0.0103\n",
      "epoch 12 batch 79/185 loss = 0.0102\n",
      "epoch 12 batch 80/185 loss = 0.0099\n",
      "epoch 12 batch 81/185 loss = 0.0103\n",
      "epoch 12 batch 82/185 loss = 0.0111\n",
      "epoch 12 batch 83/185 loss = 0.0140\n",
      "epoch 12 batch 84/185 loss = 0.0091\n",
      "epoch 12 batch 85/185 loss = 0.0112\n",
      "epoch 12 batch 86/185 loss = 0.0107\n",
      "epoch 12 batch 87/185 loss = 0.0120\n",
      "epoch 12 batch 88/185 loss = 0.0096\n",
      "epoch 12 batch 89/185 loss = 0.0123\n",
      "epoch 12 batch 90/185 loss = 0.0107\n",
      "epoch 12 batch 91/185 loss = 0.0093\n",
      "epoch 12 batch 92/185 loss = 0.0147\n",
      "epoch 12 batch 93/185 loss = 0.0134\n",
      "epoch 12 batch 94/185 loss = 0.0095\n",
      "epoch 12 batch 95/185 loss = 0.0110\n",
      "epoch 12 batch 96/185 loss = 0.0092\n",
      "epoch 12 batch 97/185 loss = 0.0129\n",
      "epoch 12 batch 98/185 loss = 0.0098\n",
      "epoch 12 batch 99/185 loss = 0.0148\n",
      "epoch 12 batch 100/185 loss = 0.0114\n",
      "epoch 12 batch 101/185 loss = 0.0118\n",
      "epoch 12 batch 102/185 loss = 0.0079\n",
      "epoch 12 batch 103/185 loss = 0.0121\n",
      "epoch 12 batch 104/185 loss = 0.0094\n",
      "epoch 12 batch 105/185 loss = 0.0094\n",
      "epoch 12 batch 106/185 loss = 0.0104\n",
      "epoch 12 batch 107/185 loss = 0.0100\n",
      "epoch 12 batch 108/185 loss = 0.0107\n",
      "epoch 12 batch 109/185 loss = 0.0100\n",
      "epoch 12 batch 110/185 loss = 0.0129\n",
      "epoch 12 batch 111/185 loss = 0.0092\n",
      "epoch 12 batch 112/185 loss = 0.0109\n",
      "epoch 12 batch 113/185 loss = 0.0077\n",
      "epoch 12 batch 114/185 loss = 0.0086\n",
      "epoch 12 batch 115/185 loss = 0.0106\n",
      "epoch 12 batch 116/185 loss = 0.0104\n",
      "epoch 12 batch 117/185 loss = 0.0094\n",
      "epoch 12 batch 118/185 loss = 0.0095\n",
      "epoch 12 batch 119/185 loss = 0.0112\n",
      "epoch 12 batch 120/185 loss = 0.0099\n",
      "epoch 12 batch 121/185 loss = 0.0106\n",
      "epoch 12 batch 122/185 loss = 0.0108\n",
      "epoch 12 batch 123/185 loss = 0.0103\n",
      "epoch 12 batch 124/185 loss = 0.0137\n",
      "epoch 12 batch 125/185 loss = 0.0106\n",
      "epoch 12 batch 126/185 loss = 0.0110\n",
      "epoch 12 batch 127/185 loss = 0.0109\n",
      "epoch 12 batch 128/185 loss = 0.0120\n",
      "epoch 12 batch 129/185 loss = 0.0110\n",
      "epoch 12 batch 130/185 loss = 0.0117\n",
      "epoch 12 batch 131/185 loss = 0.0080\n",
      "epoch 12 batch 132/185 loss = 0.0092\n",
      "epoch 12 batch 133/185 loss = 0.0096\n",
      "epoch 12 batch 134/185 loss = 0.0128\n",
      "epoch 12 batch 135/185 loss = 0.0099\n",
      "epoch 12 batch 136/185 loss = 0.0083\n",
      "epoch 12 batch 137/185 loss = 0.0104\n",
      "epoch 12 batch 138/185 loss = 0.0107\n",
      "epoch 12 batch 139/185 loss = 0.0110\n",
      "epoch 12 batch 140/185 loss = 0.0108\n",
      "epoch 12 batch 141/185 loss = 0.0110\n",
      "epoch 12 batch 142/185 loss = 0.0107\n",
      "epoch 12 batch 143/185 loss = 0.0107\n",
      "epoch 12 batch 144/185 loss = 0.0083\n",
      "epoch 12 batch 145/185 loss = 0.0107\n",
      "epoch 12 batch 146/185 loss = 0.0096\n",
      "epoch 12 batch 147/185 loss = 0.0133\n",
      "epoch 12 batch 148/185 loss = 0.0120\n",
      "epoch 12 batch 149/185 loss = 0.0105\n",
      "epoch 12 batch 150/185 loss = 0.0105\n",
      "epoch 12 batch 151/185 loss = 0.0097\n",
      "epoch 12 batch 152/185 loss = 0.0103\n",
      "epoch 12 batch 153/185 loss = 0.0104\n",
      "epoch 12 batch 154/185 loss = 0.0130\n",
      "epoch 12 batch 155/185 loss = 0.0093\n",
      "epoch 12 batch 156/185 loss = 0.0105\n",
      "epoch 12 batch 157/185 loss = 0.0105\n",
      "epoch 12 batch 158/185 loss = 0.0115\n",
      "epoch 12 batch 159/185 loss = 0.0110\n",
      "epoch 12 batch 160/185 loss = 0.0093\n",
      "epoch 12 batch 161/185 loss = 0.0128\n",
      "epoch 12 batch 162/185 loss = 0.0115\n",
      "epoch 12 batch 163/185 loss = 0.0101\n",
      "epoch 12 batch 164/185 loss = 0.0141\n",
      "epoch 12 batch 165/185 loss = 0.0118\n",
      "epoch 12 batch 166/185 loss = 0.0111\n",
      "epoch 12 batch 167/185 loss = 0.0105\n",
      "epoch 12 batch 168/185 loss = 0.0100\n",
      "epoch 12 batch 169/185 loss = 0.0097\n",
      "epoch 12 batch 170/185 loss = 0.0085\n",
      "epoch 12 batch 171/185 loss = 0.0099\n",
      "epoch 12 batch 172/185 loss = 0.0114\n",
      "epoch 12 batch 173/185 loss = 0.0102\n",
      "epoch 12 batch 174/185 loss = 0.0108\n",
      "epoch 12 batch 175/185 loss = 0.0085\n",
      "epoch 12 batch 176/185 loss = 0.0098\n",
      "epoch 12 batch 177/185 loss = 0.0111\n",
      "epoch 12 batch 178/185 loss = 0.0101\n",
      "epoch 12 batch 179/185 loss = 0.0100\n",
      "epoch 12 batch 180/185 loss = 0.0103\n",
      "epoch 12 batch 181/185 loss = 0.0130\n",
      "epoch 12 batch 182/185 loss = 0.0114\n",
      "epoch 12 batch 183/185 loss = 0.0091\n",
      "epoch 12 batch 184/185 loss = 0.0109\n",
      "epoch 12 batch 185/185 loss = 0.0095\n",
      "epoch 12 train loss = 0.0108 valid loss = 0.0120\n",
      "performance reducing: counter 2\n",
      "epoch 13 batch 1/185 loss = 0.0096\n",
      "epoch 13 batch 2/185 loss = 0.0139\n",
      "epoch 13 batch 3/185 loss = 0.0105\n",
      "epoch 13 batch 4/185 loss = 0.0116\n",
      "epoch 13 batch 5/185 loss = 0.0088\n",
      "epoch 13 batch 6/185 loss = 0.0108\n",
      "epoch 13 batch 7/185 loss = 0.0109\n",
      "epoch 13 batch 8/185 loss = 0.0117\n",
      "epoch 13 batch 9/185 loss = 0.0086\n",
      "epoch 13 batch 10/185 loss = 0.0127\n",
      "epoch 13 batch 11/185 loss = 0.0101\n",
      "epoch 13 batch 12/185 loss = 0.0084\n",
      "epoch 13 batch 13/185 loss = 0.0097\n",
      "epoch 13 batch 14/185 loss = 0.0114\n",
      "epoch 13 batch 15/185 loss = 0.0127\n",
      "epoch 13 batch 16/185 loss = 0.0098\n",
      "epoch 13 batch 17/185 loss = 0.0097\n",
      "epoch 13 batch 18/185 loss = 0.0092\n",
      "epoch 13 batch 19/185 loss = 0.0123\n",
      "epoch 13 batch 20/185 loss = 0.0087\n",
      "epoch 13 batch 21/185 loss = 0.0078\n",
      "epoch 13 batch 22/185 loss = 0.0114\n",
      "epoch 13 batch 23/185 loss = 0.0096\n",
      "epoch 13 batch 24/185 loss = 0.0104\n",
      "epoch 13 batch 25/185 loss = 0.0108\n",
      "epoch 13 batch 26/185 loss = 0.0097\n",
      "epoch 13 batch 27/185 loss = 0.0086\n",
      "epoch 13 batch 28/185 loss = 0.0123\n",
      "epoch 13 batch 29/185 loss = 0.0094\n",
      "epoch 13 batch 30/185 loss = 0.0103\n",
      "epoch 13 batch 31/185 loss = 0.0086\n",
      "epoch 13 batch 32/185 loss = 0.0097\n",
      "epoch 13 batch 33/185 loss = 0.0110\n",
      "epoch 13 batch 34/185 loss = 0.0108\n",
      "epoch 13 batch 35/185 loss = 0.0118\n",
      "epoch 13 batch 36/185 loss = 0.0116\n",
      "epoch 13 batch 37/185 loss = 0.0093\n",
      "epoch 13 batch 38/185 loss = 0.0098\n",
      "epoch 13 batch 39/185 loss = 0.0123\n",
      "epoch 13 batch 40/185 loss = 0.0096\n",
      "epoch 13 batch 41/185 loss = 0.0094\n",
      "epoch 13 batch 42/185 loss = 0.0092\n",
      "epoch 13 batch 43/185 loss = 0.0098\n",
      "epoch 13 batch 44/185 loss = 0.0081\n",
      "epoch 13 batch 45/185 loss = 0.0083\n",
      "epoch 13 batch 46/185 loss = 0.0112\n",
      "epoch 13 batch 47/185 loss = 0.0107\n",
      "epoch 13 batch 48/185 loss = 0.0078\n",
      "epoch 13 batch 49/185 loss = 0.0088\n",
      "epoch 13 batch 50/185 loss = 0.0105\n",
      "epoch 13 batch 51/185 loss = 0.0111\n",
      "epoch 13 batch 52/185 loss = 0.0096\n",
      "epoch 13 batch 53/185 loss = 0.0119\n",
      "epoch 13 batch 54/185 loss = 0.0068\n",
      "epoch 13 batch 55/185 loss = 0.0118\n",
      "epoch 13 batch 56/185 loss = 0.0122\n",
      "epoch 13 batch 57/185 loss = 0.0106\n",
      "epoch 13 batch 58/185 loss = 0.0118\n",
      "epoch 13 batch 59/185 loss = 0.0102\n",
      "epoch 13 batch 60/185 loss = 0.0131\n",
      "epoch 13 batch 61/185 loss = 0.0102\n",
      "epoch 13 batch 62/185 loss = 0.0092\n",
      "epoch 13 batch 63/185 loss = 0.0089\n",
      "epoch 13 batch 64/185 loss = 0.0123\n",
      "epoch 13 batch 65/185 loss = 0.0106\n",
      "epoch 13 batch 66/185 loss = 0.0103\n",
      "epoch 13 batch 67/185 loss = 0.0108\n",
      "epoch 13 batch 68/185 loss = 0.0094\n",
      "epoch 13 batch 69/185 loss = 0.0117\n",
      "epoch 13 batch 70/185 loss = 0.0108\n",
      "epoch 13 batch 71/185 loss = 0.0100\n",
      "epoch 13 batch 72/185 loss = 0.0083\n",
      "epoch 13 batch 73/185 loss = 0.0104\n",
      "epoch 13 batch 74/185 loss = 0.0148\n",
      "epoch 13 batch 75/185 loss = 0.0075\n",
      "epoch 13 batch 76/185 loss = 0.0081\n",
      "epoch 13 batch 77/185 loss = 0.0085\n",
      "epoch 13 batch 78/185 loss = 0.0115\n",
      "epoch 13 batch 79/185 loss = 0.0105\n",
      "epoch 13 batch 80/185 loss = 0.0092\n",
      "epoch 13 batch 81/185 loss = 0.0100\n",
      "epoch 13 batch 82/185 loss = 0.0095\n",
      "epoch 13 batch 83/185 loss = 0.0094\n",
      "epoch 13 batch 84/185 loss = 0.0125\n",
      "epoch 13 batch 85/185 loss = 0.0110\n",
      "epoch 13 batch 86/185 loss = 0.0123\n",
      "epoch 13 batch 87/185 loss = 0.0108\n",
      "epoch 13 batch 88/185 loss = 0.0098\n",
      "epoch 13 batch 89/185 loss = 0.0091\n",
      "epoch 13 batch 90/185 loss = 0.0120\n",
      "epoch 13 batch 91/185 loss = 0.0110\n",
      "epoch 13 batch 92/185 loss = 0.0082\n",
      "epoch 13 batch 93/185 loss = 0.0147\n",
      "epoch 13 batch 94/185 loss = 0.0095\n",
      "epoch 13 batch 95/185 loss = 0.0086\n",
      "epoch 13 batch 96/185 loss = 0.0110\n",
      "epoch 13 batch 97/185 loss = 0.0088\n",
      "epoch 13 batch 98/185 loss = 0.0114\n",
      "epoch 13 batch 99/185 loss = 0.0111\n",
      "epoch 13 batch 100/185 loss = 0.0111\n",
      "epoch 13 batch 101/185 loss = 0.0115\n",
      "epoch 13 batch 102/185 loss = 0.0104\n",
      "epoch 13 batch 103/185 loss = 0.0101\n",
      "epoch 13 batch 104/185 loss = 0.0099\n",
      "epoch 13 batch 105/185 loss = 0.0096\n",
      "epoch 13 batch 106/185 loss = 0.0145\n",
      "epoch 13 batch 107/185 loss = 0.0089\n",
      "epoch 13 batch 108/185 loss = 0.0101\n",
      "epoch 13 batch 109/185 loss = 0.0110\n",
      "epoch 13 batch 110/185 loss = 0.0103\n",
      "epoch 13 batch 111/185 loss = 0.0105\n",
      "epoch 13 batch 112/185 loss = 0.0107\n",
      "epoch 13 batch 113/185 loss = 0.0105\n",
      "epoch 13 batch 114/185 loss = 0.0122\n",
      "epoch 13 batch 115/185 loss = 0.0139\n",
      "epoch 13 batch 116/185 loss = 0.0099\n",
      "epoch 13 batch 117/185 loss = 0.0090\n",
      "epoch 13 batch 118/185 loss = 0.0105\n",
      "epoch 13 batch 119/185 loss = 0.0086\n",
      "epoch 13 batch 120/185 loss = 0.0096\n",
      "epoch 13 batch 121/185 loss = 0.0109\n",
      "epoch 13 batch 122/185 loss = 0.0095\n",
      "epoch 13 batch 123/185 loss = 0.0123\n",
      "epoch 13 batch 124/185 loss = 0.0128\n",
      "epoch 13 batch 125/185 loss = 0.0097\n",
      "epoch 13 batch 126/185 loss = 0.0121\n",
      "epoch 13 batch 127/185 loss = 0.0115\n",
      "epoch 13 batch 128/185 loss = 0.0107\n",
      "epoch 13 batch 129/185 loss = 0.0083\n",
      "epoch 13 batch 130/185 loss = 0.0121\n",
      "epoch 13 batch 131/185 loss = 0.0126\n",
      "epoch 13 batch 132/185 loss = 0.0109\n",
      "epoch 13 batch 133/185 loss = 0.0103\n",
      "epoch 13 batch 134/185 loss = 0.0124\n",
      "epoch 13 batch 135/185 loss = 0.0128\n",
      "epoch 13 batch 136/185 loss = 0.0120\n",
      "epoch 13 batch 137/185 loss = 0.0126\n",
      "epoch 13 batch 138/185 loss = 0.0086\n",
      "epoch 13 batch 139/185 loss = 0.0100\n",
      "epoch 13 batch 140/185 loss = 0.0111\n",
      "epoch 13 batch 141/185 loss = 0.0112\n",
      "epoch 13 batch 142/185 loss = 0.0124\n",
      "epoch 13 batch 143/185 loss = 0.0140\n",
      "epoch 13 batch 144/185 loss = 0.0105\n",
      "epoch 13 batch 145/185 loss = 0.0101\n",
      "epoch 13 batch 146/185 loss = 0.0145\n",
      "epoch 13 batch 147/185 loss = 0.0109\n",
      "epoch 13 batch 148/185 loss = 0.0099\n",
      "epoch 13 batch 149/185 loss = 0.0088\n",
      "epoch 13 batch 150/185 loss = 0.0113\n",
      "epoch 13 batch 151/185 loss = 0.0083\n",
      "epoch 13 batch 152/185 loss = 0.0092\n",
      "epoch 13 batch 153/185 loss = 0.0105\n",
      "epoch 13 batch 154/185 loss = 0.0107\n",
      "epoch 13 batch 155/185 loss = 0.0098\n",
      "epoch 13 batch 156/185 loss = 0.0098\n",
      "epoch 13 batch 157/185 loss = 0.0123\n",
      "epoch 13 batch 158/185 loss = 0.0113\n",
      "epoch 13 batch 159/185 loss = 0.0109\n",
      "epoch 13 batch 160/185 loss = 0.0107\n",
      "epoch 13 batch 161/185 loss = 0.0105\n",
      "epoch 13 batch 162/185 loss = 0.0103\n",
      "epoch 13 batch 163/185 loss = 0.0121\n",
      "epoch 13 batch 164/185 loss = 0.0095\n",
      "epoch 13 batch 165/185 loss = 0.0097\n",
      "epoch 13 batch 166/185 loss = 0.0115\n",
      "epoch 13 batch 167/185 loss = 0.0099\n",
      "epoch 13 batch 168/185 loss = 0.0103\n",
      "epoch 13 batch 169/185 loss = 0.0111\n",
      "epoch 13 batch 170/185 loss = 0.0110\n",
      "epoch 13 batch 171/185 loss = 0.0099\n",
      "epoch 13 batch 172/185 loss = 0.0103\n",
      "epoch 13 batch 173/185 loss = 0.0125\n",
      "epoch 13 batch 174/185 loss = 0.0100\n",
      "epoch 13 batch 175/185 loss = 0.0104\n",
      "epoch 13 batch 176/185 loss = 0.0090\n",
      "epoch 13 batch 177/185 loss = 0.0085\n",
      "epoch 13 batch 178/185 loss = 0.0117\n",
      "epoch 13 batch 179/185 loss = 0.0090\n",
      "epoch 13 batch 180/185 loss = 0.0090\n",
      "epoch 13 batch 181/185 loss = 0.0091\n",
      "epoch 13 batch 182/185 loss = 0.0087\n",
      "epoch 13 batch 183/185 loss = 0.0100\n",
      "epoch 13 batch 184/185 loss = 0.0114\n",
      "epoch 13 batch 185/185 loss = 0.0102\n",
      "epoch 13 train loss = 0.0105 valid loss = 0.0116\n",
      "epoch 14 batch 1/185 loss = 0.0099\n",
      "epoch 14 batch 2/185 loss = 0.0100\n",
      "epoch 14 batch 3/185 loss = 0.0111\n",
      "epoch 14 batch 4/185 loss = 0.0091\n",
      "epoch 14 batch 5/185 loss = 0.0112\n",
      "epoch 14 batch 6/185 loss = 0.0091\n",
      "epoch 14 batch 7/185 loss = 0.0126\n",
      "epoch 14 batch 8/185 loss = 0.0112\n",
      "epoch 14 batch 9/185 loss = 0.0084\n",
      "epoch 14 batch 10/185 loss = 0.0074\n",
      "epoch 14 batch 11/185 loss = 0.0095\n",
      "epoch 14 batch 12/185 loss = 0.0094\n",
      "epoch 14 batch 13/185 loss = 0.0091\n",
      "epoch 14 batch 14/185 loss = 0.0090\n",
      "epoch 14 batch 15/185 loss = 0.0125\n",
      "epoch 14 batch 16/185 loss = 0.0105\n",
      "epoch 14 batch 17/185 loss = 0.0089\n",
      "epoch 14 batch 18/185 loss = 0.0092\n",
      "epoch 14 batch 19/185 loss = 0.0103\n",
      "epoch 14 batch 20/185 loss = 0.0090\n",
      "epoch 14 batch 21/185 loss = 0.0113\n",
      "epoch 14 batch 22/185 loss = 0.0138\n",
      "epoch 14 batch 23/185 loss = 0.0074\n",
      "epoch 14 batch 24/185 loss = 0.0096\n",
      "epoch 14 batch 25/185 loss = 0.0111\n",
      "epoch 14 batch 26/185 loss = 0.0105\n",
      "epoch 14 batch 27/185 loss = 0.0095\n",
      "epoch 14 batch 28/185 loss = 0.0132\n",
      "epoch 14 batch 29/185 loss = 0.0138\n",
      "epoch 14 batch 30/185 loss = 0.0110\n",
      "epoch 14 batch 31/185 loss = 0.0112\n",
      "epoch 14 batch 32/185 loss = 0.0116\n",
      "epoch 14 batch 33/185 loss = 0.0113\n",
      "epoch 14 batch 34/185 loss = 0.0113\n",
      "epoch 14 batch 35/185 loss = 0.0114\n",
      "epoch 14 batch 36/185 loss = 0.0111\n",
      "epoch 14 batch 37/185 loss = 0.0107\n",
      "epoch 14 batch 38/185 loss = 0.0132\n",
      "epoch 14 batch 39/185 loss = 0.0109\n",
      "epoch 14 batch 40/185 loss = 0.0105\n",
      "epoch 14 batch 41/185 loss = 0.0138\n",
      "epoch 14 batch 42/185 loss = 0.0094\n",
      "epoch 14 batch 43/185 loss = 0.0114\n",
      "epoch 14 batch 44/185 loss = 0.0103\n",
      "epoch 14 batch 45/185 loss = 0.0097\n",
      "epoch 14 batch 46/185 loss = 0.0137\n",
      "epoch 14 batch 47/185 loss = 0.0090\n",
      "epoch 14 batch 48/185 loss = 0.0098\n",
      "epoch 14 batch 49/185 loss = 0.0110\n",
      "epoch 14 batch 50/185 loss = 0.0098\n",
      "epoch 14 batch 51/185 loss = 0.0103\n",
      "epoch 14 batch 52/185 loss = 0.0119\n",
      "epoch 14 batch 53/185 loss = 0.0125\n",
      "epoch 14 batch 54/185 loss = 0.0122\n",
      "epoch 14 batch 55/185 loss = 0.0107\n",
      "epoch 14 batch 56/185 loss = 0.0140\n",
      "epoch 14 batch 57/185 loss = 0.0096\n",
      "epoch 14 batch 58/185 loss = 0.0101\n",
      "epoch 14 batch 59/185 loss = 0.0133\n",
      "epoch 14 batch 60/185 loss = 0.0104\n",
      "epoch 14 batch 61/185 loss = 0.0074\n",
      "epoch 14 batch 62/185 loss = 0.0093\n",
      "epoch 14 batch 63/185 loss = 0.0118\n",
      "epoch 14 batch 64/185 loss = 0.0100\n",
      "epoch 14 batch 65/185 loss = 0.0102\n",
      "epoch 14 batch 66/185 loss = 0.0098\n",
      "epoch 14 batch 67/185 loss = 0.0076\n",
      "epoch 14 batch 68/185 loss = 0.0095\n",
      "epoch 14 batch 69/185 loss = 0.0092\n",
      "epoch 14 batch 70/185 loss = 0.0087\n",
      "epoch 14 batch 71/185 loss = 0.0079\n",
      "epoch 14 batch 72/185 loss = 0.0093\n",
      "epoch 14 batch 73/185 loss = 0.0137\n",
      "epoch 14 batch 74/185 loss = 0.0088\n",
      "epoch 14 batch 75/185 loss = 0.0107\n",
      "epoch 14 batch 76/185 loss = 0.0106\n",
      "epoch 14 batch 77/185 loss = 0.0085\n",
      "epoch 14 batch 78/185 loss = 0.0088\n",
      "epoch 14 batch 79/185 loss = 0.0084\n",
      "epoch 14 batch 80/185 loss = 0.0098\n",
      "epoch 14 batch 81/185 loss = 0.0106\n",
      "epoch 14 batch 82/185 loss = 0.0094\n",
      "epoch 14 batch 83/185 loss = 0.0099\n",
      "epoch 14 batch 84/185 loss = 0.0077\n",
      "epoch 14 batch 85/185 loss = 0.0112\n",
      "epoch 14 batch 86/185 loss = 0.0087\n",
      "epoch 14 batch 87/185 loss = 0.0094\n",
      "epoch 14 batch 88/185 loss = 0.0075\n",
      "epoch 14 batch 89/185 loss = 0.0104\n",
      "epoch 14 batch 90/185 loss = 0.0088\n",
      "epoch 14 batch 91/185 loss = 0.0114\n",
      "epoch 14 batch 92/185 loss = 0.0089\n",
      "epoch 14 batch 93/185 loss = 0.0099\n",
      "epoch 14 batch 94/185 loss = 0.0125\n",
      "epoch 14 batch 95/185 loss = 0.0113\n",
      "epoch 14 batch 96/185 loss = 0.0101\n",
      "epoch 14 batch 97/185 loss = 0.0112\n",
      "epoch 14 batch 98/185 loss = 0.0114\n",
      "epoch 14 batch 99/185 loss = 0.0109\n",
      "epoch 14 batch 100/185 loss = 0.0097\n",
      "epoch 14 batch 101/185 loss = 0.0100\n",
      "epoch 14 batch 102/185 loss = 0.0096\n",
      "epoch 14 batch 103/185 loss = 0.0101\n",
      "epoch 14 batch 104/185 loss = 0.0071\n",
      "epoch 14 batch 105/185 loss = 0.0095\n",
      "epoch 14 batch 106/185 loss = 0.0080\n",
      "epoch 14 batch 107/185 loss = 0.0084\n",
      "epoch 14 batch 108/185 loss = 0.0108\n",
      "epoch 14 batch 109/185 loss = 0.0099\n",
      "epoch 14 batch 110/185 loss = 0.0119\n",
      "epoch 14 batch 111/185 loss = 0.0088\n",
      "epoch 14 batch 112/185 loss = 0.0088\n",
      "epoch 14 batch 113/185 loss = 0.0081\n",
      "epoch 14 batch 114/185 loss = 0.0101\n",
      "epoch 14 batch 115/185 loss = 0.0117\n",
      "epoch 14 batch 116/185 loss = 0.0122\n",
      "epoch 14 batch 117/185 loss = 0.0092\n",
      "epoch 14 batch 118/185 loss = 0.0103\n",
      "epoch 14 batch 119/185 loss = 0.0095\n",
      "epoch 14 batch 120/185 loss = 0.0116\n",
      "epoch 14 batch 121/185 loss = 0.0108\n",
      "epoch 14 batch 122/185 loss = 0.0092\n",
      "epoch 14 batch 123/185 loss = 0.0094\n",
      "epoch 14 batch 124/185 loss = 0.0119\n",
      "epoch 14 batch 125/185 loss = 0.0080\n",
      "epoch 14 batch 126/185 loss = 0.0109\n",
      "epoch 14 batch 127/185 loss = 0.0093\n",
      "epoch 14 batch 128/185 loss = 0.0102\n",
      "epoch 14 batch 129/185 loss = 0.0095\n",
      "epoch 14 batch 130/185 loss = 0.0116\n",
      "epoch 14 batch 131/185 loss = 0.0118\n",
      "epoch 14 batch 132/185 loss = 0.0117\n",
      "epoch 14 batch 133/185 loss = 0.0126\n",
      "epoch 14 batch 134/185 loss = 0.0115\n",
      "epoch 14 batch 135/185 loss = 0.0097\n",
      "epoch 14 batch 136/185 loss = 0.0094\n",
      "epoch 14 batch 137/185 loss = 0.0104\n",
      "epoch 14 batch 138/185 loss = 0.0089\n",
      "epoch 14 batch 139/185 loss = 0.0101\n",
      "epoch 14 batch 140/185 loss = 0.0123\n",
      "epoch 14 batch 141/185 loss = 0.0084\n",
      "epoch 14 batch 142/185 loss = 0.0113\n",
      "epoch 14 batch 143/185 loss = 0.0096\n",
      "epoch 14 batch 144/185 loss = 0.0109\n",
      "epoch 14 batch 145/185 loss = 0.0092\n",
      "epoch 14 batch 146/185 loss = 0.0118\n",
      "epoch 14 batch 147/185 loss = 0.0124\n",
      "epoch 14 batch 148/185 loss = 0.0119\n",
      "epoch 14 batch 149/185 loss = 0.0134\n",
      "epoch 14 batch 150/185 loss = 0.0087\n",
      "epoch 14 batch 151/185 loss = 0.0106\n",
      "epoch 14 batch 152/185 loss = 0.0104\n",
      "epoch 14 batch 153/185 loss = 0.0100\n",
      "epoch 14 batch 154/185 loss = 0.0094\n",
      "epoch 14 batch 155/185 loss = 0.0084\n",
      "epoch 14 batch 156/185 loss = 0.0109\n",
      "epoch 14 batch 157/185 loss = 0.0104\n",
      "epoch 14 batch 158/185 loss = 0.0118\n",
      "epoch 14 batch 159/185 loss = 0.0106\n",
      "epoch 14 batch 160/185 loss = 0.0102\n",
      "epoch 14 batch 161/185 loss = 0.0103\n",
      "epoch 14 batch 162/185 loss = 0.0098\n",
      "epoch 14 batch 163/185 loss = 0.0082\n",
      "epoch 14 batch 164/185 loss = 0.0070\n",
      "epoch 14 batch 165/185 loss = 0.0088\n",
      "epoch 14 batch 166/185 loss = 0.0090\n",
      "epoch 14 batch 167/185 loss = 0.0090\n",
      "epoch 14 batch 168/185 loss = 0.0085\n",
      "epoch 14 batch 169/185 loss = 0.0103\n",
      "epoch 14 batch 170/185 loss = 0.0129\n",
      "epoch 14 batch 171/185 loss = 0.0106\n",
      "epoch 14 batch 172/185 loss = 0.0110\n",
      "epoch 14 batch 173/185 loss = 0.0083\n",
      "epoch 14 batch 174/185 loss = 0.0091\n",
      "epoch 14 batch 175/185 loss = 0.0118\n",
      "epoch 14 batch 176/185 loss = 0.0086\n",
      "epoch 14 batch 177/185 loss = 0.0117\n",
      "epoch 14 batch 178/185 loss = 0.0109\n",
      "epoch 14 batch 179/185 loss = 0.0139\n",
      "epoch 14 batch 180/185 loss = 0.0120\n",
      "epoch 14 batch 181/185 loss = 0.0103\n",
      "epoch 14 batch 182/185 loss = 0.0082\n",
      "epoch 14 batch 183/185 loss = 0.0097\n",
      "epoch 14 batch 184/185 loss = 0.0101\n",
      "epoch 14 batch 185/185 loss = 0.0117\n",
      "epoch 14 train loss = 0.0103 valid loss = 0.0131\n",
      "performance reducing: counter 1\n",
      "epoch 15 batch 1/185 loss = 0.0085\n",
      "epoch 15 batch 2/185 loss = 0.0112\n",
      "epoch 15 batch 3/185 loss = 0.0112\n",
      "epoch 15 batch 4/185 loss = 0.0091\n",
      "epoch 15 batch 5/185 loss = 0.0129\n",
      "epoch 15 batch 6/185 loss = 0.0090\n",
      "epoch 15 batch 7/185 loss = 0.0105\n",
      "epoch 15 batch 8/185 loss = 0.0103\n",
      "epoch 15 batch 9/185 loss = 0.0119\n",
      "epoch 15 batch 10/185 loss = 0.0117\n",
      "epoch 15 batch 11/185 loss = 0.0133\n",
      "epoch 15 batch 12/185 loss = 0.0096\n",
      "epoch 15 batch 13/185 loss = 0.0099\n",
      "epoch 15 batch 14/185 loss = 0.0092\n",
      "epoch 15 batch 15/185 loss = 0.0092\n",
      "epoch 15 batch 16/185 loss = 0.0098\n",
      "epoch 15 batch 17/185 loss = 0.0121\n",
      "epoch 15 batch 18/185 loss = 0.0103\n",
      "epoch 15 batch 19/185 loss = 0.0090\n",
      "epoch 15 batch 20/185 loss = 0.0091\n",
      "epoch 15 batch 21/185 loss = 0.0115\n",
      "epoch 15 batch 22/185 loss = 0.0094\n",
      "epoch 15 batch 23/185 loss = 0.0091\n",
      "epoch 15 batch 24/185 loss = 0.0120\n",
      "epoch 15 batch 25/185 loss = 0.0095\n",
      "epoch 15 batch 26/185 loss = 0.0100\n",
      "epoch 15 batch 27/185 loss = 0.0087\n",
      "epoch 15 batch 28/185 loss = 0.0126\n",
      "epoch 15 batch 29/185 loss = 0.0104\n",
      "epoch 15 batch 30/185 loss = 0.0083\n",
      "epoch 15 batch 31/185 loss = 0.0099\n",
      "epoch 15 batch 32/185 loss = 0.0099\n",
      "epoch 15 batch 33/185 loss = 0.0122\n",
      "epoch 15 batch 34/185 loss = 0.0082\n",
      "epoch 15 batch 35/185 loss = 0.0086\n",
      "epoch 15 batch 36/185 loss = 0.0086\n",
      "epoch 15 batch 37/185 loss = 0.0097\n",
      "epoch 15 batch 38/185 loss = 0.0126\n",
      "epoch 15 batch 39/185 loss = 0.0091\n",
      "epoch 15 batch 40/185 loss = 0.0109\n",
      "epoch 15 batch 41/185 loss = 0.0104\n",
      "epoch 15 batch 42/185 loss = 0.0117\n",
      "epoch 15 batch 43/185 loss = 0.0095\n",
      "epoch 15 batch 44/185 loss = 0.0089\n",
      "epoch 15 batch 45/185 loss = 0.0095\n",
      "epoch 15 batch 46/185 loss = 0.0105\n",
      "epoch 15 batch 47/185 loss = 0.0103\n",
      "epoch 15 batch 48/185 loss = 0.0109\n",
      "epoch 15 batch 49/185 loss = 0.0097\n",
      "epoch 15 batch 50/185 loss = 0.0087\n",
      "epoch 15 batch 51/185 loss = 0.0086\n",
      "epoch 15 batch 52/185 loss = 0.0087\n",
      "epoch 15 batch 53/185 loss = 0.0078\n",
      "epoch 15 batch 54/185 loss = 0.0076\n",
      "epoch 15 batch 55/185 loss = 0.0090\n",
      "epoch 15 batch 56/185 loss = 0.0104\n",
      "epoch 15 batch 57/185 loss = 0.0089\n",
      "epoch 15 batch 58/185 loss = 0.0105\n",
      "epoch 15 batch 59/185 loss = 0.0116\n",
      "epoch 15 batch 60/185 loss = 0.0099\n",
      "epoch 15 batch 61/185 loss = 0.0106\n",
      "epoch 15 batch 62/185 loss = 0.0107\n",
      "epoch 15 batch 63/185 loss = 0.0098\n",
      "epoch 15 batch 64/185 loss = 0.0109\n",
      "epoch 15 batch 65/185 loss = 0.0115\n",
      "epoch 15 batch 66/185 loss = 0.0106\n",
      "epoch 15 batch 67/185 loss = 0.0102\n",
      "epoch 15 batch 68/185 loss = 0.0100\n",
      "epoch 15 batch 69/185 loss = 0.0115\n",
      "epoch 15 batch 70/185 loss = 0.0098\n",
      "epoch 15 batch 71/185 loss = 0.0107\n",
      "epoch 15 batch 72/185 loss = 0.0099\n",
      "epoch 15 batch 73/185 loss = 0.0121\n",
      "epoch 15 batch 74/185 loss = 0.0071\n",
      "epoch 15 batch 75/185 loss = 0.0086\n",
      "epoch 15 batch 76/185 loss = 0.0095\n",
      "epoch 15 batch 77/185 loss = 0.0097\n",
      "epoch 15 batch 78/185 loss = 0.0098\n",
      "epoch 15 batch 79/185 loss = 0.0107\n",
      "epoch 15 batch 80/185 loss = 0.0085\n",
      "epoch 15 batch 81/185 loss = 0.0091\n",
      "epoch 15 batch 82/185 loss = 0.0087\n",
      "epoch 15 batch 83/185 loss = 0.0101\n",
      "epoch 15 batch 84/185 loss = 0.0098\n",
      "epoch 15 batch 85/185 loss = 0.0074\n",
      "epoch 15 batch 86/185 loss = 0.0126\n",
      "epoch 15 batch 87/185 loss = 0.0092\n",
      "epoch 15 batch 88/185 loss = 0.0094\n",
      "epoch 15 batch 89/185 loss = 0.0088\n",
      "epoch 15 batch 90/185 loss = 0.0096\n",
      "epoch 15 batch 91/185 loss = 0.0102\n",
      "epoch 15 batch 92/185 loss = 0.0092\n",
      "epoch 15 batch 93/185 loss = 0.0090\n",
      "epoch 15 batch 94/185 loss = 0.0122\n",
      "epoch 15 batch 95/185 loss = 0.0097\n",
      "epoch 15 batch 96/185 loss = 0.0089\n",
      "epoch 15 batch 97/185 loss = 0.0106\n",
      "epoch 15 batch 98/185 loss = 0.0101\n",
      "epoch 15 batch 99/185 loss = 0.0107\n",
      "epoch 15 batch 100/185 loss = 0.0107\n",
      "epoch 15 batch 101/185 loss = 0.0077\n",
      "epoch 15 batch 102/185 loss = 0.0128\n",
      "epoch 15 batch 103/185 loss = 0.0096\n",
      "epoch 15 batch 104/185 loss = 0.0119\n",
      "epoch 15 batch 105/185 loss = 0.0099\n",
      "epoch 15 batch 106/185 loss = 0.0102\n",
      "epoch 15 batch 107/185 loss = 0.0118\n",
      "epoch 15 batch 108/185 loss = 0.0140\n",
      "epoch 15 batch 109/185 loss = 0.0133\n",
      "epoch 15 batch 110/185 loss = 0.0104\n",
      "epoch 15 batch 111/185 loss = 0.0097\n",
      "epoch 15 batch 112/185 loss = 0.0087\n",
      "epoch 15 batch 113/185 loss = 0.0113\n",
      "epoch 15 batch 114/185 loss = 0.0108\n",
      "epoch 15 batch 115/185 loss = 0.0112\n",
      "epoch 15 batch 116/185 loss = 0.0081\n",
      "epoch 15 batch 117/185 loss = 0.0098\n",
      "epoch 15 batch 118/185 loss = 0.0103\n",
      "epoch 15 batch 119/185 loss = 0.0080\n",
      "epoch 15 batch 120/185 loss = 0.0098\n",
      "epoch 15 batch 121/185 loss = 0.0102\n",
      "epoch 15 batch 122/185 loss = 0.0094\n",
      "epoch 15 batch 123/185 loss = 0.0074\n",
      "epoch 15 batch 124/185 loss = 0.0114\n",
      "epoch 15 batch 125/185 loss = 0.0101\n",
      "epoch 15 batch 126/185 loss = 0.0098\n",
      "epoch 15 batch 127/185 loss = 0.0085\n",
      "epoch 15 batch 128/185 loss = 0.0111\n",
      "epoch 15 batch 129/185 loss = 0.0098\n",
      "epoch 15 batch 130/185 loss = 0.0101\n",
      "epoch 15 batch 131/185 loss = 0.0119\n",
      "epoch 15 batch 132/185 loss = 0.0076\n",
      "epoch 15 batch 133/185 loss = 0.0098\n",
      "epoch 15 batch 134/185 loss = 0.0108\n",
      "epoch 15 batch 135/185 loss = 0.0129\n",
      "epoch 15 batch 136/185 loss = 0.0107\n",
      "epoch 15 batch 137/185 loss = 0.0122\n",
      "epoch 15 batch 138/185 loss = 0.0100\n",
      "epoch 15 batch 139/185 loss = 0.0122\n",
      "epoch 15 batch 140/185 loss = 0.0110\n",
      "epoch 15 batch 141/185 loss = 0.0101\n",
      "epoch 15 batch 142/185 loss = 0.0112\n",
      "epoch 15 batch 143/185 loss = 0.0106\n",
      "epoch 15 batch 144/185 loss = 0.0093\n",
      "epoch 15 batch 145/185 loss = 0.0107\n",
      "epoch 15 batch 146/185 loss = 0.0130\n",
      "epoch 15 batch 147/185 loss = 0.0088\n",
      "epoch 15 batch 148/185 loss = 0.0073\n",
      "epoch 15 batch 149/185 loss = 0.0129\n",
      "epoch 15 batch 150/185 loss = 0.0097\n",
      "epoch 15 batch 151/185 loss = 0.0090\n",
      "epoch 15 batch 152/185 loss = 0.0127\n",
      "epoch 15 batch 153/185 loss = 0.0106\n",
      "epoch 15 batch 154/185 loss = 0.0091\n",
      "epoch 15 batch 155/185 loss = 0.0130\n",
      "epoch 15 batch 156/185 loss = 0.0090\n",
      "epoch 15 batch 157/185 loss = 0.0105\n",
      "epoch 15 batch 158/185 loss = 0.0099\n",
      "epoch 15 batch 159/185 loss = 0.0086\n",
      "epoch 15 batch 160/185 loss = 0.0099\n",
      "epoch 15 batch 161/185 loss = 0.0106\n",
      "epoch 15 batch 162/185 loss = 0.0095\n",
      "epoch 15 batch 163/185 loss = 0.0083\n",
      "epoch 15 batch 164/185 loss = 0.0104\n",
      "epoch 15 batch 165/185 loss = 0.0097\n",
      "epoch 15 batch 166/185 loss = 0.0078\n",
      "epoch 15 batch 167/185 loss = 0.0084\n",
      "epoch 15 batch 168/185 loss = 0.0092\n",
      "epoch 15 batch 169/185 loss = 0.0108\n",
      "epoch 15 batch 170/185 loss = 0.0126\n",
      "epoch 15 batch 171/185 loss = 0.0091\n",
      "epoch 15 batch 172/185 loss = 0.0106\n",
      "epoch 15 batch 173/185 loss = 0.0096\n",
      "epoch 15 batch 174/185 loss = 0.0105\n",
      "epoch 15 batch 175/185 loss = 0.0127\n",
      "epoch 15 batch 176/185 loss = 0.0117\n",
      "epoch 15 batch 177/185 loss = 0.0112\n",
      "epoch 15 batch 178/185 loss = 0.0094\n",
      "epoch 15 batch 179/185 loss = 0.0133\n",
      "epoch 15 batch 180/185 loss = 0.0102\n",
      "epoch 15 batch 181/185 loss = 0.0081\n",
      "epoch 15 batch 182/185 loss = 0.0108\n",
      "epoch 15 batch 183/185 loss = 0.0112\n",
      "epoch 15 batch 184/185 loss = 0.0103\n",
      "epoch 15 batch 185/185 loss = 0.0095\n",
      "epoch 15 train loss = 0.0102 valid loss = 0.0118\n",
      "performance reducing: counter 2\n",
      "epoch 16 batch 1/185 loss = 0.0105\n",
      "epoch 16 batch 2/185 loss = 0.0101\n",
      "epoch 16 batch 3/185 loss = 0.0088\n",
      "epoch 16 batch 4/185 loss = 0.0105\n",
      "epoch 16 batch 5/185 loss = 0.0092\n",
      "epoch 16 batch 6/185 loss = 0.0119\n",
      "epoch 16 batch 7/185 loss = 0.0119\n",
      "epoch 16 batch 8/185 loss = 0.0143\n",
      "epoch 16 batch 9/185 loss = 0.0106\n",
      "epoch 16 batch 10/185 loss = 0.0093\n",
      "epoch 16 batch 11/185 loss = 0.0082\n",
      "epoch 16 batch 12/185 loss = 0.0119\n",
      "epoch 16 batch 13/185 loss = 0.0093\n",
      "epoch 16 batch 14/185 loss = 0.0089\n",
      "epoch 16 batch 15/185 loss = 0.0087\n",
      "epoch 16 batch 16/185 loss = 0.0108\n",
      "epoch 16 batch 17/185 loss = 0.0110\n",
      "epoch 16 batch 18/185 loss = 0.0114\n",
      "epoch 16 batch 19/185 loss = 0.0106\n",
      "epoch 16 batch 20/185 loss = 0.0109\n",
      "epoch 16 batch 21/185 loss = 0.0100\n",
      "epoch 16 batch 22/185 loss = 0.0090\n",
      "epoch 16 batch 23/185 loss = 0.0105\n",
      "epoch 16 batch 24/185 loss = 0.0093\n",
      "epoch 16 batch 25/185 loss = 0.0099\n",
      "epoch 16 batch 26/185 loss = 0.0106\n",
      "epoch 16 batch 27/185 loss = 0.0120\n",
      "epoch 16 batch 28/185 loss = 0.0108\n",
      "epoch 16 batch 29/185 loss = 0.0089\n",
      "epoch 16 batch 30/185 loss = 0.0114\n",
      "epoch 16 batch 31/185 loss = 0.0086\n",
      "epoch 16 batch 32/185 loss = 0.0123\n",
      "epoch 16 batch 33/185 loss = 0.0104\n",
      "epoch 16 batch 34/185 loss = 0.0090\n",
      "epoch 16 batch 35/185 loss = 0.0075\n",
      "epoch 16 batch 36/185 loss = 0.0093\n",
      "epoch 16 batch 37/185 loss = 0.0097\n",
      "epoch 16 batch 38/185 loss = 0.0108\n",
      "epoch 16 batch 39/185 loss = 0.0086\n",
      "epoch 16 batch 40/185 loss = 0.0105\n",
      "epoch 16 batch 41/185 loss = 0.0100\n",
      "epoch 16 batch 42/185 loss = 0.0126\n",
      "epoch 16 batch 43/185 loss = 0.0098\n",
      "epoch 16 batch 44/185 loss = 0.0103\n",
      "epoch 16 batch 45/185 loss = 0.0114\n",
      "epoch 16 batch 46/185 loss = 0.0092\n",
      "epoch 16 batch 47/185 loss = 0.0071\n",
      "epoch 16 batch 48/185 loss = 0.0110\n",
      "epoch 16 batch 49/185 loss = 0.0085\n",
      "epoch 16 batch 50/185 loss = 0.0082\n",
      "epoch 16 batch 51/185 loss = 0.0099\n",
      "epoch 16 batch 52/185 loss = 0.0080\n",
      "epoch 16 batch 53/185 loss = 0.0094\n",
      "epoch 16 batch 54/185 loss = 0.0109\n",
      "epoch 16 batch 55/185 loss = 0.0103\n",
      "epoch 16 batch 56/185 loss = 0.0088\n",
      "epoch 16 batch 57/185 loss = 0.0101\n",
      "epoch 16 batch 58/185 loss = 0.0074\n",
      "epoch 16 batch 59/185 loss = 0.0097\n",
      "epoch 16 batch 60/185 loss = 0.0089\n",
      "epoch 16 batch 61/185 loss = 0.0089\n",
      "epoch 16 batch 62/185 loss = 0.0078\n",
      "epoch 16 batch 63/185 loss = 0.0106\n",
      "epoch 16 batch 64/185 loss = 0.0112\n",
      "epoch 16 batch 65/185 loss = 0.0125\n",
      "epoch 16 batch 66/185 loss = 0.0104\n",
      "epoch 16 batch 67/185 loss = 0.0091\n",
      "epoch 16 batch 68/185 loss = 0.0102\n",
      "epoch 16 batch 69/185 loss = 0.0115\n",
      "epoch 16 batch 70/185 loss = 0.0110\n",
      "epoch 16 batch 71/185 loss = 0.0123\n",
      "epoch 16 batch 72/185 loss = 0.0116\n",
      "epoch 16 batch 73/185 loss = 0.0096\n",
      "epoch 16 batch 74/185 loss = 0.0125\n",
      "epoch 16 batch 75/185 loss = 0.0090\n",
      "epoch 16 batch 76/185 loss = 0.0088\n",
      "epoch 16 batch 77/185 loss = 0.0100\n",
      "epoch 16 batch 78/185 loss = 0.0078\n",
      "epoch 16 batch 79/185 loss = 0.0095\n",
      "epoch 16 batch 80/185 loss = 0.0089\n",
      "epoch 16 batch 81/185 loss = 0.0089\n",
      "epoch 16 batch 82/185 loss = 0.0119\n",
      "epoch 16 batch 83/185 loss = 0.0092\n",
      "epoch 16 batch 84/185 loss = 0.0085\n",
      "epoch 16 batch 85/185 loss = 0.0107\n",
      "epoch 16 batch 86/185 loss = 0.0094\n",
      "epoch 16 batch 87/185 loss = 0.0142\n",
      "epoch 16 batch 88/185 loss = 0.0118\n",
      "epoch 16 batch 89/185 loss = 0.0090\n",
      "epoch 16 batch 90/185 loss = 0.0112\n",
      "epoch 16 batch 91/185 loss = 0.0109\n",
      "epoch 16 batch 92/185 loss = 0.0113\n",
      "epoch 16 batch 93/185 loss = 0.0097\n",
      "epoch 16 batch 94/185 loss = 0.0079\n",
      "epoch 16 batch 95/185 loss = 0.0088\n",
      "epoch 16 batch 96/185 loss = 0.0116\n",
      "epoch 16 batch 97/185 loss = 0.0119\n",
      "epoch 16 batch 98/185 loss = 0.0074\n",
      "epoch 16 batch 99/185 loss = 0.0097\n",
      "epoch 16 batch 100/185 loss = 0.0121\n",
      "epoch 16 batch 101/185 loss = 0.0129\n",
      "epoch 16 batch 102/185 loss = 0.0092\n",
      "epoch 16 batch 103/185 loss = 0.0107\n",
      "epoch 16 batch 104/185 loss = 0.0111\n",
      "epoch 16 batch 105/185 loss = 0.0098\n",
      "epoch 16 batch 106/185 loss = 0.0096\n",
      "epoch 16 batch 107/185 loss = 0.0138\n",
      "epoch 16 batch 108/185 loss = 0.0083\n",
      "epoch 16 batch 109/185 loss = 0.0085\n",
      "epoch 16 batch 110/185 loss = 0.0106\n",
      "epoch 16 batch 111/185 loss = 0.0127\n",
      "epoch 16 batch 112/185 loss = 0.0093\n",
      "epoch 16 batch 113/185 loss = 0.0099\n",
      "epoch 16 batch 114/185 loss = 0.0096\n",
      "epoch 16 batch 115/185 loss = 0.0118\n",
      "epoch 16 batch 116/185 loss = 0.0117\n",
      "epoch 16 batch 117/185 loss = 0.0110\n",
      "epoch 16 batch 118/185 loss = 0.0091\n",
      "epoch 16 batch 119/185 loss = 0.0084\n",
      "epoch 16 batch 120/185 loss = 0.0117\n",
      "epoch 16 batch 121/185 loss = 0.0104\n",
      "epoch 16 batch 122/185 loss = 0.0143\n",
      "epoch 16 batch 123/185 loss = 0.0093\n",
      "epoch 16 batch 124/185 loss = 0.0112\n",
      "epoch 16 batch 125/185 loss = 0.0095\n",
      "epoch 16 batch 126/185 loss = 0.0105\n",
      "epoch 16 batch 127/185 loss = 0.0091\n",
      "epoch 16 batch 128/185 loss = 0.0095\n",
      "epoch 16 batch 129/185 loss = 0.0075\n",
      "epoch 16 batch 130/185 loss = 0.0090\n",
      "epoch 16 batch 131/185 loss = 0.0088\n",
      "epoch 16 batch 132/185 loss = 0.0100\n",
      "epoch 16 batch 133/185 loss = 0.0097\n",
      "epoch 16 batch 134/185 loss = 0.0110\n",
      "epoch 16 batch 135/185 loss = 0.0094\n",
      "epoch 16 batch 136/185 loss = 0.0094\n",
      "epoch 16 batch 137/185 loss = 0.0113\n",
      "epoch 16 batch 138/185 loss = 0.0087\n",
      "epoch 16 batch 139/185 loss = 0.0071\n",
      "epoch 16 batch 140/185 loss = 0.0111\n",
      "epoch 16 batch 141/185 loss = 0.0089\n",
      "epoch 16 batch 142/185 loss = 0.0109\n",
      "epoch 16 batch 143/185 loss = 0.0085\n",
      "epoch 16 batch 144/185 loss = 0.0113\n",
      "epoch 16 batch 145/185 loss = 0.0134\n",
      "epoch 16 batch 146/185 loss = 0.0078\n",
      "epoch 16 batch 147/185 loss = 0.0083\n",
      "epoch 16 batch 148/185 loss = 0.0103\n",
      "epoch 16 batch 149/185 loss = 0.0090\n",
      "epoch 16 batch 150/185 loss = 0.0104\n",
      "epoch 16 batch 151/185 loss = 0.0086\n",
      "epoch 16 batch 152/185 loss = 0.0122\n",
      "epoch 16 batch 153/185 loss = 0.0097\n",
      "epoch 16 batch 154/185 loss = 0.0088\n",
      "epoch 16 batch 155/185 loss = 0.0104\n",
      "epoch 16 batch 156/185 loss = 0.0096\n",
      "epoch 16 batch 157/185 loss = 0.0106\n",
      "epoch 16 batch 158/185 loss = 0.0104\n",
      "epoch 16 batch 159/185 loss = 0.0070\n",
      "epoch 16 batch 160/185 loss = 0.0104\n",
      "epoch 16 batch 161/185 loss = 0.0102\n",
      "epoch 16 batch 162/185 loss = 0.0101\n",
      "epoch 16 batch 163/185 loss = 0.0117\n",
      "epoch 16 batch 164/185 loss = 0.0090\n",
      "epoch 16 batch 165/185 loss = 0.0088\n",
      "epoch 16 batch 166/185 loss = 0.0106\n",
      "epoch 16 batch 167/185 loss = 0.0088\n",
      "epoch 16 batch 168/185 loss = 0.0078\n",
      "epoch 16 batch 169/185 loss = 0.0083\n",
      "epoch 16 batch 170/185 loss = 0.0103\n",
      "epoch 16 batch 171/185 loss = 0.0097\n",
      "epoch 16 batch 172/185 loss = 0.0107\n",
      "epoch 16 batch 173/185 loss = 0.0084\n",
      "epoch 16 batch 174/185 loss = 0.0112\n",
      "epoch 16 batch 175/185 loss = 0.0088\n",
      "epoch 16 batch 176/185 loss = 0.0112\n",
      "epoch 16 batch 177/185 loss = 0.0093\n",
      "epoch 16 batch 178/185 loss = 0.0106\n",
      "epoch 16 batch 179/185 loss = 0.0120\n",
      "epoch 16 batch 180/185 loss = 0.0090\n",
      "epoch 16 batch 181/185 loss = 0.0091\n",
      "epoch 16 batch 182/185 loss = 0.0081\n",
      "epoch 16 batch 183/185 loss = 0.0122\n",
      "epoch 16 batch 184/185 loss = 0.0089\n",
      "epoch 16 batch 185/185 loss = 0.0094\n",
      "epoch 16 train loss = 0.0100 valid loss = 0.0124\n",
      "performance reducing: counter 3\n",
      "epoch 17 batch 1/185 loss = 0.0101\n",
      "epoch 17 batch 2/185 loss = 0.0098\n",
      "epoch 17 batch 3/185 loss = 0.0086\n",
      "epoch 17 batch 4/185 loss = 0.0111\n",
      "epoch 17 batch 5/185 loss = 0.0098\n",
      "epoch 17 batch 6/185 loss = 0.0088\n",
      "epoch 17 batch 7/185 loss = 0.0091\n",
      "epoch 17 batch 8/185 loss = 0.0123\n",
      "epoch 17 batch 9/185 loss = 0.0088\n",
      "epoch 17 batch 10/185 loss = 0.0094\n",
      "epoch 17 batch 11/185 loss = 0.0086\n",
      "epoch 17 batch 12/185 loss = 0.0095\n",
      "epoch 17 batch 13/185 loss = 0.0081\n",
      "epoch 17 batch 14/185 loss = 0.0112\n",
      "epoch 17 batch 15/185 loss = 0.0126\n",
      "epoch 17 batch 16/185 loss = 0.0119\n",
      "epoch 17 batch 17/185 loss = 0.0108\n",
      "epoch 17 batch 18/185 loss = 0.0097\n",
      "epoch 17 batch 19/185 loss = 0.0090\n",
      "epoch 17 batch 20/185 loss = 0.0114\n",
      "epoch 17 batch 21/185 loss = 0.0106\n",
      "epoch 17 batch 22/185 loss = 0.0110\n",
      "epoch 17 batch 23/185 loss = 0.0107\n",
      "epoch 17 batch 24/185 loss = 0.0098\n",
      "epoch 17 batch 25/185 loss = 0.0077\n",
      "epoch 17 batch 26/185 loss = 0.0093\n",
      "epoch 17 batch 27/185 loss = 0.0102\n",
      "epoch 17 batch 28/185 loss = 0.0099\n",
      "epoch 17 batch 29/185 loss = 0.0088\n",
      "epoch 17 batch 30/185 loss = 0.0110\n",
      "epoch 17 batch 31/185 loss = 0.0091\n",
      "epoch 17 batch 32/185 loss = 0.0084\n",
      "epoch 17 batch 33/185 loss = 0.0072\n",
      "epoch 17 batch 34/185 loss = 0.0101\n",
      "epoch 17 batch 35/185 loss = 0.0089\n",
      "epoch 17 batch 36/185 loss = 0.0097\n",
      "epoch 17 batch 37/185 loss = 0.0078\n",
      "epoch 17 batch 38/185 loss = 0.0117\n",
      "epoch 17 batch 39/185 loss = 0.0107\n",
      "epoch 17 batch 40/185 loss = 0.0069\n",
      "epoch 17 batch 41/185 loss = 0.0100\n",
      "epoch 17 batch 42/185 loss = 0.0115\n",
      "epoch 17 batch 43/185 loss = 0.0089\n",
      "epoch 17 batch 44/185 loss = 0.0101\n",
      "epoch 17 batch 45/185 loss = 0.0110\n",
      "epoch 17 batch 46/185 loss = 0.0105\n",
      "epoch 17 batch 47/185 loss = 0.0107\n",
      "epoch 17 batch 48/185 loss = 0.0099\n",
      "epoch 17 batch 49/185 loss = 0.0086\n",
      "epoch 17 batch 50/185 loss = 0.0074\n",
      "epoch 17 batch 51/185 loss = 0.0103\n",
      "epoch 17 batch 52/185 loss = 0.0086\n",
      "epoch 17 batch 53/185 loss = 0.0123\n",
      "epoch 17 batch 54/185 loss = 0.0099\n",
      "epoch 17 batch 55/185 loss = 0.0092\n",
      "epoch 17 batch 56/185 loss = 0.0101\n",
      "epoch 17 batch 57/185 loss = 0.0094\n",
      "epoch 17 batch 58/185 loss = 0.0103\n",
      "epoch 17 batch 59/185 loss = 0.0086\n",
      "epoch 17 batch 60/185 loss = 0.0087\n",
      "epoch 17 batch 61/185 loss = 0.0105\n",
      "epoch 17 batch 62/185 loss = 0.0098\n",
      "epoch 17 batch 63/185 loss = 0.0087\n",
      "epoch 17 batch 64/185 loss = 0.0112\n",
      "epoch 17 batch 65/185 loss = 0.0088\n",
      "epoch 17 batch 66/185 loss = 0.0121\n",
      "epoch 17 batch 67/185 loss = 0.0098\n",
      "epoch 17 batch 68/185 loss = 0.0100\n",
      "epoch 17 batch 69/185 loss = 0.0141\n",
      "epoch 17 batch 70/185 loss = 0.0100\n",
      "epoch 17 batch 71/185 loss = 0.0104\n",
      "epoch 17 batch 72/185 loss = 0.0106\n",
      "epoch 17 batch 73/185 loss = 0.0111\n",
      "epoch 17 batch 74/185 loss = 0.0115\n",
      "epoch 17 batch 75/185 loss = 0.0124\n",
      "epoch 17 batch 76/185 loss = 0.0096\n",
      "epoch 17 batch 77/185 loss = 0.0091\n",
      "epoch 17 batch 78/185 loss = 0.0089\n",
      "epoch 17 batch 79/185 loss = 0.0078\n",
      "epoch 17 batch 80/185 loss = 0.0094\n",
      "epoch 17 batch 81/185 loss = 0.0110\n",
      "epoch 17 batch 82/185 loss = 0.0079\n",
      "epoch 17 batch 83/185 loss = 0.0092\n",
      "epoch 17 batch 84/185 loss = 0.0090\n",
      "epoch 17 batch 85/185 loss = 0.0085\n",
      "epoch 17 batch 86/185 loss = 0.0115\n",
      "epoch 17 batch 87/185 loss = 0.0092\n",
      "epoch 17 batch 88/185 loss = 0.0079\n",
      "epoch 17 batch 89/185 loss = 0.0114\n",
      "epoch 17 batch 90/185 loss = 0.0087\n",
      "epoch 17 batch 91/185 loss = 0.0086\n",
      "epoch 17 batch 92/185 loss = 0.0098\n",
      "epoch 17 batch 93/185 loss = 0.0116\n",
      "epoch 17 batch 94/185 loss = 0.0098\n",
      "epoch 17 batch 95/185 loss = 0.0138\n",
      "epoch 17 batch 96/185 loss = 0.0118\n",
      "epoch 17 batch 97/185 loss = 0.0107\n",
      "epoch 17 batch 98/185 loss = 0.0102\n",
      "epoch 17 batch 99/185 loss = 0.0096\n",
      "epoch 17 batch 100/185 loss = 0.0117\n",
      "epoch 17 batch 101/185 loss = 0.0100\n",
      "epoch 17 batch 102/185 loss = 0.0123\n",
      "epoch 17 batch 103/185 loss = 0.0092\n",
      "epoch 17 batch 104/185 loss = 0.0083\n",
      "epoch 17 batch 105/185 loss = 0.0093\n",
      "epoch 17 batch 106/185 loss = 0.0096\n",
      "epoch 17 batch 107/185 loss = 0.0123\n",
      "epoch 17 batch 108/185 loss = 0.0086\n",
      "epoch 17 batch 109/185 loss = 0.0092\n",
      "epoch 17 batch 110/185 loss = 0.0100\n",
      "epoch 17 batch 111/185 loss = 0.0112\n",
      "epoch 17 batch 112/185 loss = 0.0088\n",
      "epoch 17 batch 113/185 loss = 0.0094\n",
      "epoch 17 batch 114/185 loss = 0.0085\n",
      "epoch 17 batch 115/185 loss = 0.0097\n",
      "epoch 17 batch 116/185 loss = 0.0103\n",
      "epoch 17 batch 117/185 loss = 0.0119\n",
      "epoch 17 batch 118/185 loss = 0.0085\n",
      "epoch 17 batch 119/185 loss = 0.0085\n",
      "epoch 17 batch 120/185 loss = 0.0118\n",
      "epoch 17 batch 121/185 loss = 0.0089\n",
      "epoch 17 batch 122/185 loss = 0.0079\n",
      "epoch 17 batch 123/185 loss = 0.0103\n",
      "epoch 17 batch 124/185 loss = 0.0089\n",
      "epoch 17 batch 125/185 loss = 0.0122\n",
      "epoch 17 batch 126/185 loss = 0.0101\n",
      "epoch 17 batch 127/185 loss = 0.0083\n",
      "epoch 17 batch 128/185 loss = 0.0088\n",
      "epoch 17 batch 129/185 loss = 0.0097\n",
      "epoch 17 batch 130/185 loss = 0.0103\n",
      "epoch 17 batch 131/185 loss = 0.0087\n",
      "epoch 17 batch 132/185 loss = 0.0074\n",
      "epoch 17 batch 133/185 loss = 0.0090\n",
      "epoch 17 batch 134/185 loss = 0.0112\n",
      "epoch 17 batch 135/185 loss = 0.0093\n",
      "epoch 17 batch 136/185 loss = 0.0096\n",
      "epoch 17 batch 137/185 loss = 0.0109\n",
      "epoch 17 batch 138/185 loss = 0.0084\n",
      "epoch 17 batch 139/185 loss = 0.0130\n",
      "epoch 17 batch 140/185 loss = 0.0101\n",
      "epoch 17 batch 141/185 loss = 0.0087\n",
      "epoch 17 batch 142/185 loss = 0.0089\n",
      "epoch 17 batch 143/185 loss = 0.0081\n",
      "epoch 17 batch 144/185 loss = 0.0115\n",
      "epoch 17 batch 145/185 loss = 0.0104\n",
      "epoch 17 batch 146/185 loss = 0.0112\n",
      "epoch 17 batch 147/185 loss = 0.0112\n",
      "epoch 17 batch 148/185 loss = 0.0104\n",
      "epoch 17 batch 149/185 loss = 0.0090\n",
      "epoch 17 batch 150/185 loss = 0.0096\n",
      "epoch 17 batch 151/185 loss = 0.0104\n",
      "epoch 17 batch 152/185 loss = 0.0098\n",
      "epoch 17 batch 153/185 loss = 0.0083\n",
      "epoch 17 batch 154/185 loss = 0.0066\n",
      "epoch 17 batch 155/185 loss = 0.0089\n",
      "epoch 17 batch 156/185 loss = 0.0095\n",
      "epoch 17 batch 157/185 loss = 0.0081\n",
      "epoch 17 batch 158/185 loss = 0.0092\n",
      "epoch 17 batch 159/185 loss = 0.0113\n",
      "epoch 17 batch 160/185 loss = 0.0099\n",
      "epoch 17 batch 161/185 loss = 0.0105\n",
      "epoch 17 batch 162/185 loss = 0.0101\n",
      "epoch 17 batch 163/185 loss = 0.0104\n",
      "epoch 17 batch 164/185 loss = 0.0065\n",
      "epoch 17 batch 165/185 loss = 0.0098\n",
      "epoch 17 batch 166/185 loss = 0.0126\n",
      "epoch 17 batch 167/185 loss = 0.0107\n",
      "epoch 17 batch 168/185 loss = 0.0085\n",
      "epoch 17 batch 169/185 loss = 0.0094\n",
      "epoch 17 batch 170/185 loss = 0.0112\n",
      "epoch 17 batch 171/185 loss = 0.0100\n",
      "epoch 17 batch 172/185 loss = 0.0078\n",
      "epoch 17 batch 173/185 loss = 0.0092\n",
      "epoch 17 batch 174/185 loss = 0.0079\n",
      "epoch 17 batch 175/185 loss = 0.0099\n",
      "epoch 17 batch 176/185 loss = 0.0103\n",
      "epoch 17 batch 177/185 loss = 0.0096\n",
      "epoch 17 batch 178/185 loss = 0.0096\n",
      "epoch 17 batch 179/185 loss = 0.0104\n",
      "epoch 17 batch 180/185 loss = 0.0117\n",
      "epoch 17 batch 181/185 loss = 0.0096\n",
      "epoch 17 batch 182/185 loss = 0.0092\n",
      "epoch 17 batch 183/185 loss = 0.0099\n",
      "epoch 17 batch 184/185 loss = 0.0097\n",
      "epoch 17 batch 185/185 loss = 0.0123\n",
      "epoch 17 train loss = 0.0098 valid loss = 0.0120\n",
      "performance reducing: counter 4\n",
      "epoch 18 batch 1/185 loss = 0.0077\n",
      "epoch 18 batch 2/185 loss = 0.0094\n",
      "epoch 18 batch 3/185 loss = 0.0136\n",
      "epoch 18 batch 4/185 loss = 0.0091\n",
      "epoch 18 batch 5/185 loss = 0.0086\n",
      "epoch 18 batch 6/185 loss = 0.0098\n",
      "epoch 18 batch 7/185 loss = 0.0096\n",
      "epoch 18 batch 8/185 loss = 0.0099\n",
      "epoch 18 batch 9/185 loss = 0.0099\n",
      "epoch 18 batch 10/185 loss = 0.0089\n",
      "epoch 18 batch 11/185 loss = 0.0098\n",
      "epoch 18 batch 12/185 loss = 0.0103\n",
      "epoch 18 batch 13/185 loss = 0.0083\n",
      "epoch 18 batch 14/185 loss = 0.0134\n",
      "epoch 18 batch 15/185 loss = 0.0096\n",
      "epoch 18 batch 16/185 loss = 0.0082\n",
      "epoch 18 batch 17/185 loss = 0.0119\n",
      "epoch 18 batch 18/185 loss = 0.0108\n",
      "epoch 18 batch 19/185 loss = 0.0106\n",
      "epoch 18 batch 20/185 loss = 0.0092\n",
      "epoch 18 batch 21/185 loss = 0.0074\n",
      "epoch 18 batch 22/185 loss = 0.0104\n",
      "epoch 18 batch 23/185 loss = 0.0107\n",
      "epoch 18 batch 24/185 loss = 0.0113\n",
      "epoch 18 batch 25/185 loss = 0.0113\n",
      "epoch 18 batch 26/185 loss = 0.0102\n",
      "epoch 18 batch 27/185 loss = 0.0096\n",
      "epoch 18 batch 28/185 loss = 0.0108\n",
      "epoch 18 batch 29/185 loss = 0.0096\n",
      "epoch 18 batch 30/185 loss = 0.0086\n",
      "epoch 18 batch 31/185 loss = 0.0089\n",
      "epoch 18 batch 32/185 loss = 0.0116\n",
      "epoch 18 batch 33/185 loss = 0.0102\n",
      "epoch 18 batch 34/185 loss = 0.0098\n",
      "epoch 18 batch 35/185 loss = 0.0115\n",
      "epoch 18 batch 36/185 loss = 0.0114\n",
      "epoch 18 batch 37/185 loss = 0.0123\n",
      "epoch 18 batch 38/185 loss = 0.0093\n",
      "epoch 18 batch 39/185 loss = 0.0111\n",
      "epoch 18 batch 40/185 loss = 0.0110\n",
      "epoch 18 batch 41/185 loss = 0.0105\n",
      "epoch 18 batch 42/185 loss = 0.0133\n",
      "epoch 18 batch 43/185 loss = 0.0082\n",
      "epoch 18 batch 44/185 loss = 0.0111\n",
      "epoch 18 batch 45/185 loss = 0.0101\n",
      "epoch 18 batch 46/185 loss = 0.0081\n",
      "epoch 18 batch 47/185 loss = 0.0071\n",
      "epoch 18 batch 48/185 loss = 0.0099\n",
      "epoch 18 batch 49/185 loss = 0.0115\n",
      "epoch 18 batch 50/185 loss = 0.0118\n",
      "epoch 18 batch 51/185 loss = 0.0082\n",
      "epoch 18 batch 52/185 loss = 0.0116\n",
      "epoch 18 batch 53/185 loss = 0.0105\n",
      "epoch 18 batch 54/185 loss = 0.0090\n",
      "epoch 18 batch 55/185 loss = 0.0089\n",
      "epoch 18 batch 56/185 loss = 0.0108\n",
      "epoch 18 batch 57/185 loss = 0.0128\n",
      "epoch 18 batch 58/185 loss = 0.0115\n",
      "epoch 18 batch 59/185 loss = 0.0089\n",
      "epoch 18 batch 60/185 loss = 0.0114\n",
      "epoch 18 batch 61/185 loss = 0.0089\n",
      "epoch 18 batch 62/185 loss = 0.0092\n",
      "epoch 18 batch 63/185 loss = 0.0093\n",
      "epoch 18 batch 64/185 loss = 0.0091\n",
      "epoch 18 batch 65/185 loss = 0.0119\n",
      "epoch 18 batch 66/185 loss = 0.0105\n",
      "epoch 18 batch 67/185 loss = 0.0077\n",
      "epoch 18 batch 68/185 loss = 0.0080\n",
      "epoch 18 batch 69/185 loss = 0.0098\n",
      "epoch 18 batch 70/185 loss = 0.0076\n",
      "epoch 18 batch 71/185 loss = 0.0094\n",
      "epoch 18 batch 72/185 loss = 0.0114\n",
      "epoch 18 batch 73/185 loss = 0.0114\n",
      "epoch 18 batch 74/185 loss = 0.0106\n",
      "epoch 18 batch 75/185 loss = 0.0086\n",
      "epoch 18 batch 76/185 loss = 0.0078\n",
      "epoch 18 batch 77/185 loss = 0.0111\n",
      "epoch 18 batch 78/185 loss = 0.0097\n",
      "epoch 18 batch 79/185 loss = 0.0080\n",
      "epoch 18 batch 80/185 loss = 0.0090\n",
      "epoch 18 batch 81/185 loss = 0.0094\n",
      "epoch 18 batch 82/185 loss = 0.0091\n",
      "epoch 18 batch 83/185 loss = 0.0094\n",
      "epoch 18 batch 84/185 loss = 0.0076\n",
      "epoch 18 batch 85/185 loss = 0.0107\n",
      "epoch 18 batch 86/185 loss = 0.0091\n",
      "epoch 18 batch 87/185 loss = 0.0100\n",
      "epoch 18 batch 88/185 loss = 0.0135\n",
      "epoch 18 batch 89/185 loss = 0.0107\n",
      "epoch 18 batch 90/185 loss = 0.0080\n",
      "epoch 18 batch 91/185 loss = 0.0118\n",
      "epoch 18 batch 92/185 loss = 0.0106\n",
      "epoch 18 batch 93/185 loss = 0.0102\n",
      "epoch 18 batch 94/185 loss = 0.0081\n",
      "epoch 18 batch 95/185 loss = 0.0090\n",
      "epoch 18 batch 96/185 loss = 0.0093\n",
      "epoch 18 batch 97/185 loss = 0.0090\n",
      "epoch 18 batch 98/185 loss = 0.0114\n",
      "epoch 18 batch 99/185 loss = 0.0091\n",
      "epoch 18 batch 100/185 loss = 0.0093\n",
      "epoch 18 batch 101/185 loss = 0.0110\n",
      "epoch 18 batch 102/185 loss = 0.0100\n",
      "epoch 18 batch 103/185 loss = 0.0098\n",
      "epoch 18 batch 104/185 loss = 0.0093\n",
      "epoch 18 batch 105/185 loss = 0.0083\n",
      "epoch 18 batch 106/185 loss = 0.0114\n",
      "epoch 18 batch 107/185 loss = 0.0096\n",
      "epoch 18 batch 108/185 loss = 0.0112\n",
      "epoch 18 batch 109/185 loss = 0.0076\n",
      "epoch 18 batch 110/185 loss = 0.0103\n",
      "epoch 18 batch 111/185 loss = 0.0129\n",
      "epoch 18 batch 112/185 loss = 0.0106\n",
      "epoch 18 batch 113/185 loss = 0.0091\n",
      "epoch 18 batch 114/185 loss = 0.0078\n",
      "epoch 18 batch 115/185 loss = 0.0085\n",
      "epoch 18 batch 116/185 loss = 0.0083\n",
      "epoch 18 batch 117/185 loss = 0.0100\n",
      "epoch 18 batch 118/185 loss = 0.0122\n",
      "epoch 18 batch 119/185 loss = 0.0086\n",
      "epoch 18 batch 120/185 loss = 0.0096\n",
      "epoch 18 batch 121/185 loss = 0.0115\n",
      "epoch 18 batch 122/185 loss = 0.0099\n",
      "epoch 18 batch 123/185 loss = 0.0100\n",
      "epoch 18 batch 124/185 loss = 0.0088\n",
      "epoch 18 batch 125/185 loss = 0.0074\n",
      "epoch 18 batch 126/185 loss = 0.0083\n",
      "epoch 18 batch 127/185 loss = 0.0112\n",
      "epoch 18 batch 128/185 loss = 0.0083\n",
      "epoch 18 batch 129/185 loss = 0.0108\n",
      "epoch 18 batch 130/185 loss = 0.0086\n",
      "epoch 18 batch 131/185 loss = 0.0105\n",
      "epoch 18 batch 132/185 loss = 0.0102\n",
      "epoch 18 batch 133/185 loss = 0.0089\n",
      "epoch 18 batch 134/185 loss = 0.0112\n",
      "epoch 18 batch 135/185 loss = 0.0116\n",
      "epoch 18 batch 136/185 loss = 0.0087\n",
      "epoch 18 batch 137/185 loss = 0.0098\n",
      "epoch 18 batch 138/185 loss = 0.0112\n",
      "epoch 18 batch 139/185 loss = 0.0083\n",
      "epoch 18 batch 140/185 loss = 0.0093\n",
      "epoch 18 batch 141/185 loss = 0.0084\n",
      "epoch 18 batch 142/185 loss = 0.0085\n",
      "epoch 18 batch 143/185 loss = 0.0084\n",
      "epoch 18 batch 144/185 loss = 0.0077\n",
      "epoch 18 batch 145/185 loss = 0.0089\n",
      "epoch 18 batch 146/185 loss = 0.0113\n",
      "epoch 18 batch 147/185 loss = 0.0073\n",
      "epoch 18 batch 148/185 loss = 0.0077\n",
      "epoch 18 batch 149/185 loss = 0.0094\n",
      "epoch 18 batch 150/185 loss = 0.0097\n",
      "epoch 18 batch 151/185 loss = 0.0087\n",
      "epoch 18 batch 152/185 loss = 0.0093\n",
      "epoch 18 batch 153/185 loss = 0.0081\n",
      "epoch 18 batch 154/185 loss = 0.0112\n",
      "epoch 18 batch 155/185 loss = 0.0089\n",
      "epoch 18 batch 156/185 loss = 0.0099\n",
      "epoch 18 batch 157/185 loss = 0.0092\n",
      "epoch 18 batch 158/185 loss = 0.0108\n",
      "epoch 18 batch 159/185 loss = 0.0087\n",
      "epoch 18 batch 160/185 loss = 0.0076\n",
      "epoch 18 batch 161/185 loss = 0.0091\n",
      "epoch 18 batch 162/185 loss = 0.0087\n",
      "epoch 18 batch 163/185 loss = 0.0096\n",
      "epoch 18 batch 164/185 loss = 0.0103\n",
      "epoch 18 batch 165/185 loss = 0.0125\n",
      "epoch 18 batch 166/185 loss = 0.0098\n",
      "epoch 18 batch 167/185 loss = 0.0115\n",
      "epoch 18 batch 168/185 loss = 0.0101\n",
      "epoch 18 batch 169/185 loss = 0.0116\n",
      "epoch 18 batch 170/185 loss = 0.0069\n",
      "epoch 18 batch 171/185 loss = 0.0098\n",
      "epoch 18 batch 172/185 loss = 0.0088\n",
      "epoch 18 batch 173/185 loss = 0.0085\n",
      "epoch 18 batch 174/185 loss = 0.0091\n",
      "epoch 18 batch 175/185 loss = 0.0104\n",
      "epoch 18 batch 176/185 loss = 0.0118\n",
      "epoch 18 batch 177/185 loss = 0.0090\n",
      "epoch 18 batch 178/185 loss = 0.0092\n",
      "epoch 18 batch 179/185 loss = 0.0091\n",
      "epoch 18 batch 180/185 loss = 0.0093\n",
      "epoch 18 batch 181/185 loss = 0.0093\n",
      "epoch 18 batch 182/185 loss = 0.0092\n",
      "epoch 18 batch 183/185 loss = 0.0084\n",
      "epoch 18 batch 184/185 loss = 0.0102\n",
      "epoch 18 batch 185/185 loss = 0.0084\n",
      "epoch 18 train loss = 0.0098 valid loss = 0.0128\n",
      "performance reducing: counter 5\n",
      "epoch 19 batch 1/185 loss = 0.0077\n",
      "epoch 19 batch 2/185 loss = 0.0093\n",
      "epoch 19 batch 3/185 loss = 0.0097\n",
      "epoch 19 batch 4/185 loss = 0.0093\n",
      "epoch 19 batch 5/185 loss = 0.0124\n",
      "epoch 19 batch 6/185 loss = 0.0076\n",
      "epoch 19 batch 7/185 loss = 0.0084\n",
      "epoch 19 batch 8/185 loss = 0.0094\n",
      "epoch 19 batch 9/185 loss = 0.0086\n",
      "epoch 19 batch 10/185 loss = 0.0123\n",
      "epoch 19 batch 11/185 loss = 0.0093\n",
      "epoch 19 batch 12/185 loss = 0.0105\n",
      "epoch 19 batch 13/185 loss = 0.0078\n",
      "epoch 19 batch 14/185 loss = 0.0093\n",
      "epoch 19 batch 15/185 loss = 0.0079\n",
      "epoch 19 batch 16/185 loss = 0.0110\n",
      "epoch 19 batch 17/185 loss = 0.0078\n",
      "epoch 19 batch 18/185 loss = 0.0103\n",
      "epoch 19 batch 19/185 loss = 0.0079\n",
      "epoch 19 batch 20/185 loss = 0.0093\n",
      "epoch 19 batch 21/185 loss = 0.0091\n",
      "epoch 19 batch 22/185 loss = 0.0106\n",
      "epoch 19 batch 23/185 loss = 0.0086\n",
      "epoch 19 batch 24/185 loss = 0.0102\n",
      "epoch 19 batch 25/185 loss = 0.0076\n",
      "epoch 19 batch 26/185 loss = 0.0101\n",
      "epoch 19 batch 27/185 loss = 0.0105\n",
      "epoch 19 batch 28/185 loss = 0.0108\n",
      "epoch 19 batch 29/185 loss = 0.0118\n",
      "epoch 19 batch 30/185 loss = 0.0088\n",
      "epoch 19 batch 31/185 loss = 0.0082\n",
      "epoch 19 batch 32/185 loss = 0.0091\n",
      "epoch 19 batch 33/185 loss = 0.0094\n",
      "epoch 19 batch 34/185 loss = 0.0088\n",
      "epoch 19 batch 35/185 loss = 0.0108\n",
      "epoch 19 batch 36/185 loss = 0.0082\n",
      "epoch 19 batch 37/185 loss = 0.0099\n",
      "epoch 19 batch 38/185 loss = 0.0098\n",
      "epoch 19 batch 39/185 loss = 0.0078\n",
      "epoch 19 batch 40/185 loss = 0.0104\n",
      "epoch 19 batch 41/185 loss = 0.0084\n",
      "epoch 19 batch 42/185 loss = 0.0096\n",
      "epoch 19 batch 43/185 loss = 0.0113\n",
      "epoch 19 batch 44/185 loss = 0.0100\n",
      "epoch 19 batch 45/185 loss = 0.0114\n",
      "epoch 19 batch 46/185 loss = 0.0098\n",
      "epoch 19 batch 47/185 loss = 0.0081\n",
      "epoch 19 batch 48/185 loss = 0.0105\n",
      "epoch 19 batch 49/185 loss = 0.0105\n",
      "epoch 19 batch 50/185 loss = 0.0091\n",
      "epoch 19 batch 51/185 loss = 0.0090\n",
      "epoch 19 batch 52/185 loss = 0.0079\n",
      "epoch 19 batch 53/185 loss = 0.0088\n",
      "epoch 19 batch 54/185 loss = 0.0084\n",
      "epoch 19 batch 55/185 loss = 0.0092\n",
      "epoch 19 batch 56/185 loss = 0.0083\n",
      "epoch 19 batch 57/185 loss = 0.0080\n",
      "epoch 19 batch 58/185 loss = 0.0100\n",
      "epoch 19 batch 59/185 loss = 0.0075\n",
      "epoch 19 batch 60/185 loss = 0.0109\n",
      "epoch 19 batch 61/185 loss = 0.0082\n",
      "epoch 19 batch 62/185 loss = 0.0076\n",
      "epoch 19 batch 63/185 loss = 0.0091\n",
      "epoch 19 batch 64/185 loss = 0.0105\n",
      "epoch 19 batch 65/185 loss = 0.0081\n",
      "epoch 19 batch 66/185 loss = 0.0106\n",
      "epoch 19 batch 67/185 loss = 0.0090\n",
      "epoch 19 batch 68/185 loss = 0.0088\n",
      "epoch 19 batch 69/185 loss = 0.0079\n",
      "epoch 19 batch 70/185 loss = 0.0092\n",
      "epoch 19 batch 71/185 loss = 0.0096\n",
      "epoch 19 batch 72/185 loss = 0.0115\n",
      "epoch 19 batch 73/185 loss = 0.0102\n",
      "epoch 19 batch 74/185 loss = 0.0099\n",
      "epoch 19 batch 75/185 loss = 0.0098\n",
      "epoch 19 batch 76/185 loss = 0.0113\n",
      "epoch 19 batch 77/185 loss = 0.0105\n",
      "epoch 19 batch 78/185 loss = 0.0097\n",
      "epoch 19 batch 79/185 loss = 0.0102\n",
      "epoch 19 batch 80/185 loss = 0.0093\n",
      "epoch 19 batch 81/185 loss = 0.0112\n",
      "epoch 19 batch 82/185 loss = 0.0103\n",
      "epoch 19 batch 83/185 loss = 0.0118\n",
      "epoch 19 batch 84/185 loss = 0.0082\n",
      "epoch 19 batch 85/185 loss = 0.0103\n",
      "epoch 19 batch 86/185 loss = 0.0085\n",
      "epoch 19 batch 87/185 loss = 0.0073\n",
      "epoch 19 batch 88/185 loss = 0.0077\n",
      "epoch 19 batch 89/185 loss = 0.0084\n",
      "epoch 19 batch 90/185 loss = 0.0081\n",
      "epoch 19 batch 91/185 loss = 0.0092\n",
      "epoch 19 batch 92/185 loss = 0.0079\n",
      "epoch 19 batch 93/185 loss = 0.0092\n",
      "epoch 19 batch 94/185 loss = 0.0115\n",
      "epoch 19 batch 95/185 loss = 0.0108\n",
      "epoch 19 batch 96/185 loss = 0.0109\n",
      "epoch 19 batch 97/185 loss = 0.0096\n",
      "epoch 19 batch 98/185 loss = 0.0109\n",
      "epoch 19 batch 99/185 loss = 0.0085\n",
      "epoch 19 batch 100/185 loss = 0.0080\n",
      "epoch 19 batch 101/185 loss = 0.0103\n",
      "epoch 19 batch 102/185 loss = 0.0084\n",
      "epoch 19 batch 103/185 loss = 0.0087\n",
      "epoch 19 batch 104/185 loss = 0.0091\n",
      "epoch 19 batch 105/185 loss = 0.0082\n",
      "epoch 19 batch 106/185 loss = 0.0089\n",
      "epoch 19 batch 107/185 loss = 0.0122\n",
      "epoch 19 batch 108/185 loss = 0.0086\n",
      "epoch 19 batch 109/185 loss = 0.0088\n",
      "epoch 19 batch 110/185 loss = 0.0093\n",
      "epoch 19 batch 111/185 loss = 0.0081\n",
      "epoch 19 batch 112/185 loss = 0.0083\n",
      "epoch 19 batch 113/185 loss = 0.0088\n",
      "epoch 19 batch 114/185 loss = 0.0097\n",
      "epoch 19 batch 115/185 loss = 0.0085\n",
      "epoch 19 batch 116/185 loss = 0.0090\n",
      "epoch 19 batch 117/185 loss = 0.0098\n",
      "epoch 19 batch 118/185 loss = 0.0113\n",
      "epoch 19 batch 119/185 loss = 0.0103\n",
      "epoch 19 batch 120/185 loss = 0.0099\n",
      "epoch 19 batch 121/185 loss = 0.0079\n",
      "epoch 19 batch 122/185 loss = 0.0126\n",
      "epoch 19 batch 123/185 loss = 0.0111\n",
      "epoch 19 batch 124/185 loss = 0.0107\n",
      "epoch 19 batch 125/185 loss = 0.0101\n",
      "epoch 19 batch 126/185 loss = 0.0083\n",
      "epoch 19 batch 127/185 loss = 0.0067\n",
      "epoch 19 batch 128/185 loss = 0.0091\n",
      "epoch 19 batch 129/185 loss = 0.0098\n",
      "epoch 19 batch 130/185 loss = 0.0104\n",
      "epoch 19 batch 131/185 loss = 0.0130\n",
      "epoch 19 batch 132/185 loss = 0.0102\n",
      "epoch 19 batch 133/185 loss = 0.0112\n",
      "epoch 19 batch 134/185 loss = 0.0089\n",
      "epoch 19 batch 135/185 loss = 0.0080\n",
      "epoch 19 batch 136/185 loss = 0.0112\n",
      "epoch 19 batch 137/185 loss = 0.0076\n",
      "epoch 19 batch 138/185 loss = 0.0076\n",
      "epoch 19 batch 139/185 loss = 0.0094\n",
      "epoch 19 batch 140/185 loss = 0.0095\n",
      "epoch 19 batch 141/185 loss = 0.0100\n",
      "epoch 19 batch 142/185 loss = 0.0096\n",
      "epoch 19 batch 143/185 loss = 0.0097\n",
      "epoch 19 batch 144/185 loss = 0.0105\n",
      "epoch 19 batch 145/185 loss = 0.0102\n",
      "epoch 19 batch 146/185 loss = 0.0101\n",
      "epoch 19 batch 147/185 loss = 0.0090\n",
      "epoch 19 batch 148/185 loss = 0.0094\n",
      "epoch 19 batch 149/185 loss = 0.0099\n",
      "epoch 19 batch 150/185 loss = 0.0098\n",
      "epoch 19 batch 151/185 loss = 0.0070\n",
      "epoch 19 batch 152/185 loss = 0.0104\n",
      "epoch 19 batch 153/185 loss = 0.0078\n",
      "epoch 19 batch 154/185 loss = 0.0101\n",
      "epoch 19 batch 155/185 loss = 0.0095\n",
      "epoch 19 batch 156/185 loss = 0.0097\n",
      "epoch 19 batch 157/185 loss = 0.0096\n",
      "epoch 19 batch 158/185 loss = 0.0117\n",
      "epoch 19 batch 159/185 loss = 0.0098\n",
      "epoch 19 batch 160/185 loss = 0.0083\n",
      "epoch 19 batch 161/185 loss = 0.0090\n",
      "epoch 19 batch 162/185 loss = 0.0085\n",
      "epoch 19 batch 163/185 loss = 0.0075\n",
      "epoch 19 batch 164/185 loss = 0.0131\n",
      "epoch 19 batch 165/185 loss = 0.0102\n",
      "epoch 19 batch 166/185 loss = 0.0089\n",
      "epoch 19 batch 167/185 loss = 0.0089\n",
      "epoch 19 batch 168/185 loss = 0.0111\n",
      "epoch 19 batch 169/185 loss = 0.0128\n",
      "epoch 19 batch 170/185 loss = 0.0088\n",
      "epoch 19 batch 171/185 loss = 0.0089\n",
      "epoch 19 batch 172/185 loss = 0.0106\n",
      "epoch 19 batch 173/185 loss = 0.0078\n",
      "epoch 19 batch 174/185 loss = 0.0118\n",
      "epoch 19 batch 175/185 loss = 0.0106\n",
      "epoch 19 batch 176/185 loss = 0.0072\n",
      "epoch 19 batch 177/185 loss = 0.0112\n",
      "epoch 19 batch 178/185 loss = 0.0091\n",
      "epoch 19 batch 179/185 loss = 0.0104\n",
      "epoch 19 batch 180/185 loss = 0.0131\n",
      "epoch 19 batch 181/185 loss = 0.0091\n",
      "epoch 19 batch 182/185 loss = 0.0089\n",
      "epoch 19 batch 183/185 loss = 0.0116\n",
      "epoch 19 batch 184/185 loss = 0.0091\n",
      "epoch 19 batch 185/185 loss = 0.0090\n",
      "epoch 19 train loss = 0.0095 valid loss = 0.0119\n",
      "performance reducing: counter 6\n",
      "epoch 20 batch 1/185 loss = 0.0093\n",
      "epoch 20 batch 2/185 loss = 0.0096\n",
      "epoch 20 batch 3/185 loss = 0.0090\n",
      "epoch 20 batch 4/185 loss = 0.0091\n",
      "epoch 20 batch 5/185 loss = 0.0105\n",
      "epoch 20 batch 6/185 loss = 0.0103\n",
      "epoch 20 batch 7/185 loss = 0.0078\n",
      "epoch 20 batch 8/185 loss = 0.0086\n",
      "epoch 20 batch 9/185 loss = 0.0088\n",
      "epoch 20 batch 10/185 loss = 0.0096\n",
      "epoch 20 batch 11/185 loss = 0.0093\n",
      "epoch 20 batch 12/185 loss = 0.0090\n",
      "epoch 20 batch 13/185 loss = 0.0089\n",
      "epoch 20 batch 14/185 loss = 0.0079\n",
      "epoch 20 batch 15/185 loss = 0.0096\n",
      "epoch 20 batch 16/185 loss = 0.0094\n",
      "epoch 20 batch 17/185 loss = 0.0082\n",
      "epoch 20 batch 18/185 loss = 0.0066\n",
      "epoch 20 batch 19/185 loss = 0.0094\n",
      "epoch 20 batch 20/185 loss = 0.0102\n",
      "epoch 20 batch 21/185 loss = 0.0087\n",
      "epoch 20 batch 22/185 loss = 0.0076\n",
      "epoch 20 batch 23/185 loss = 0.0099\n",
      "epoch 20 batch 24/185 loss = 0.0079\n",
      "epoch 20 batch 25/185 loss = 0.0105\n",
      "epoch 20 batch 26/185 loss = 0.0111\n",
      "epoch 20 batch 27/185 loss = 0.0100\n",
      "epoch 20 batch 28/185 loss = 0.0067\n",
      "epoch 20 batch 29/185 loss = 0.0115\n",
      "epoch 20 batch 30/185 loss = 0.0091\n",
      "epoch 20 batch 31/185 loss = 0.0082\n",
      "epoch 20 batch 32/185 loss = 0.0075\n",
      "epoch 20 batch 33/185 loss = 0.0076\n",
      "epoch 20 batch 34/185 loss = 0.0087\n",
      "epoch 20 batch 35/185 loss = 0.0101\n",
      "epoch 20 batch 36/185 loss = 0.0064\n",
      "epoch 20 batch 37/185 loss = 0.0073\n",
      "epoch 20 batch 38/185 loss = 0.0079\n",
      "epoch 20 batch 39/185 loss = 0.0106\n",
      "epoch 20 batch 40/185 loss = 0.0098\n",
      "epoch 20 batch 41/185 loss = 0.0091\n",
      "epoch 20 batch 42/185 loss = 0.0104\n",
      "epoch 20 batch 43/185 loss = 0.0092\n",
      "epoch 20 batch 44/185 loss = 0.0095\n",
      "epoch 20 batch 45/185 loss = 0.0088\n",
      "epoch 20 batch 46/185 loss = 0.0089\n",
      "epoch 20 batch 47/185 loss = 0.0097\n",
      "epoch 20 batch 48/185 loss = 0.0093\n",
      "epoch 20 batch 49/185 loss = 0.0094\n",
      "epoch 20 batch 50/185 loss = 0.0085\n",
      "epoch 20 batch 51/185 loss = 0.0096\n",
      "epoch 20 batch 52/185 loss = 0.0091\n",
      "epoch 20 batch 53/185 loss = 0.0085\n",
      "epoch 20 batch 54/185 loss = 0.0105\n",
      "epoch 20 batch 55/185 loss = 0.0111\n",
      "epoch 20 batch 56/185 loss = 0.0100\n",
      "epoch 20 batch 57/185 loss = 0.0092\n",
      "epoch 20 batch 58/185 loss = 0.0083\n",
      "epoch 20 batch 59/185 loss = 0.0103\n",
      "epoch 20 batch 60/185 loss = 0.0090\n",
      "epoch 20 batch 61/185 loss = 0.0089\n",
      "epoch 20 batch 62/185 loss = 0.0086\n",
      "epoch 20 batch 63/185 loss = 0.0101\n",
      "epoch 20 batch 64/185 loss = 0.0073\n",
      "epoch 20 batch 65/185 loss = 0.0097\n",
      "epoch 20 batch 66/185 loss = 0.0096\n",
      "epoch 20 batch 67/185 loss = 0.0084\n",
      "epoch 20 batch 68/185 loss = 0.0116\n",
      "epoch 20 batch 69/185 loss = 0.0098\n",
      "epoch 20 batch 70/185 loss = 0.0114\n",
      "epoch 20 batch 71/185 loss = 0.0092\n",
      "epoch 20 batch 72/185 loss = 0.0100\n",
      "epoch 20 batch 73/185 loss = 0.0090\n",
      "epoch 20 batch 74/185 loss = 0.0098\n",
      "epoch 20 batch 75/185 loss = 0.0103\n",
      "epoch 20 batch 76/185 loss = 0.0097\n",
      "epoch 20 batch 77/185 loss = 0.0076\n",
      "epoch 20 batch 78/185 loss = 0.0092\n",
      "epoch 20 batch 79/185 loss = 0.0088\n",
      "epoch 20 batch 80/185 loss = 0.0120\n",
      "epoch 20 batch 81/185 loss = 0.0135\n",
      "epoch 20 batch 82/185 loss = 0.0082\n",
      "epoch 20 batch 83/185 loss = 0.0073\n",
      "epoch 20 batch 84/185 loss = 0.0097\n",
      "epoch 20 batch 85/185 loss = 0.0098\n",
      "epoch 20 batch 86/185 loss = 0.0107\n",
      "epoch 20 batch 87/185 loss = 0.0099\n",
      "epoch 20 batch 88/185 loss = 0.0105\n",
      "epoch 20 batch 89/185 loss = 0.0092\n",
      "epoch 20 batch 90/185 loss = 0.0089\n",
      "epoch 20 batch 91/185 loss = 0.0081\n",
      "epoch 20 batch 92/185 loss = 0.0064\n",
      "epoch 20 batch 93/185 loss = 0.0089\n",
      "epoch 20 batch 94/185 loss = 0.0092\n",
      "epoch 20 batch 95/185 loss = 0.0086\n",
      "epoch 20 batch 96/185 loss = 0.0081\n",
      "epoch 20 batch 97/185 loss = 0.0072\n",
      "epoch 20 batch 98/185 loss = 0.0117\n",
      "epoch 20 batch 99/185 loss = 0.0097\n",
      "epoch 20 batch 100/185 loss = 0.0094\n",
      "epoch 20 batch 101/185 loss = 0.0077\n",
      "epoch 20 batch 102/185 loss = 0.0079\n",
      "epoch 20 batch 103/185 loss = 0.0100\n",
      "epoch 20 batch 104/185 loss = 0.0111\n",
      "epoch 20 batch 105/185 loss = 0.0081\n",
      "epoch 20 batch 106/185 loss = 0.0109\n",
      "epoch 20 batch 107/185 loss = 0.0108\n",
      "epoch 20 batch 108/185 loss = 0.0097\n",
      "epoch 20 batch 109/185 loss = 0.0082\n",
      "epoch 20 batch 110/185 loss = 0.0091\n",
      "epoch 20 batch 111/185 loss = 0.0087\n",
      "epoch 20 batch 112/185 loss = 0.0090\n",
      "epoch 20 batch 113/185 loss = 0.0116\n",
      "epoch 20 batch 114/185 loss = 0.0082\n",
      "epoch 20 batch 115/185 loss = 0.0108\n",
      "epoch 20 batch 116/185 loss = 0.0106\n",
      "epoch 20 batch 117/185 loss = 0.0085\n",
      "epoch 20 batch 118/185 loss = 0.0109\n",
      "epoch 20 batch 119/185 loss = 0.0093\n",
      "epoch 20 batch 120/185 loss = 0.0098\n",
      "epoch 20 batch 121/185 loss = 0.0089\n",
      "epoch 20 batch 122/185 loss = 0.0087\n",
      "epoch 20 batch 123/185 loss = 0.0091\n",
      "epoch 20 batch 124/185 loss = 0.0090\n",
      "epoch 20 batch 125/185 loss = 0.0115\n",
      "epoch 20 batch 126/185 loss = 0.0090\n",
      "epoch 20 batch 127/185 loss = 0.0092\n",
      "epoch 20 batch 128/185 loss = 0.0084\n",
      "epoch 20 batch 129/185 loss = 0.0087\n",
      "epoch 20 batch 130/185 loss = 0.0080\n",
      "epoch 20 batch 131/185 loss = 0.0096\n",
      "epoch 20 batch 132/185 loss = 0.0089\n",
      "epoch 20 batch 133/185 loss = 0.0073\n",
      "epoch 20 batch 134/185 loss = 0.0086\n",
      "epoch 20 batch 135/185 loss = 0.0090\n",
      "epoch 20 batch 136/185 loss = 0.0123\n",
      "epoch 20 batch 137/185 loss = 0.0080\n",
      "epoch 20 batch 138/185 loss = 0.0084\n",
      "epoch 20 batch 139/185 loss = 0.0097\n",
      "epoch 20 batch 140/185 loss = 0.0112\n",
      "epoch 20 batch 141/185 loss = 0.0098\n",
      "epoch 20 batch 142/185 loss = 0.0101\n",
      "epoch 20 batch 143/185 loss = 0.0107\n",
      "epoch 20 batch 144/185 loss = 0.0100\n",
      "epoch 20 batch 145/185 loss = 0.0099\n",
      "epoch 20 batch 146/185 loss = 0.0096\n",
      "epoch 20 batch 147/185 loss = 0.0086\n",
      "epoch 20 batch 148/185 loss = 0.0109\n",
      "epoch 20 batch 149/185 loss = 0.0085\n",
      "epoch 20 batch 150/185 loss = 0.0079\n",
      "epoch 20 batch 151/185 loss = 0.0100\n",
      "epoch 20 batch 152/185 loss = 0.0084\n",
      "epoch 20 batch 153/185 loss = 0.0112\n",
      "epoch 20 batch 154/185 loss = 0.0068\n",
      "epoch 20 batch 155/185 loss = 0.0074\n",
      "epoch 20 batch 156/185 loss = 0.0093\n",
      "epoch 20 batch 157/185 loss = 0.0110\n",
      "epoch 20 batch 158/185 loss = 0.0088\n",
      "epoch 20 batch 159/185 loss = 0.0112\n",
      "epoch 20 batch 160/185 loss = 0.0128\n",
      "epoch 20 batch 161/185 loss = 0.0086\n",
      "epoch 20 batch 162/185 loss = 0.0110\n",
      "epoch 20 batch 163/185 loss = 0.0062\n",
      "epoch 20 batch 164/185 loss = 0.0109\n",
      "epoch 20 batch 165/185 loss = 0.0095\n",
      "epoch 20 batch 166/185 loss = 0.0103\n",
      "epoch 20 batch 167/185 loss = 0.0088\n",
      "epoch 20 batch 168/185 loss = 0.0092\n",
      "epoch 20 batch 169/185 loss = 0.0096\n",
      "epoch 20 batch 170/185 loss = 0.0084\n",
      "epoch 20 batch 171/185 loss = 0.0093\n",
      "epoch 20 batch 172/185 loss = 0.0104\n",
      "epoch 20 batch 173/185 loss = 0.0091\n",
      "epoch 20 batch 174/185 loss = 0.0076\n",
      "epoch 20 batch 175/185 loss = 0.0130\n",
      "epoch 20 batch 176/185 loss = 0.0079\n",
      "epoch 20 batch 177/185 loss = 0.0085\n",
      "epoch 20 batch 178/185 loss = 0.0096\n",
      "epoch 20 batch 179/185 loss = 0.0087\n",
      "epoch 20 batch 180/185 loss = 0.0084\n",
      "epoch 20 batch 181/185 loss = 0.0095\n",
      "epoch 20 batch 182/185 loss = 0.0104\n",
      "epoch 20 batch 183/185 loss = 0.0087\n",
      "epoch 20 batch 184/185 loss = 0.0085\n",
      "epoch 20 batch 185/185 loss = 0.0071\n",
      "epoch 20 train loss = 0.0093 valid loss = 0.0124\n",
      "performance reducing: counter 7\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    current_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    train_image_path = glob('../input/cityscapes-image-pairs/cityscapes_data/train/*')\n",
    "    valid_image_path = glob('../input/cityscapes-image-pairs/cityscapes_data/val/*')\n",
    "\n",
    "    image_transforms = transforms.Compose([\n",
    "#         transforms.ToPILImage(mode='RGB'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256),\n",
    "#         transforms.PILToTensor(),\n",
    "#         transforms.ColorJitter(),\n",
    "#         transforms.GaussianBlur((5,), (5, 15)),\n",
    "#         transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "    target_transforms = transforms.Compose([\n",
    "#         transforms.ToPILImage(mode='RGB'),\n",
    "#         transforms.Grayscale(),\n",
    "#         transforms.PILToTensor(),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "    valid_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.Normalize((0.5,), (0.5,)),\n",
    "#         transforms.ToPILImage(mode='RGB'),\n",
    "        transforms.Resize(256),\n",
    "#         transforms.PILToTensor(),\n",
    "#         transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "\n",
    "    train_cityscapes = Cityscapes(train_image_path, image_transforms, target_transforms)\n",
    "    valid_cityscapes = Cityscapes(valid_image_path, valid_transforms, target_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_cityscapes, batch_size=16, shuffle=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_cityscapes, batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "    unet = UNet().to(current_device)\n",
    "    ce_loss = nn.MSELoss().to(current_device)\n",
    "    optimizer_adam = optim.Adam(unet.parameters(), lr=0.001)\n",
    "    continue_train = False\n",
    "    if continue_train:\n",
    "        trained_model_params = torch.load('../input/cityscapes-unet/unet-last.pth')\n",
    "        unet.load_state_dict(trained_model_params['model_state_dict'])\n",
    "        optimizer_adam.load_state_dict(trained_model_params['optimizer_state_dict'])\n",
    "    train(train_loader, valid_loader, unet, optimizer_adam, ce_loss, epoch=20, device=current_device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2628.652227,
   "end_time": "2022-06-16T08:04:01.885827",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-16T07:20:13.233600",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
