{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89febaf9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-17T00:59:32.092941Z",
     "iopub.status.busy": "2022-06-17T00:59:32.092513Z",
     "iopub.status.idle": "2022-06-17T00:59:32.103769Z",
     "shell.execute_reply": "2022-06-17T00:59:32.103162Z"
    },
    "papermill": {
     "duration": 0.02526,
     "end_time": "2022-06-17T00:59:32.105566",
     "exception": false,
     "start_time": "2022-06-17T00:59:32.080306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#os.remove('/kaggle/working/datasets/cityscapes.pth')\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#       print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c14388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T00:59:32.125981Z",
     "iopub.status.busy": "2022-06-17T00:59:32.125432Z",
     "iopub.status.idle": "2022-06-17T00:59:34.508105Z",
     "shell.execute_reply": "2022-06-17T00:59:34.507137Z"
    },
    "papermill": {
     "duration": 2.395456,
     "end_time": "2022-06-17T00:59:34.510544",
     "exception": false,
     "start_time": "2022-06-17T00:59:32.115088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as functional\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97cd5460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T00:59:34.532713Z",
     "iopub.status.busy": "2022-06-17T00:59:34.532291Z",
     "iopub.status.idle": "2022-06-17T00:59:34.955299Z",
     "shell.execute_reply": "2022-06-17T00:59:34.954452Z"
    },
    "papermill": {
     "duration": 0.43638,
     "end_time": "2022-06-17T00:59:34.957524",
     "exception": false,
     "start_time": "2022-06-17T00:59:34.521144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = glob('/kaggle/input/cityscapes-image-pairs/cityscapes_data/train/*')\n",
    "valid_path = glob('/kaggle/input/cityscapes-image-pairs/cityscapes_data/val/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e371bec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T00:59:34.980086Z",
     "iopub.status.busy": "2022-06-17T00:59:34.979820Z",
     "iopub.status.idle": "2022-06-17T00:59:34.988443Z",
     "shell.execute_reply": "2022-06-17T00:59:34.987676Z"
    },
    "papermill": {
     "duration": 0.022451,
     "end_time": "2022-06-17T00:59:34.990423",
     "exception": false,
     "start_time": "2022-06-17T00:59:34.967972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Cityscapes(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None):\n",
    "        super(Cityscapes, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        #self.datasets = np.array(data)\n",
    "        #self.images, self.targets = np.array_split(self.datasets, 2, axis=2)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image_pair = plt.imread(self.data_path[item])\n",
    "        image, target = image_pair[:, :int(image_pair.shape[1] / 2)], image_pair[:, int(image_pair.shape[1] / 2):]\n",
    "        #image = self.images[item]\n",
    "        #target = self.targets[item]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518c8bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T00:59:35.012403Z",
     "iopub.status.busy": "2022-06-17T00:59:35.012100Z",
     "iopub.status.idle": "2022-06-17T00:59:35.040814Z",
     "shell.execute_reply": "2022-06-17T00:59:35.040081Z"
    },
    "papermill": {
     "duration": 0.042017,
     "end_time": "2022-06-17T00:59:35.042997",
     "exception": false,
     "start_time": "2022-06-17T00:59:35.000980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_class=3, image_channel=3, mid_channel=64):\n",
    "        super(UNet, self).__init__()\n",
    "        self.two_conv_block = nn.Sequential(\n",
    "            nn.Conv2d(image_channel, mid_channel, kernel_size=3, dilation=4, padding=4),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channel, mid_channel, kernel_size=3, dilation=4, padding=4),\n",
    "            nn.BatchNorm2d(mid_channel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.down_sample_1 = DownSampleConvBlock(mid_channel, mid_channel * 2, mid_channel * 2, dilation=3, padding=3)\n",
    "        self.down_sample_2 = DownSampleConvBlock(mid_channel * 2, mid_channel * 4, mid_channel * 4, dilation=2, padding=2)\n",
    "        self.down_sample_3 = DownSampleConvBlock(mid_channel * 4, mid_channel * 8, mid_channel * 8)\n",
    "        self.down_sample_4 = DownSampleConvBlock(mid_channel * 8, mid_channel * 16, mid_channel * 16)\n",
    "        self.up_sample_1 = UpSampleConvBlock(mid_channel * 16, mid_channel * 8, mid_channel * 8)\n",
    "        self.up_sample_2 = UpSampleConvBlock(mid_channel * 8, mid_channel * 4, mid_channel * 4)\n",
    "        self.up_sample_3 = UpSampleConvBlock(mid_channel * 4, mid_channel * 2, mid_channel * 2)\n",
    "        self.up_sample_4 = UpSampleConvBlock(mid_channel * 2, mid_channel, mid_channel)\n",
    "        # 降维\n",
    "        self.conv1x1 = nn.Conv2d(mid_channel, num_class, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.two_conv_block(x)\n",
    "        x2 = self.down_sample_1(x1)\n",
    "        x3 = self.down_sample_2(x2)\n",
    "        x4 = self.down_sample_3(x3)\n",
    "        x5 = self.down_sample_4(x4)\n",
    "        x_u1 = self.up_sample_1(x5, x4)\n",
    "        x_u2 = self.up_sample_2(x_u1, x3)\n",
    "        x_u3 = self.up_sample_3(x_u2, x2)\n",
    "        x_u4 = self.up_sample_4(x_u3, x1)\n",
    "        # return self.conv1x1(x_u4)\n",
    "        return self.bn(self.conv1x1(x_u4))\n",
    "\n",
    "\n",
    "class BasicConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1):\n",
    "        super(BasicConvBlock, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # the first conv block\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size, stride, padding, dilation),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # the second conv block\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size, stride, padding, dilation),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class DownSampleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, pool_size=2, kernel_size=3, stride=1, padding=1,\n",
    "                 dilation=1):\n",
    "        super(DownSampleConvBlock, self).__init__()\n",
    "        self.down_sample = nn.MaxPool2d(kernel_size=pool_size)\n",
    "        self.basic_conv_block = BasicConvBlock(in_channels, mid_channels, out_channels, kernel_size, stride, padding,\n",
    "                                               dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # down sample\n",
    "        x = self.down_sample(x)\n",
    "        # two conv block\n",
    "        x = self.basic_conv_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSampleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, up_size=2, kernel_size=3, stride=1, padding=1,\n",
    "                 dilation=1):\n",
    "        super(UpSampleConvBlock, self).__init__()\n",
    "        self.up_sample = nn.ConvTranspose2d(in_channels, mid_channels, kernel_size=up_size, stride=up_size,\n",
    "                                            dilation=dilation)\n",
    "        self.basic_conv_block = BasicConvBlock(in_channels, mid_channels, out_channels, kernel_size, stride, padding,\n",
    "                                               dilation)\n",
    "\n",
    "    def forward(self, x, skip_x):\n",
    "        # up sample\n",
    "        x = self.up_sample(x)\n",
    "        # concat x and skip_x in the dimension of channel\n",
    "        x = torch.cat([x, skip_x], dim=1)\n",
    "        # two conv block\n",
    "        x = self.basic_conv_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AdaptiveFeatureFusionModule(nn.Module):\n",
    "    \"\"\"Adaptive Feature Fusion Module(AFFM)\n",
    "\n",
    "    Fusion multiple-scale feature maps, the count of feature maps is not fixed,\n",
    "    the value of counts must equal the size of feature_maps, the number of layers\n",
    "    in AFFM is determined by the parameter of counts.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, counts):\n",
    "        super(AdaptiveFeatureFusionModule, self).__init__()\n",
    "        self.counts = counts\n",
    "        pass\n",
    "\n",
    "    def forward(self, feature_maps: tuple = None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6da7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T00:59:35.064438Z",
     "iopub.status.busy": "2022-06-17T00:59:35.063816Z",
     "iopub.status.idle": "2022-06-17T00:59:35.077214Z",
     "shell.execute_reply": "2022-06-17T00:59:35.076510Z"
    },
    "papermill": {
     "duration": 0.025925,
     "end_time": "2022-06-17T00:59:35.079154",
     "exception": false,
     "start_time": "2022-06-17T00:59:35.053229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coeff(predict, target, reduce_batch_first=False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    assert predict.size() == target.size()\n",
    "    if predict.dim() == 2 and reduce_batch_first:\n",
    "        raise ValueError(f'Dice: asked to reduce batch but got tensor without batch dimension (shape {predict.shape})')\n",
    "\n",
    "    if predict.dim() == 2 or reduce_batch_first:\n",
    "        inter = torch.dot(predict.reshape(-1), target.reshape(-1))\n",
    "        sets_sum = torch.sum(predict) + torch.sum(target)\n",
    "        if sets_sum.item() == 0:\n",
    "            sets_sum = 2 * inter\n",
    "        return (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "    else:\n",
    "        # compute and average metric for each batch element\n",
    "        dice = 0\n",
    "        for i in range(predict.shape[0]):\n",
    "            dice += dice_coeff(predict[i, ...], target[i, ...])\n",
    "        # return average dice loss value of a batch\n",
    "        return dice / predict.shape[0]\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(predict, target, reduce_batch_first=False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all classes\n",
    "    assert predict.size() == target.size()\n",
    "    dice = 0\n",
    "    for channel in range(predict.shape[1]):\n",
    "        dice += dice_coeff(predict[:, channel, ...], target[:, channel, ...], reduce_batch_first, epsilon)\n",
    "    return dice / predict.shape[1]\n",
    "\n",
    "\n",
    "def dice_loss(predict, target, multiclass=True, epsilon=1e-6):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    assert predict.size() == target.size()\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(predict, target, reduce_batch_first=True, epsilon=epsilon)\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, ep=1e-8):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.ep = ep\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        # the shape of predict must equal to the shape of target\n",
    "        value = dice_loss(predict, target, True, self.ep)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80acfda1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T00:59:35.099939Z",
     "iopub.status.busy": "2022-06-17T00:59:35.099732Z",
     "iopub.status.idle": "2022-06-17T00:59:35.108721Z",
     "shell.execute_reply": "2022-06-17T00:59:35.107984Z"
    },
    "papermill": {
     "duration": 0.021851,
     "end_time": "2022-06-17T00:59:35.110683",
     "exception": false,
     "start_time": "2022-06-17T00:59:35.088832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(network_model, valid_loader, loss, device):\n",
    "    network_model.eval()\n",
    "    v_loss_total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for j, (v_x, v_l) in enumerate(valid_loader):\n",
    "            v_x = v_x.to(device)\n",
    "            v_l = v_l.to(device)\n",
    "            v_predict = network_model(v_x)\n",
    "            loss_value = loss(v_predict, v_l)\n",
    "            v_loss_total += loss_value.item()\n",
    "    val_avg_loss = v_loss_total / len(valid_loader)\n",
    "    return val_avg_loss\n",
    "\n",
    "\n",
    "class SearchBestModel(object):\n",
    "    def __init__(self, min_delta=0, verbose=True):\n",
    "        super(SearchBestModel, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "        elif self.best_score - val_loss >= self.min_delta:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print('performance reducing: counter {}'.format(self.counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08841c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T00:59:35.131486Z",
     "iopub.status.busy": "2022-06-17T00:59:35.131247Z",
     "iopub.status.idle": "2022-06-17T00:59:35.142852Z",
     "shell.execute_reply": "2022-06-17T00:59:35.142217Z"
    },
    "papermill": {
     "duration": 0.024546,
     "end_time": "2022-06-17T00:59:35.144980",
     "exception": false,
     "start_time": "2022-06-17T00:59:35.120434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, optimizer, loss, epoch, device):\n",
    "    loss_change_list = []\n",
    "    valid_loss_change = []\n",
    "    save_best = {}\n",
    "    save_last = {}\n",
    "    search_best_model = SearchBestModel()\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for index, (image, label) in enumerate(train_loader):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device).to(torch.float32)\n",
    "\n",
    "            segment_mask = model(image)\n",
    "            loss_value = loss(segment_mask, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss = total_loss + loss_value.item()\n",
    "\n",
    "            print('epoch {} batch {}/{} loss = {:.4f}'.format(i + 1, index + 1, len(train_loader), loss_value.item()))\n",
    "        # save train loss change history used for model analyse\n",
    "        loss_change_list.append(total_loss / len(train_loader))\n",
    "        # use the dataset for validation to validate the trained model\n",
    "        valid_avg_loss = validate(model, valid_loader, loss, device)\n",
    "        # save valid loss change history used for model analyse\n",
    "        valid_loss_change.append(valid_avg_loss)\n",
    "\n",
    "        print('epoch {} train loss = {:.4f} valid loss = {:.4f}'.format(i + 1, total_loss / len(train_loader), valid_avg_loss))\n",
    "\n",
    "        # see if satisfy the conditions of early stopping\n",
    "        search_best_model(valid_avg_loss)\n",
    "        # if satisfy the conditions of early stopping, break the training process\n",
    "        if search_best_model.counter > 0:\n",
    "            continue\n",
    "        # if not satisfy the conditions of early stopping, it shows that\n",
    "        # the model in this epoch is the best, save the params of current model.\n",
    "        save_best['model_state_dict'] = model.state_dict()\n",
    "        # save optimizer used for re-train\n",
    "        save_best['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        # save the epoch of current best model\n",
    "        save_best['epoch'] = i\n",
    "    # save loss change history of training and validation\n",
    "    save_last['train_loss_change'] = loss_change_list\n",
    "    save_last['valid_loss_change'] = valid_loss_change\n",
    "    save_last['model_state_dict'] = model.state_dict()\n",
    "    save_last['optimizer_state_dict'] = optimizer.state_dict()\n",
    "    save_last['trained_epoch'] = epoch\n",
    "    torch.save(save_best, './unet-best.pth')\n",
    "    torch.save(save_last, './unet-last.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1339561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T00:59:35.167018Z",
     "iopub.status.busy": "2022-06-17T00:59:35.166586Z",
     "iopub.status.idle": "2022-06-17T02:02:19.353110Z",
     "shell.execute_reply": "2022-06-17T02:02:19.352359Z"
    },
    "papermill": {
     "duration": 3764.200006,
     "end_time": "2022-06-17T02:02:19.355193",
     "exception": false,
     "start_time": "2022-06-17T00:59:35.155187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch 1/185 loss = 1.1916\n",
      "epoch 1 batch 2/185 loss = 1.0590\n",
      "epoch 1 batch 3/185 loss = 1.0275\n",
      "epoch 1 batch 4/185 loss = 0.9936\n",
      "epoch 1 batch 5/185 loss = 0.9776\n",
      "epoch 1 batch 6/185 loss = 0.9619\n",
      "epoch 1 batch 7/185 loss = 0.9572\n",
      "epoch 1 batch 8/185 loss = 0.9438\n",
      "epoch 1 batch 9/185 loss = 0.9261\n",
      "epoch 1 batch 10/185 loss = 0.9084\n",
      "epoch 1 batch 11/185 loss = 0.9203\n",
      "epoch 1 batch 12/185 loss = 0.8800\n",
      "epoch 1 batch 13/185 loss = 0.9016\n",
      "epoch 1 batch 14/185 loss = 0.8977\n",
      "epoch 1 batch 15/185 loss = 0.8853\n",
      "epoch 1 batch 16/185 loss = 0.8745\n",
      "epoch 1 batch 17/185 loss = 0.8760\n",
      "epoch 1 batch 18/185 loss = 0.8721\n",
      "epoch 1 batch 19/185 loss = 0.8634\n",
      "epoch 1 batch 20/185 loss = 0.8663\n",
      "epoch 1 batch 21/185 loss = 0.8495\n",
      "epoch 1 batch 22/185 loss = 0.8686\n",
      "epoch 1 batch 23/185 loss = 0.8692\n",
      "epoch 1 batch 24/185 loss = 0.8490\n",
      "epoch 1 batch 25/185 loss = 0.8636\n",
      "epoch 1 batch 26/185 loss = 0.8398\n",
      "epoch 1 batch 27/185 loss = 0.8650\n",
      "epoch 1 batch 28/185 loss = 0.8350\n",
      "epoch 1 batch 29/185 loss = 0.8456\n",
      "epoch 1 batch 30/185 loss = 0.8222\n",
      "epoch 1 batch 31/185 loss = 0.8146\n",
      "epoch 1 batch 32/185 loss = 0.8137\n",
      "epoch 1 batch 33/185 loss = 0.8076\n",
      "epoch 1 batch 34/185 loss = 0.8112\n",
      "epoch 1 batch 35/185 loss = 0.8431\n",
      "epoch 1 batch 36/185 loss = 0.8066\n",
      "epoch 1 batch 37/185 loss = 0.7930\n",
      "epoch 1 batch 38/185 loss = 0.8044\n",
      "epoch 1 batch 39/185 loss = 0.7929\n",
      "epoch 1 batch 40/185 loss = 0.7870\n",
      "epoch 1 batch 41/185 loss = 0.7995\n",
      "epoch 1 batch 42/185 loss = 0.7765\n",
      "epoch 1 batch 43/185 loss = 0.7814\n",
      "epoch 1 batch 44/185 loss = 0.8024\n",
      "epoch 1 batch 45/185 loss = 0.8010\n",
      "epoch 1 batch 46/185 loss = 0.7724\n",
      "epoch 1 batch 47/185 loss = 0.7709\n",
      "epoch 1 batch 48/185 loss = 0.7878\n",
      "epoch 1 batch 49/185 loss = 0.7755\n",
      "epoch 1 batch 50/185 loss = 0.7587\n",
      "epoch 1 batch 51/185 loss = 0.7479\n",
      "epoch 1 batch 52/185 loss = 0.7546\n",
      "epoch 1 batch 53/185 loss = 0.8135\n",
      "epoch 1 batch 54/185 loss = 0.7466\n",
      "epoch 1 batch 55/185 loss = 0.7598\n",
      "epoch 1 batch 56/185 loss = 0.7537\n",
      "epoch 1 batch 57/185 loss = 0.7582\n",
      "epoch 1 batch 58/185 loss = 0.7477\n",
      "epoch 1 batch 59/185 loss = 0.7400\n",
      "epoch 1 batch 60/185 loss = 0.7475\n",
      "epoch 1 batch 61/185 loss = 0.7439\n",
      "epoch 1 batch 62/185 loss = 0.7347\n",
      "epoch 1 batch 63/185 loss = 0.7609\n",
      "epoch 1 batch 64/185 loss = 0.7406\n",
      "epoch 1 batch 65/185 loss = 0.7276\n",
      "epoch 1 batch 66/185 loss = 0.7221\n",
      "epoch 1 batch 67/185 loss = 0.7339\n",
      "epoch 1 batch 68/185 loss = 0.7537\n",
      "epoch 1 batch 69/185 loss = 0.7144\n",
      "epoch 1 batch 70/185 loss = 0.7133\n",
      "epoch 1 batch 71/185 loss = 0.7232\n",
      "epoch 1 batch 72/185 loss = 0.7316\n",
      "epoch 1 batch 73/185 loss = 0.7165\n",
      "epoch 1 batch 74/185 loss = 0.7155\n",
      "epoch 1 batch 75/185 loss = 0.6995\n",
      "epoch 1 batch 76/185 loss = 0.6974\n",
      "epoch 1 batch 77/185 loss = 0.7064\n",
      "epoch 1 batch 78/185 loss = 0.7095\n",
      "epoch 1 batch 79/185 loss = 0.6898\n",
      "epoch 1 batch 80/185 loss = 0.7066\n",
      "epoch 1 batch 81/185 loss = 0.7004\n",
      "epoch 1 batch 82/185 loss = 0.6995\n",
      "epoch 1 batch 83/185 loss = 0.6848\n",
      "epoch 1 batch 84/185 loss = 0.6890\n",
      "epoch 1 batch 85/185 loss = 0.6894\n",
      "epoch 1 batch 86/185 loss = 0.6905\n",
      "epoch 1 batch 87/185 loss = 0.6596\n",
      "epoch 1 batch 88/185 loss = 0.6674\n",
      "epoch 1 batch 89/185 loss = 0.6668\n",
      "epoch 1 batch 90/185 loss = 0.6619\n",
      "epoch 1 batch 91/185 loss = 0.6759\n",
      "epoch 1 batch 92/185 loss = 0.6641\n",
      "epoch 1 batch 93/185 loss = 0.6667\n",
      "epoch 1 batch 94/185 loss = 0.6654\n",
      "epoch 1 batch 95/185 loss = 0.6797\n",
      "epoch 1 batch 96/185 loss = 0.6608\n",
      "epoch 1 batch 97/185 loss = 0.6646\n",
      "epoch 1 batch 98/185 loss = 0.6674\n",
      "epoch 1 batch 99/185 loss = 0.6522\n",
      "epoch 1 batch 100/185 loss = 0.6530\n",
      "epoch 1 batch 101/185 loss = 0.6599\n",
      "epoch 1 batch 102/185 loss = 0.6706\n",
      "epoch 1 batch 103/185 loss = 0.6491\n",
      "epoch 1 batch 104/185 loss = 0.6399\n",
      "epoch 1 batch 105/185 loss = 0.6484\n",
      "epoch 1 batch 106/185 loss = 0.6490\n",
      "epoch 1 batch 107/185 loss = 0.6399\n",
      "epoch 1 batch 108/185 loss = 0.6457\n",
      "epoch 1 batch 109/185 loss = 0.6204\n",
      "epoch 1 batch 110/185 loss = 0.6373\n",
      "epoch 1 batch 111/185 loss = 0.6185\n",
      "epoch 1 batch 112/185 loss = 0.6403\n",
      "epoch 1 batch 113/185 loss = 0.6393\n",
      "epoch 1 batch 114/185 loss = 0.6258\n",
      "epoch 1 batch 115/185 loss = 0.6213\n",
      "epoch 1 batch 116/185 loss = 0.6342\n",
      "epoch 1 batch 117/185 loss = 0.6264\n",
      "epoch 1 batch 118/185 loss = 0.6241\n",
      "epoch 1 batch 119/185 loss = 0.6100\n",
      "epoch 1 batch 120/185 loss = 0.6155\n",
      "epoch 1 batch 121/185 loss = 0.6136\n",
      "epoch 1 batch 122/185 loss = 0.6162\n",
      "epoch 1 batch 123/185 loss = 0.6166\n",
      "epoch 1 batch 124/185 loss = 0.6054\n",
      "epoch 1 batch 125/185 loss = 0.6028\n",
      "epoch 1 batch 126/185 loss = 0.6019\n",
      "epoch 1 batch 127/185 loss = 0.5951\n",
      "epoch 1 batch 128/185 loss = 0.5977\n",
      "epoch 1 batch 129/185 loss = 0.6128\n",
      "epoch 1 batch 130/185 loss = 0.6000\n",
      "epoch 1 batch 131/185 loss = 0.5742\n",
      "epoch 1 batch 132/185 loss = 0.5872\n",
      "epoch 1 batch 133/185 loss = 0.5825\n",
      "epoch 1 batch 134/185 loss = 0.5924\n",
      "epoch 1 batch 135/185 loss = 0.5917\n",
      "epoch 1 batch 136/185 loss = 0.5931\n",
      "epoch 1 batch 137/185 loss = 0.5891\n",
      "epoch 1 batch 138/185 loss = 0.5924\n",
      "epoch 1 batch 139/185 loss = 0.5870\n",
      "epoch 1 batch 140/185 loss = 0.5668\n",
      "epoch 1 batch 141/185 loss = 0.5832\n",
      "epoch 1 batch 142/185 loss = 0.5857\n",
      "epoch 1 batch 143/185 loss = 0.5645\n",
      "epoch 1 batch 144/185 loss = 0.5801\n",
      "epoch 1 batch 145/185 loss = 0.5819\n",
      "epoch 1 batch 146/185 loss = 0.5723\n",
      "epoch 1 batch 147/185 loss = 0.5583\n",
      "epoch 1 batch 148/185 loss = 0.5650\n",
      "epoch 1 batch 149/185 loss = 0.5806\n",
      "epoch 1 batch 150/185 loss = 0.5569\n",
      "epoch 1 batch 151/185 loss = 0.5628\n",
      "epoch 1 batch 152/185 loss = 0.5522\n",
      "epoch 1 batch 153/185 loss = 0.5642\n",
      "epoch 1 batch 154/185 loss = 0.5569\n",
      "epoch 1 batch 155/185 loss = 0.5495\n",
      "epoch 1 batch 156/185 loss = 0.5647\n",
      "epoch 1 batch 157/185 loss = 0.5396\n",
      "epoch 1 batch 158/185 loss = 0.5423\n",
      "epoch 1 batch 159/185 loss = 0.5437\n",
      "epoch 1 batch 160/185 loss = 0.5418\n",
      "epoch 1 batch 161/185 loss = 0.5440\n",
      "epoch 1 batch 162/185 loss = 0.5473\n",
      "epoch 1 batch 163/185 loss = 0.5305\n",
      "epoch 1 batch 164/185 loss = 0.5368\n",
      "epoch 1 batch 165/185 loss = 0.5285\n",
      "epoch 1 batch 166/185 loss = 0.5370\n",
      "epoch 1 batch 167/185 loss = 0.5328\n",
      "epoch 1 batch 168/185 loss = 0.5198\n",
      "epoch 1 batch 169/185 loss = 0.5059\n",
      "epoch 1 batch 170/185 loss = 0.5384\n",
      "epoch 1 batch 171/185 loss = 0.5274\n",
      "epoch 1 batch 172/185 loss = 0.5223\n",
      "epoch 1 batch 173/185 loss = 0.5274\n",
      "epoch 1 batch 174/185 loss = 0.5301\n",
      "epoch 1 batch 175/185 loss = 0.5119\n",
      "epoch 1 batch 176/185 loss = 0.5206\n",
      "epoch 1 batch 177/185 loss = 0.5206\n",
      "epoch 1 batch 178/185 loss = 0.5183\n",
      "epoch 1 batch 179/185 loss = 0.5207\n",
      "epoch 1 batch 180/185 loss = 0.5071\n",
      "epoch 1 batch 181/185 loss = 0.5269\n",
      "epoch 1 batch 182/185 loss = 0.5092\n",
      "epoch 1 batch 183/185 loss = 0.5066\n",
      "epoch 1 batch 184/185 loss = 0.5021\n",
      "epoch 1 batch 185/185 loss = 0.5168\n",
      "epoch 1 train loss = 0.6899 valid loss = 0.6776\n",
      "epoch 2 batch 1/185 loss = 0.4946\n",
      "epoch 2 batch 2/185 loss = 0.4967\n",
      "epoch 2 batch 3/185 loss = 0.4904\n",
      "epoch 2 batch 4/185 loss = 0.4923\n",
      "epoch 2 batch 5/185 loss = 0.5238\n",
      "epoch 2 batch 6/185 loss = 0.4911\n",
      "epoch 2 batch 7/185 loss = 0.4990\n",
      "epoch 2 batch 8/185 loss = 0.5115\n",
      "epoch 2 batch 9/185 loss = 0.4762\n",
      "epoch 2 batch 10/185 loss = 0.4847\n",
      "epoch 2 batch 11/185 loss = 0.4834\n",
      "epoch 2 batch 12/185 loss = 0.4862\n",
      "epoch 2 batch 13/185 loss = 0.4895\n",
      "epoch 2 batch 14/185 loss = 0.4791\n",
      "epoch 2 batch 15/185 loss = 0.4778\n",
      "epoch 2 batch 16/185 loss = 0.4850\n",
      "epoch 2 batch 17/185 loss = 0.4719\n",
      "epoch 2 batch 18/185 loss = 0.4878\n",
      "epoch 2 batch 19/185 loss = 0.4873\n",
      "epoch 2 batch 20/185 loss = 0.4653\n",
      "epoch 2 batch 21/185 loss = 0.4753\n",
      "epoch 2 batch 22/185 loss = 0.4754\n",
      "epoch 2 batch 23/185 loss = 0.4662\n",
      "epoch 2 batch 24/185 loss = 0.4611\n",
      "epoch 2 batch 25/185 loss = 0.4683\n",
      "epoch 2 batch 26/185 loss = 0.4604\n",
      "epoch 2 batch 27/185 loss = 0.4758\n",
      "epoch 2 batch 28/185 loss = 0.4640\n",
      "epoch 2 batch 29/185 loss = 0.4441\n",
      "epoch 2 batch 30/185 loss = 0.4584\n",
      "epoch 2 batch 31/185 loss = 0.4656\n",
      "epoch 2 batch 32/185 loss = 0.4622\n",
      "epoch 2 batch 33/185 loss = 0.4413\n",
      "epoch 2 batch 34/185 loss = 0.4585\n",
      "epoch 2 batch 35/185 loss = 0.4635\n",
      "epoch 2 batch 36/185 loss = 0.4650\n",
      "epoch 2 batch 37/185 loss = 0.4514\n",
      "epoch 2 batch 38/185 loss = 0.4546\n",
      "epoch 2 batch 39/185 loss = 0.4492\n",
      "epoch 2 batch 40/185 loss = 0.4450\n",
      "epoch 2 batch 41/185 loss = 0.4580\n",
      "epoch 2 batch 42/185 loss = 0.4328\n",
      "epoch 2 batch 43/185 loss = 0.4589\n",
      "epoch 2 batch 44/185 loss = 0.4493\n",
      "epoch 2 batch 45/185 loss = 0.4411\n",
      "epoch 2 batch 46/185 loss = 0.4333\n",
      "epoch 2 batch 47/185 loss = 0.4329\n",
      "epoch 2 batch 48/185 loss = 0.4386\n",
      "epoch 2 batch 49/185 loss = 0.4368\n",
      "epoch 2 batch 50/185 loss = 0.4401\n",
      "epoch 2 batch 51/185 loss = 0.4341\n",
      "epoch 2 batch 52/185 loss = 0.4251\n",
      "epoch 2 batch 53/185 loss = 0.4304\n",
      "epoch 2 batch 54/185 loss = 0.4341\n",
      "epoch 2 batch 55/185 loss = 0.4266\n",
      "epoch 2 batch 56/185 loss = 0.4312\n",
      "epoch 2 batch 57/185 loss = 0.4215\n",
      "epoch 2 batch 58/185 loss = 0.4248\n",
      "epoch 2 batch 59/185 loss = 0.4243\n",
      "epoch 2 batch 60/185 loss = 0.4402\n",
      "epoch 2 batch 61/185 loss = 0.4296\n",
      "epoch 2 batch 62/185 loss = 0.4265\n",
      "epoch 2 batch 63/185 loss = 0.4159\n",
      "epoch 2 batch 64/185 loss = 0.4161\n",
      "epoch 2 batch 65/185 loss = 0.4144\n",
      "epoch 2 batch 66/185 loss = 0.4009\n",
      "epoch 2 batch 67/185 loss = 0.4170\n",
      "epoch 2 batch 68/185 loss = 0.4086\n",
      "epoch 2 batch 69/185 loss = 0.4341\n",
      "epoch 2 batch 70/185 loss = 0.4170\n",
      "epoch 2 batch 71/185 loss = 0.4004\n",
      "epoch 2 batch 72/185 loss = 0.4022\n",
      "epoch 2 batch 73/185 loss = 0.4057\n",
      "epoch 2 batch 74/185 loss = 0.4166\n",
      "epoch 2 batch 75/185 loss = 0.3952\n",
      "epoch 2 batch 76/185 loss = 0.3905\n",
      "epoch 2 batch 77/185 loss = 0.3942\n",
      "epoch 2 batch 78/185 loss = 0.3937\n",
      "epoch 2 batch 79/185 loss = 0.3967\n",
      "epoch 2 batch 80/185 loss = 0.3863\n",
      "epoch 2 batch 81/185 loss = 0.3911\n",
      "epoch 2 batch 82/185 loss = 0.3860\n",
      "epoch 2 batch 83/185 loss = 0.3857\n",
      "epoch 2 batch 84/185 loss = 0.3909\n",
      "epoch 2 batch 85/185 loss = 0.3921\n",
      "epoch 2 batch 86/185 loss = 0.3842\n",
      "epoch 2 batch 87/185 loss = 0.3928\n",
      "epoch 2 batch 88/185 loss = 0.3841\n",
      "epoch 2 batch 89/185 loss = 0.3942\n",
      "epoch 2 batch 90/185 loss = 0.3787\n",
      "epoch 2 batch 91/185 loss = 0.3904\n",
      "epoch 2 batch 92/185 loss = 0.3726\n",
      "epoch 2 batch 93/185 loss = 0.3736\n",
      "epoch 2 batch 94/185 loss = 0.3875\n",
      "epoch 2 batch 95/185 loss = 0.3726\n",
      "epoch 2 batch 96/185 loss = 0.3738\n",
      "epoch 2 batch 97/185 loss = 0.3767\n",
      "epoch 2 batch 98/185 loss = 0.3598\n",
      "epoch 2 batch 99/185 loss = 0.3712\n",
      "epoch 2 batch 100/185 loss = 0.3691\n",
      "epoch 2 batch 101/185 loss = 0.3754\n",
      "epoch 2 batch 102/185 loss = 0.3555\n",
      "epoch 2 batch 103/185 loss = 0.3615\n",
      "epoch 2 batch 104/185 loss = 0.3635\n",
      "epoch 2 batch 105/185 loss = 0.3745\n",
      "epoch 2 batch 106/185 loss = 0.3538\n",
      "epoch 2 batch 107/185 loss = 0.3623\n",
      "epoch 2 batch 108/185 loss = 0.3527\n",
      "epoch 2 batch 109/185 loss = 0.3548\n",
      "epoch 2 batch 110/185 loss = 0.3546\n",
      "epoch 2 batch 111/185 loss = 0.3563\n",
      "epoch 2 batch 112/185 loss = 0.3572\n",
      "epoch 2 batch 113/185 loss = 0.3807\n",
      "epoch 2 batch 114/185 loss = 0.3527\n",
      "epoch 2 batch 115/185 loss = 0.3591\n",
      "epoch 2 batch 116/185 loss = 0.3682\n",
      "epoch 2 batch 117/185 loss = 0.3482\n",
      "epoch 2 batch 118/185 loss = 0.3609\n",
      "epoch 2 batch 119/185 loss = 0.3507\n",
      "epoch 2 batch 120/185 loss = 0.3529\n",
      "epoch 2 batch 121/185 loss = 0.3542\n",
      "epoch 2 batch 122/185 loss = 0.3413\n",
      "epoch 2 batch 123/185 loss = 0.3473\n",
      "epoch 2 batch 124/185 loss = 0.3391\n",
      "epoch 2 batch 125/185 loss = 0.3451\n",
      "epoch 2 batch 126/185 loss = 0.3486\n",
      "epoch 2 batch 127/185 loss = 0.3594\n",
      "epoch 2 batch 128/185 loss = 0.3402\n",
      "epoch 2 batch 129/185 loss = 0.3417\n",
      "epoch 2 batch 130/185 loss = 0.3438\n",
      "epoch 2 batch 131/185 loss = 0.3409\n",
      "epoch 2 batch 132/185 loss = 0.3283\n",
      "epoch 2 batch 133/185 loss = 0.3155\n",
      "epoch 2 batch 134/185 loss = 0.3304\n",
      "epoch 2 batch 135/185 loss = 0.3380\n",
      "epoch 2 batch 136/185 loss = 0.3216\n",
      "epoch 2 batch 137/185 loss = 0.3351\n",
      "epoch 2 batch 138/185 loss = 0.3281\n",
      "epoch 2 batch 139/185 loss = 0.3337\n",
      "epoch 2 batch 140/185 loss = 0.3180\n",
      "epoch 2 batch 141/185 loss = 0.3358\n",
      "epoch 2 batch 142/185 loss = 0.3092\n",
      "epoch 2 batch 143/185 loss = 0.3309\n",
      "epoch 2 batch 144/185 loss = 0.3123\n",
      "epoch 2 batch 145/185 loss = 0.3201\n",
      "epoch 2 batch 146/185 loss = 0.3235\n",
      "epoch 2 batch 147/185 loss = 0.3293\n",
      "epoch 2 batch 148/185 loss = 0.3362\n",
      "epoch 2 batch 149/185 loss = 0.3159\n",
      "epoch 2 batch 150/185 loss = 0.3201\n",
      "epoch 2 batch 151/185 loss = 0.3026\n",
      "epoch 2 batch 152/185 loss = 0.3172\n",
      "epoch 2 batch 153/185 loss = 0.3184\n",
      "epoch 2 batch 154/185 loss = 0.2980\n",
      "epoch 2 batch 155/185 loss = 0.3192\n",
      "epoch 2 batch 156/185 loss = 0.3084\n",
      "epoch 2 batch 157/185 loss = 0.3160\n",
      "epoch 2 batch 158/185 loss = 0.3138\n",
      "epoch 2 batch 159/185 loss = 0.3013\n",
      "epoch 2 batch 160/185 loss = 0.3168\n",
      "epoch 2 batch 161/185 loss = 0.3094\n",
      "epoch 2 batch 162/185 loss = 0.3000\n",
      "epoch 2 batch 163/185 loss = 0.2971\n",
      "epoch 2 batch 164/185 loss = 0.3116\n",
      "epoch 2 batch 165/185 loss = 0.3083\n",
      "epoch 2 batch 166/185 loss = 0.3010\n",
      "epoch 2 batch 167/185 loss = 0.2935\n",
      "epoch 2 batch 168/185 loss = 0.2924\n",
      "epoch 2 batch 169/185 loss = 0.2982\n",
      "epoch 2 batch 170/185 loss = 0.2983\n",
      "epoch 2 batch 171/185 loss = 0.2984\n",
      "epoch 2 batch 172/185 loss = 0.2885\n",
      "epoch 2 batch 173/185 loss = 0.3012\n",
      "epoch 2 batch 174/185 loss = 0.2957\n",
      "epoch 2 batch 175/185 loss = 0.2876\n",
      "epoch 2 batch 176/185 loss = 0.2904\n",
      "epoch 2 batch 177/185 loss = 0.2910\n",
      "epoch 2 batch 178/185 loss = 0.2899\n",
      "epoch 2 batch 179/185 loss = 0.2894\n",
      "epoch 2 batch 180/185 loss = 0.2961\n",
      "epoch 2 batch 181/185 loss = 0.2848\n",
      "epoch 2 batch 182/185 loss = 0.2832\n",
      "epoch 2 batch 183/185 loss = 0.2828\n",
      "epoch 2 batch 184/185 loss = 0.2888\n",
      "epoch 2 batch 185/185 loss = 0.2857\n",
      "epoch 2 train loss = 0.3845 valid loss = 0.3058\n",
      "epoch 3 batch 1/185 loss = 0.2850\n",
      "epoch 3 batch 2/185 loss = 0.2877\n",
      "epoch 3 batch 3/185 loss = 0.2853\n",
      "epoch 3 batch 4/185 loss = 0.2778\n",
      "epoch 3 batch 5/185 loss = 0.2702\n",
      "epoch 3 batch 6/185 loss = 0.2756\n",
      "epoch 3 batch 7/185 loss = 0.2782\n",
      "epoch 3 batch 8/185 loss = 0.2782\n",
      "epoch 3 batch 9/185 loss = 0.2846\n",
      "epoch 3 batch 10/185 loss = 0.2755\n",
      "epoch 3 batch 11/185 loss = 0.2736\n",
      "epoch 3 batch 12/185 loss = 0.2760\n",
      "epoch 3 batch 13/185 loss = 0.2725\n",
      "epoch 3 batch 14/185 loss = 0.2642\n",
      "epoch 3 batch 15/185 loss = 0.2737\n",
      "epoch 3 batch 16/185 loss = 0.2839\n",
      "epoch 3 batch 17/185 loss = 0.2721\n",
      "epoch 3 batch 18/185 loss = 0.2701\n",
      "epoch 3 batch 19/185 loss = 0.2766\n",
      "epoch 3 batch 20/185 loss = 0.2597\n",
      "epoch 3 batch 21/185 loss = 0.2606\n",
      "epoch 3 batch 22/185 loss = 0.2663\n",
      "epoch 3 batch 23/185 loss = 0.2476\n",
      "epoch 3 batch 24/185 loss = 0.2580\n",
      "epoch 3 batch 25/185 loss = 0.2600\n",
      "epoch 3 batch 26/185 loss = 0.2585\n",
      "epoch 3 batch 27/185 loss = 0.2621\n",
      "epoch 3 batch 28/185 loss = 0.2521\n",
      "epoch 3 batch 29/185 loss = 0.2587\n",
      "epoch 3 batch 30/185 loss = 0.2702\n",
      "epoch 3 batch 31/185 loss = 0.2468\n",
      "epoch 3 batch 32/185 loss = 0.2434\n",
      "epoch 3 batch 33/185 loss = 0.2605\n",
      "epoch 3 batch 34/185 loss = 0.2637\n",
      "epoch 3 batch 35/185 loss = 0.2732\n",
      "epoch 3 batch 36/185 loss = 0.2523\n",
      "epoch 3 batch 37/185 loss = 0.2525\n",
      "epoch 3 batch 38/185 loss = 0.2448\n",
      "epoch 3 batch 39/185 loss = 0.2499\n",
      "epoch 3 batch 40/185 loss = 0.2634\n",
      "epoch 3 batch 41/185 loss = 0.2455\n",
      "epoch 3 batch 42/185 loss = 0.2384\n",
      "epoch 3 batch 43/185 loss = 0.2525\n",
      "epoch 3 batch 44/185 loss = 0.2449\n",
      "epoch 3 batch 45/185 loss = 0.2518\n",
      "epoch 3 batch 46/185 loss = 0.2531\n",
      "epoch 3 batch 47/185 loss = 0.2474\n",
      "epoch 3 batch 48/185 loss = 0.2428\n",
      "epoch 3 batch 49/185 loss = 0.2489\n",
      "epoch 3 batch 50/185 loss = 0.2437\n",
      "epoch 3 batch 51/185 loss = 0.2465\n",
      "epoch 3 batch 52/185 loss = 0.2352\n",
      "epoch 3 batch 53/185 loss = 0.2381\n",
      "epoch 3 batch 54/185 loss = 0.2373\n",
      "epoch 3 batch 55/185 loss = 0.2413\n",
      "epoch 3 batch 56/185 loss = 0.2574\n",
      "epoch 3 batch 57/185 loss = 0.2229\n",
      "epoch 3 batch 58/185 loss = 0.2384\n",
      "epoch 3 batch 59/185 loss = 0.2465\n",
      "epoch 3 batch 60/185 loss = 0.2391\n",
      "epoch 3 batch 61/185 loss = 0.2340\n",
      "epoch 3 batch 62/185 loss = 0.2411\n",
      "epoch 3 batch 63/185 loss = 0.2230\n",
      "epoch 3 batch 64/185 loss = 0.2223\n",
      "epoch 3 batch 65/185 loss = 0.2223\n",
      "epoch 3 batch 66/185 loss = 0.2406\n",
      "epoch 3 batch 67/185 loss = 0.2268\n",
      "epoch 3 batch 68/185 loss = 0.2185\n",
      "epoch 3 batch 69/185 loss = 0.2272\n",
      "epoch 3 batch 70/185 loss = 0.2284\n",
      "epoch 3 batch 71/185 loss = 0.2280\n",
      "epoch 3 batch 72/185 loss = 0.2314\n",
      "epoch 3 batch 73/185 loss = 0.2276\n",
      "epoch 3 batch 74/185 loss = 0.2229\n",
      "epoch 3 batch 75/185 loss = 0.2274\n",
      "epoch 3 batch 76/185 loss = 0.2203\n",
      "epoch 3 batch 77/185 loss = 0.2268\n",
      "epoch 3 batch 78/185 loss = 0.2202\n",
      "epoch 3 batch 79/185 loss = 0.2308\n",
      "epoch 3 batch 80/185 loss = 0.2237\n",
      "epoch 3 batch 81/185 loss = 0.2172\n",
      "epoch 3 batch 82/185 loss = 0.2188\n",
      "epoch 3 batch 83/185 loss = 0.2295\n",
      "epoch 3 batch 84/185 loss = 0.2221\n",
      "epoch 3 batch 85/185 loss = 0.2109\n",
      "epoch 3 batch 86/185 loss = 0.2091\n",
      "epoch 3 batch 87/185 loss = 0.2128\n",
      "epoch 3 batch 88/185 loss = 0.2173\n",
      "epoch 3 batch 89/185 loss = 0.2139\n",
      "epoch 3 batch 90/185 loss = 0.2105\n",
      "epoch 3 batch 91/185 loss = 0.2125\n",
      "epoch 3 batch 92/185 loss = 0.2062\n",
      "epoch 3 batch 93/185 loss = 0.2137\n",
      "epoch 3 batch 94/185 loss = 0.2080\n",
      "epoch 3 batch 95/185 loss = 0.2076\n",
      "epoch 3 batch 96/185 loss = 0.2034\n",
      "epoch 3 batch 97/185 loss = 0.2082\n",
      "epoch 3 batch 98/185 loss = 0.2076\n",
      "epoch 3 batch 99/185 loss = 0.2082\n",
      "epoch 3 batch 100/185 loss = 0.1960\n",
      "epoch 3 batch 101/185 loss = 0.1976\n",
      "epoch 3 batch 102/185 loss = 0.1996\n",
      "epoch 3 batch 103/185 loss = 0.1974\n",
      "epoch 3 batch 104/185 loss = 0.1979\n",
      "epoch 3 batch 105/185 loss = 0.2028\n",
      "epoch 3 batch 106/185 loss = 0.2030\n",
      "epoch 3 batch 107/185 loss = 0.2059\n",
      "epoch 3 batch 108/185 loss = 0.2006\n",
      "epoch 3 batch 109/185 loss = 0.2012\n",
      "epoch 3 batch 110/185 loss = 0.1997\n",
      "epoch 3 batch 111/185 loss = 0.2062\n",
      "epoch 3 batch 112/185 loss = 0.2070\n",
      "epoch 3 batch 113/185 loss = 0.1981\n",
      "epoch 3 batch 114/185 loss = 0.1862\n",
      "epoch 3 batch 115/185 loss = 0.1948\n",
      "epoch 3 batch 116/185 loss = 0.2015\n",
      "epoch 3 batch 117/185 loss = 0.2052\n",
      "epoch 3 batch 118/185 loss = 0.2003\n",
      "epoch 3 batch 119/185 loss = 0.1921\n",
      "epoch 3 batch 120/185 loss = 0.1979\n",
      "epoch 3 batch 121/185 loss = 0.1901\n",
      "epoch 3 batch 122/185 loss = 0.1932\n",
      "epoch 3 batch 123/185 loss = 0.1818\n",
      "epoch 3 batch 124/185 loss = 0.1844\n",
      "epoch 3 batch 125/185 loss = 0.1855\n",
      "epoch 3 batch 126/185 loss = 0.1921\n",
      "epoch 3 batch 127/185 loss = 0.1908\n",
      "epoch 3 batch 128/185 loss = 0.1824\n",
      "epoch 3 batch 129/185 loss = 0.1926\n",
      "epoch 3 batch 130/185 loss = 0.1797\n",
      "epoch 3 batch 131/185 loss = 0.1836\n",
      "epoch 3 batch 132/185 loss = 0.1946\n",
      "epoch 3 batch 133/185 loss = 0.1869\n",
      "epoch 3 batch 134/185 loss = 0.1823\n",
      "epoch 3 batch 135/185 loss = 0.1818\n",
      "epoch 3 batch 136/185 loss = 0.1858\n",
      "epoch 3 batch 137/185 loss = 0.1926\n",
      "epoch 3 batch 138/185 loss = 0.1791\n",
      "epoch 3 batch 139/185 loss = 0.1746\n",
      "epoch 3 batch 140/185 loss = 0.1731\n",
      "epoch 3 batch 141/185 loss = 0.1798\n",
      "epoch 3 batch 142/185 loss = 0.1808\n",
      "epoch 3 batch 143/185 loss = 0.1724\n",
      "epoch 3 batch 144/185 loss = 0.1726\n",
      "epoch 3 batch 145/185 loss = 0.1707\n",
      "epoch 3 batch 146/185 loss = 0.1793\n",
      "epoch 3 batch 147/185 loss = 0.1747\n",
      "epoch 3 batch 148/185 loss = 0.1854\n",
      "epoch 3 batch 149/185 loss = 0.1695\n",
      "epoch 3 batch 150/185 loss = 0.1771\n",
      "epoch 3 batch 151/185 loss = 0.1844\n",
      "epoch 3 batch 152/185 loss = 0.1718\n",
      "epoch 3 batch 153/185 loss = 0.1714\n",
      "epoch 3 batch 154/185 loss = 0.1698\n",
      "epoch 3 batch 155/185 loss = 0.1664\n",
      "epoch 3 batch 156/185 loss = 0.1680\n",
      "epoch 3 batch 157/185 loss = 0.1660\n",
      "epoch 3 batch 158/185 loss = 0.1681\n",
      "epoch 3 batch 159/185 loss = 0.1644\n",
      "epoch 3 batch 160/185 loss = 0.1701\n",
      "epoch 3 batch 161/185 loss = 0.1628\n",
      "epoch 3 batch 162/185 loss = 0.1723\n",
      "epoch 3 batch 163/185 loss = 0.1708\n",
      "epoch 3 batch 164/185 loss = 0.1746\n",
      "epoch 3 batch 165/185 loss = 0.1611\n",
      "epoch 3 batch 166/185 loss = 0.1603\n",
      "epoch 3 batch 167/185 loss = 0.1664\n",
      "epoch 3 batch 168/185 loss = 0.1661\n",
      "epoch 3 batch 169/185 loss = 0.1553\n",
      "epoch 3 batch 170/185 loss = 0.1700\n",
      "epoch 3 batch 171/185 loss = 0.1741\n",
      "epoch 3 batch 172/185 loss = 0.1649\n",
      "epoch 3 batch 173/185 loss = 0.1751\n",
      "epoch 3 batch 174/185 loss = 0.1561\n",
      "epoch 3 batch 175/185 loss = 0.1602\n",
      "epoch 3 batch 176/185 loss = 0.1575\n",
      "epoch 3 batch 177/185 loss = 0.1512\n",
      "epoch 3 batch 178/185 loss = 0.1562\n",
      "epoch 3 batch 179/185 loss = 0.1554\n",
      "epoch 3 batch 180/185 loss = 0.1637\n",
      "epoch 3 batch 181/185 loss = 0.1585\n",
      "epoch 3 batch 182/185 loss = 0.1532\n",
      "epoch 3 batch 183/185 loss = 0.1542\n",
      "epoch 3 batch 184/185 loss = 0.1582\n",
      "epoch 3 batch 185/185 loss = 0.1581\n",
      "epoch 3 train loss = 0.2137 valid loss = 0.1717\n",
      "epoch 4 batch 1/185 loss = 0.1533\n",
      "epoch 4 batch 2/185 loss = 0.1517\n",
      "epoch 4 batch 3/185 loss = 0.1488\n",
      "epoch 4 batch 4/185 loss = 0.1552\n",
      "epoch 4 batch 5/185 loss = 0.1453\n",
      "epoch 4 batch 6/185 loss = 0.1468\n",
      "epoch 4 batch 7/185 loss = 0.1581\n",
      "epoch 4 batch 8/185 loss = 0.1604\n",
      "epoch 4 batch 9/185 loss = 0.1483\n",
      "epoch 4 batch 10/185 loss = 0.1472\n",
      "epoch 4 batch 11/185 loss = 0.1470\n",
      "epoch 4 batch 12/185 loss = 0.1445\n",
      "epoch 4 batch 13/185 loss = 0.1532\n",
      "epoch 4 batch 14/185 loss = 0.1434\n",
      "epoch 4 batch 15/185 loss = 0.1437\n",
      "epoch 4 batch 16/185 loss = 0.1542\n",
      "epoch 4 batch 17/185 loss = 0.1461\n",
      "epoch 4 batch 18/185 loss = 0.1434\n",
      "epoch 4 batch 19/185 loss = 0.1517\n",
      "epoch 4 batch 20/185 loss = 0.1504\n",
      "epoch 4 batch 21/185 loss = 0.1411\n",
      "epoch 4 batch 22/185 loss = 0.1520\n",
      "epoch 4 batch 23/185 loss = 0.1560\n",
      "epoch 4 batch 24/185 loss = 0.1425\n",
      "epoch 4 batch 25/185 loss = 0.1427\n",
      "epoch 4 batch 26/185 loss = 0.1402\n",
      "epoch 4 batch 27/185 loss = 0.1400\n",
      "epoch 4 batch 28/185 loss = 0.1379\n",
      "epoch 4 batch 29/185 loss = 0.1386\n",
      "epoch 4 batch 30/185 loss = 0.1401\n",
      "epoch 4 batch 31/185 loss = 0.1321\n",
      "epoch 4 batch 32/185 loss = 0.1377\n",
      "epoch 4 batch 33/185 loss = 0.1299\n",
      "epoch 4 batch 34/185 loss = 0.1377\n",
      "epoch 4 batch 35/185 loss = 0.1312\n",
      "epoch 4 batch 36/185 loss = 0.1354\n",
      "epoch 4 batch 37/185 loss = 0.1322\n",
      "epoch 4 batch 38/185 loss = 0.1376\n",
      "epoch 4 batch 39/185 loss = 0.1274\n",
      "epoch 4 batch 40/185 loss = 0.1317\n",
      "epoch 4 batch 41/185 loss = 0.1363\n",
      "epoch 4 batch 42/185 loss = 0.1370\n",
      "epoch 4 batch 43/185 loss = 0.1302\n",
      "epoch 4 batch 44/185 loss = 0.1437\n",
      "epoch 4 batch 45/185 loss = 0.1328\n",
      "epoch 4 batch 46/185 loss = 0.1298\n",
      "epoch 4 batch 47/185 loss = 0.1356\n",
      "epoch 4 batch 48/185 loss = 0.1290\n",
      "epoch 4 batch 49/185 loss = 0.1392\n",
      "epoch 4 batch 50/185 loss = 0.1356\n",
      "epoch 4 batch 51/185 loss = 0.1383\n",
      "epoch 4 batch 52/185 loss = 0.1271\n",
      "epoch 4 batch 53/185 loss = 0.1384\n",
      "epoch 4 batch 54/185 loss = 0.1364\n",
      "epoch 4 batch 55/185 loss = 0.1293\n",
      "epoch 4 batch 56/185 loss = 0.1306\n",
      "epoch 4 batch 57/185 loss = 0.1383\n",
      "epoch 4 batch 58/185 loss = 0.1247\n",
      "epoch 4 batch 59/185 loss = 0.1224\n",
      "epoch 4 batch 60/185 loss = 0.1255\n",
      "epoch 4 batch 61/185 loss = 0.1252\n",
      "epoch 4 batch 62/185 loss = 0.1243\n",
      "epoch 4 batch 63/185 loss = 0.1378\n",
      "epoch 4 batch 64/185 loss = 0.1219\n",
      "epoch 4 batch 65/185 loss = 0.1220\n",
      "epoch 4 batch 66/185 loss = 0.1203\n",
      "epoch 4 batch 67/185 loss = 0.1208\n",
      "epoch 4 batch 68/185 loss = 0.1185\n",
      "epoch 4 batch 69/185 loss = 0.1160\n",
      "epoch 4 batch 70/185 loss = 0.1276\n",
      "epoch 4 batch 71/185 loss = 0.1245\n",
      "epoch 4 batch 72/185 loss = 0.1276\n",
      "epoch 4 batch 73/185 loss = 0.1197\n",
      "epoch 4 batch 74/185 loss = 0.1152\n",
      "epoch 4 batch 75/185 loss = 0.1246\n",
      "epoch 4 batch 76/185 loss = 0.1235\n",
      "epoch 4 batch 77/185 loss = 0.1159\n",
      "epoch 4 batch 78/185 loss = 0.1123\n",
      "epoch 4 batch 79/185 loss = 0.1214\n",
      "epoch 4 batch 80/185 loss = 0.1209\n",
      "epoch 4 batch 81/185 loss = 0.1251\n",
      "epoch 4 batch 82/185 loss = 0.1249\n",
      "epoch 4 batch 83/185 loss = 0.1225\n",
      "epoch 4 batch 84/185 loss = 0.1250\n",
      "epoch 4 batch 85/185 loss = 0.1177\n",
      "epoch 4 batch 86/185 loss = 0.1128\n",
      "epoch 4 batch 87/185 loss = 0.1218\n",
      "epoch 4 batch 88/185 loss = 0.1123\n",
      "epoch 4 batch 89/185 loss = 0.1174\n",
      "epoch 4 batch 90/185 loss = 0.1115\n",
      "epoch 4 batch 91/185 loss = 0.1173\n",
      "epoch 4 batch 92/185 loss = 0.1269\n",
      "epoch 4 batch 93/185 loss = 0.1132\n",
      "epoch 4 batch 94/185 loss = 0.1189\n",
      "epoch 4 batch 95/185 loss = 0.1121\n",
      "epoch 4 batch 96/185 loss = 0.1181\n",
      "epoch 4 batch 97/185 loss = 0.1179\n",
      "epoch 4 batch 98/185 loss = 0.1203\n",
      "epoch 4 batch 99/185 loss = 0.1092\n",
      "epoch 4 batch 100/185 loss = 0.1094\n",
      "epoch 4 batch 101/185 loss = 0.1121\n",
      "epoch 4 batch 102/185 loss = 0.1117\n",
      "epoch 4 batch 103/185 loss = 0.1129\n",
      "epoch 4 batch 104/185 loss = 0.1114\n",
      "epoch 4 batch 105/185 loss = 0.1074\n",
      "epoch 4 batch 106/185 loss = 0.1078\n",
      "epoch 4 batch 107/185 loss = 0.1134\n",
      "epoch 4 batch 108/185 loss = 0.1104\n",
      "epoch 4 batch 109/185 loss = 0.1042\n",
      "epoch 4 batch 110/185 loss = 0.1182\n",
      "epoch 4 batch 111/185 loss = 0.1115\n",
      "epoch 4 batch 112/185 loss = 0.1130\n",
      "epoch 4 batch 113/185 loss = 0.1031\n",
      "epoch 4 batch 114/185 loss = 0.1012\n",
      "epoch 4 batch 115/185 loss = 0.1048\n",
      "epoch 4 batch 116/185 loss = 0.1002\n",
      "epoch 4 batch 117/185 loss = 0.1083\n",
      "epoch 4 batch 118/185 loss = 0.1135\n",
      "epoch 4 batch 119/185 loss = 0.1023\n",
      "epoch 4 batch 120/185 loss = 0.1127\n",
      "epoch 4 batch 121/185 loss = 0.1051\n",
      "epoch 4 batch 122/185 loss = 0.0985\n",
      "epoch 4 batch 123/185 loss = 0.1058\n",
      "epoch 4 batch 124/185 loss = 0.1047\n",
      "epoch 4 batch 125/185 loss = 0.1077\n",
      "epoch 4 batch 126/185 loss = 0.1030\n",
      "epoch 4 batch 127/185 loss = 0.0966\n",
      "epoch 4 batch 128/185 loss = 0.0961\n",
      "epoch 4 batch 129/185 loss = 0.0969\n",
      "epoch 4 batch 130/185 loss = 0.1077\n",
      "epoch 4 batch 131/185 loss = 0.0987\n",
      "epoch 4 batch 132/185 loss = 0.1005\n",
      "epoch 4 batch 133/185 loss = 0.1057\n",
      "epoch 4 batch 134/185 loss = 0.0991\n",
      "epoch 4 batch 135/185 loss = 0.0971\n",
      "epoch 4 batch 136/185 loss = 0.0951\n",
      "epoch 4 batch 137/185 loss = 0.1071\n",
      "epoch 4 batch 138/185 loss = 0.0969\n",
      "epoch 4 batch 139/185 loss = 0.1002\n",
      "epoch 4 batch 140/185 loss = 0.1046\n",
      "epoch 4 batch 141/185 loss = 0.1008\n",
      "epoch 4 batch 142/185 loss = 0.0940\n",
      "epoch 4 batch 143/185 loss = 0.0964\n",
      "epoch 4 batch 144/185 loss = 0.0928\n",
      "epoch 4 batch 145/185 loss = 0.0964\n",
      "epoch 4 batch 146/185 loss = 0.1092\n",
      "epoch 4 batch 147/185 loss = 0.0997\n",
      "epoch 4 batch 148/185 loss = 0.0922\n",
      "epoch 4 batch 149/185 loss = 0.0952\n",
      "epoch 4 batch 150/185 loss = 0.1001\n",
      "epoch 4 batch 151/185 loss = 0.0928\n",
      "epoch 4 batch 152/185 loss = 0.0881\n",
      "epoch 4 batch 153/185 loss = 0.0997\n",
      "epoch 4 batch 154/185 loss = 0.0980\n",
      "epoch 4 batch 155/185 loss = 0.0984\n",
      "epoch 4 batch 156/185 loss = 0.0880\n",
      "epoch 4 batch 157/185 loss = 0.0949\n",
      "epoch 4 batch 158/185 loss = 0.0971\n",
      "epoch 4 batch 159/185 loss = 0.0928\n",
      "epoch 4 batch 160/185 loss = 0.0992\n",
      "epoch 4 batch 161/185 loss = 0.0908\n",
      "epoch 4 batch 162/185 loss = 0.0904\n",
      "epoch 4 batch 163/185 loss = 0.0959\n",
      "epoch 4 batch 164/185 loss = 0.0938\n",
      "epoch 4 batch 165/185 loss = 0.0935\n",
      "epoch 4 batch 166/185 loss = 0.0885\n",
      "epoch 4 batch 167/185 loss = 0.0891\n",
      "epoch 4 batch 168/185 loss = 0.0814\n",
      "epoch 4 batch 169/185 loss = 0.0910\n",
      "epoch 4 batch 170/185 loss = 0.0848\n",
      "epoch 4 batch 171/185 loss = 0.0908\n",
      "epoch 4 batch 172/185 loss = 0.0899\n",
      "epoch 4 batch 173/185 loss = 0.0797\n",
      "epoch 4 batch 174/185 loss = 0.0900\n",
      "epoch 4 batch 175/185 loss = 0.0831\n",
      "epoch 4 batch 176/185 loss = 0.0805\n",
      "epoch 4 batch 177/185 loss = 0.0928\n",
      "epoch 4 batch 178/185 loss = 0.0919\n",
      "epoch 4 batch 179/185 loss = 0.0871\n",
      "epoch 4 batch 180/185 loss = 0.0849\n",
      "epoch 4 batch 181/185 loss = 0.0818\n",
      "epoch 4 batch 182/185 loss = 0.0875\n",
      "epoch 4 batch 183/185 loss = 0.0822\n",
      "epoch 4 batch 184/185 loss = 0.0835\n",
      "epoch 4 batch 185/185 loss = 0.0861\n",
      "epoch 4 train loss = 0.1164 valid loss = 0.0969\n",
      "epoch 5 batch 1/185 loss = 0.0839\n",
      "epoch 5 batch 2/185 loss = 0.0887\n",
      "epoch 5 batch 3/185 loss = 0.0868\n",
      "epoch 5 batch 4/185 loss = 0.0830\n",
      "epoch 5 batch 5/185 loss = 0.0899\n",
      "epoch 5 batch 6/185 loss = 0.0846\n",
      "epoch 5 batch 7/185 loss = 0.0851\n",
      "epoch 5 batch 8/185 loss = 0.0843\n",
      "epoch 5 batch 9/185 loss = 0.0817\n",
      "epoch 5 batch 10/185 loss = 0.0867\n",
      "epoch 5 batch 11/185 loss = 0.0761\n",
      "epoch 5 batch 12/185 loss = 0.0845\n",
      "epoch 5 batch 13/185 loss = 0.0828\n",
      "epoch 5 batch 14/185 loss = 0.0811\n",
      "epoch 5 batch 15/185 loss = 0.0833\n",
      "epoch 5 batch 16/185 loss = 0.0780\n",
      "epoch 5 batch 17/185 loss = 0.0860\n",
      "epoch 5 batch 18/185 loss = 0.0751\n",
      "epoch 5 batch 19/185 loss = 0.0806\n",
      "epoch 5 batch 20/185 loss = 0.0840\n",
      "epoch 5 batch 21/185 loss = 0.0775\n",
      "epoch 5 batch 22/185 loss = 0.0812\n",
      "epoch 5 batch 23/185 loss = 0.0807\n",
      "epoch 5 batch 24/185 loss = 0.0838\n",
      "epoch 5 batch 25/185 loss = 0.0818\n",
      "epoch 5 batch 26/185 loss = 0.0823\n",
      "epoch 5 batch 27/185 loss = 0.0759\n",
      "epoch 5 batch 28/185 loss = 0.0754\n",
      "epoch 5 batch 29/185 loss = 0.0735\n",
      "epoch 5 batch 30/185 loss = 0.0725\n",
      "epoch 5 batch 31/185 loss = 0.0724\n",
      "epoch 5 batch 32/185 loss = 0.0793\n",
      "epoch 5 batch 33/185 loss = 0.0813\n",
      "epoch 5 batch 34/185 loss = 0.0780\n",
      "epoch 5 batch 35/185 loss = 0.0722\n",
      "epoch 5 batch 36/185 loss = 0.0710\n",
      "epoch 5 batch 37/185 loss = 0.0706\n",
      "epoch 5 batch 38/185 loss = 0.0709\n",
      "epoch 5 batch 39/185 loss = 0.0722\n",
      "epoch 5 batch 40/185 loss = 0.0760\n",
      "epoch 5 batch 41/185 loss = 0.0754\n",
      "epoch 5 batch 42/185 loss = 0.0784\n",
      "epoch 5 batch 43/185 loss = 0.0776\n",
      "epoch 5 batch 44/185 loss = 0.0717\n",
      "epoch 5 batch 45/185 loss = 0.0753\n",
      "epoch 5 batch 46/185 loss = 0.0690\n",
      "epoch 5 batch 47/185 loss = 0.0740\n",
      "epoch 5 batch 48/185 loss = 0.0706\n",
      "epoch 5 batch 49/185 loss = 0.0685\n",
      "epoch 5 batch 50/185 loss = 0.0639\n",
      "epoch 5 batch 51/185 loss = 0.0815\n",
      "epoch 5 batch 52/185 loss = 0.0680\n",
      "epoch 5 batch 53/185 loss = 0.0713\n",
      "epoch 5 batch 54/185 loss = 0.0610\n",
      "epoch 5 batch 55/185 loss = 0.0589\n",
      "epoch 5 batch 56/185 loss = 0.0646\n",
      "epoch 5 batch 57/185 loss = 0.0680\n",
      "epoch 5 batch 58/185 loss = 0.0678\n",
      "epoch 5 batch 59/185 loss = 0.0717\n",
      "epoch 5 batch 60/185 loss = 0.0672\n",
      "epoch 5 batch 61/185 loss = 0.0707\n",
      "epoch 5 batch 62/185 loss = 0.0600\n",
      "epoch 5 batch 63/185 loss = 0.0720\n",
      "epoch 5 batch 64/185 loss = 0.0706\n",
      "epoch 5 batch 65/185 loss = 0.0633\n",
      "epoch 5 batch 66/185 loss = 0.0617\n",
      "epoch 5 batch 67/185 loss = 0.0674\n",
      "epoch 5 batch 68/185 loss = 0.0648\n",
      "epoch 5 batch 69/185 loss = 0.0677\n",
      "epoch 5 batch 70/185 loss = 0.0596\n",
      "epoch 5 batch 71/185 loss = 0.0632\n",
      "epoch 5 batch 72/185 loss = 0.0643\n",
      "epoch 5 batch 73/185 loss = 0.0665\n",
      "epoch 5 batch 74/185 loss = 0.0649\n",
      "epoch 5 batch 75/185 loss = 0.0615\n",
      "epoch 5 batch 76/185 loss = 0.0575\n",
      "epoch 5 batch 77/185 loss = 0.0626\n",
      "epoch 5 batch 78/185 loss = 0.0634\n",
      "epoch 5 batch 79/185 loss = 0.0657\n",
      "epoch 5 batch 80/185 loss = 0.0633\n",
      "epoch 5 batch 81/185 loss = 0.0645\n",
      "epoch 5 batch 82/185 loss = 0.0610\n",
      "epoch 5 batch 83/185 loss = 0.0599\n",
      "epoch 5 batch 84/185 loss = 0.0648\n",
      "epoch 5 batch 85/185 loss = 0.0636\n",
      "epoch 5 batch 86/185 loss = 0.0658\n",
      "epoch 5 batch 87/185 loss = 0.0593\n",
      "epoch 5 batch 88/185 loss = 0.0611\n",
      "epoch 5 batch 89/185 loss = 0.0593\n",
      "epoch 5 batch 90/185 loss = 0.0620\n",
      "epoch 5 batch 91/185 loss = 0.0602\n",
      "epoch 5 batch 92/185 loss = 0.0621\n",
      "epoch 5 batch 93/185 loss = 0.0661\n",
      "epoch 5 batch 94/185 loss = 0.0633\n",
      "epoch 5 batch 95/185 loss = 0.0545\n",
      "epoch 5 batch 96/185 loss = 0.0581\n",
      "epoch 5 batch 97/185 loss = 0.0578\n",
      "epoch 5 batch 98/185 loss = 0.0661\n",
      "epoch 5 batch 99/185 loss = 0.0572\n",
      "epoch 5 batch 100/185 loss = 0.0603\n",
      "epoch 5 batch 101/185 loss = 0.0601\n",
      "epoch 5 batch 102/185 loss = 0.0583\n",
      "epoch 5 batch 103/185 loss = 0.0653\n",
      "epoch 5 batch 104/185 loss = 0.0585\n",
      "epoch 5 batch 105/185 loss = 0.0622\n",
      "epoch 5 batch 106/185 loss = 0.0566\n",
      "epoch 5 batch 107/185 loss = 0.0564\n",
      "epoch 5 batch 108/185 loss = 0.0571\n",
      "epoch 5 batch 109/185 loss = 0.0646\n",
      "epoch 5 batch 110/185 loss = 0.0579\n",
      "epoch 5 batch 111/185 loss = 0.0604\n",
      "epoch 5 batch 112/185 loss = 0.0540\n",
      "epoch 5 batch 113/185 loss = 0.0614\n",
      "epoch 5 batch 114/185 loss = 0.0503\n",
      "epoch 5 batch 115/185 loss = 0.0725\n",
      "epoch 5 batch 116/185 loss = 0.0578\n",
      "epoch 5 batch 117/185 loss = 0.0539\n",
      "epoch 5 batch 118/185 loss = 0.0499\n",
      "epoch 5 batch 119/185 loss = 0.0525\n",
      "epoch 5 batch 120/185 loss = 0.0574\n",
      "epoch 5 batch 121/185 loss = 0.0596\n",
      "epoch 5 batch 122/185 loss = 0.0542\n",
      "epoch 5 batch 123/185 loss = 0.0564\n",
      "epoch 5 batch 124/185 loss = 0.0570\n",
      "epoch 5 batch 125/185 loss = 0.0572\n",
      "epoch 5 batch 126/185 loss = 0.0512\n",
      "epoch 5 batch 127/185 loss = 0.0536\n",
      "epoch 5 batch 128/185 loss = 0.0527\n",
      "epoch 5 batch 129/185 loss = 0.0493\n",
      "epoch 5 batch 130/185 loss = 0.0555\n",
      "epoch 5 batch 131/185 loss = 0.0528\n",
      "epoch 5 batch 132/185 loss = 0.0562\n",
      "epoch 5 batch 133/185 loss = 0.0619\n",
      "epoch 5 batch 134/185 loss = 0.0538\n",
      "epoch 5 batch 135/185 loss = 0.0488\n",
      "epoch 5 batch 136/185 loss = 0.0507\n",
      "epoch 5 batch 137/185 loss = 0.0546\n",
      "epoch 5 batch 138/185 loss = 0.0554\n",
      "epoch 5 batch 139/185 loss = 0.0523\n",
      "epoch 5 batch 140/185 loss = 0.0475\n",
      "epoch 5 batch 141/185 loss = 0.0577\n",
      "epoch 5 batch 142/185 loss = 0.0512\n",
      "epoch 5 batch 143/185 loss = 0.0485\n",
      "epoch 5 batch 144/185 loss = 0.0531\n",
      "epoch 5 batch 145/185 loss = 0.0495\n",
      "epoch 5 batch 146/185 loss = 0.0465\n",
      "epoch 5 batch 147/185 loss = 0.0466\n",
      "epoch 5 batch 148/185 loss = 0.0583\n",
      "epoch 5 batch 149/185 loss = 0.0547\n",
      "epoch 5 batch 150/185 loss = 0.0471\n",
      "epoch 5 batch 151/185 loss = 0.0529\n",
      "epoch 5 batch 152/185 loss = 0.0530\n",
      "epoch 5 batch 153/185 loss = 0.0505\n",
      "epoch 5 batch 154/185 loss = 0.0553\n",
      "epoch 5 batch 155/185 loss = 0.0581\n",
      "epoch 5 batch 156/185 loss = 0.0499\n",
      "epoch 5 batch 157/185 loss = 0.0472\n",
      "epoch 5 batch 158/185 loss = 0.0533\n",
      "epoch 5 batch 159/185 loss = 0.0534\n",
      "epoch 5 batch 160/185 loss = 0.0512\n",
      "epoch 5 batch 161/185 loss = 0.0497\n",
      "epoch 5 batch 162/185 loss = 0.0489\n",
      "epoch 5 batch 163/185 loss = 0.0501\n",
      "epoch 5 batch 164/185 loss = 0.0525\n",
      "epoch 5 batch 165/185 loss = 0.0486\n",
      "epoch 5 batch 166/185 loss = 0.0445\n",
      "epoch 5 batch 167/185 loss = 0.0460\n",
      "epoch 5 batch 168/185 loss = 0.0453\n",
      "epoch 5 batch 169/185 loss = 0.0473\n",
      "epoch 5 batch 170/185 loss = 0.0452\n",
      "epoch 5 batch 171/185 loss = 0.0509\n",
      "epoch 5 batch 172/185 loss = 0.0501\n",
      "epoch 5 batch 173/185 loss = 0.0429\n",
      "epoch 5 batch 174/185 loss = 0.0447\n",
      "epoch 5 batch 175/185 loss = 0.0452\n",
      "epoch 5 batch 176/185 loss = 0.0455\n",
      "epoch 5 batch 177/185 loss = 0.0424\n",
      "epoch 5 batch 178/185 loss = 0.0480\n",
      "epoch 5 batch 179/185 loss = 0.0497\n",
      "epoch 5 batch 180/185 loss = 0.0421\n",
      "epoch 5 batch 181/185 loss = 0.0445\n",
      "epoch 5 batch 182/185 loss = 0.0425\n",
      "epoch 5 batch 183/185 loss = 0.0421\n",
      "epoch 5 batch 184/185 loss = 0.0433\n",
      "epoch 5 batch 185/185 loss = 0.0449\n",
      "epoch 5 train loss = 0.0625 valid loss = 0.0531\n",
      "epoch 6 batch 1/185 loss = 0.0444\n",
      "epoch 6 batch 2/185 loss = 0.0435\n",
      "epoch 6 batch 3/185 loss = 0.0450\n",
      "epoch 6 batch 4/185 loss = 0.0489\n",
      "epoch 6 batch 5/185 loss = 0.0437\n",
      "epoch 6 batch 6/185 loss = 0.0449\n",
      "epoch 6 batch 7/185 loss = 0.0455\n",
      "epoch 6 batch 8/185 loss = 0.0494\n",
      "epoch 6 batch 9/185 loss = 0.0427\n",
      "epoch 6 batch 10/185 loss = 0.0404\n",
      "epoch 6 batch 11/185 loss = 0.0434\n",
      "epoch 6 batch 12/185 loss = 0.0368\n",
      "epoch 6 batch 13/185 loss = 0.0456\n",
      "epoch 6 batch 14/185 loss = 0.0450\n",
      "epoch 6 batch 15/185 loss = 0.0414\n",
      "epoch 6 batch 16/185 loss = 0.0495\n",
      "epoch 6 batch 17/185 loss = 0.0428\n",
      "epoch 6 batch 18/185 loss = 0.0428\n",
      "epoch 6 batch 19/185 loss = 0.0435\n",
      "epoch 6 batch 20/185 loss = 0.0454\n",
      "epoch 6 batch 21/185 loss = 0.0490\n",
      "epoch 6 batch 22/185 loss = 0.0421\n",
      "epoch 6 batch 23/185 loss = 0.0431\n",
      "epoch 6 batch 24/185 loss = 0.0361\n",
      "epoch 6 batch 25/185 loss = 0.0392\n",
      "epoch 6 batch 26/185 loss = 0.0408\n",
      "epoch 6 batch 27/185 loss = 0.0395\n",
      "epoch 6 batch 28/185 loss = 0.0450\n",
      "epoch 6 batch 29/185 loss = 0.0403\n",
      "epoch 6 batch 30/185 loss = 0.0397\n",
      "epoch 6 batch 31/185 loss = 0.0360\n",
      "epoch 6 batch 32/185 loss = 0.0429\n",
      "epoch 6 batch 33/185 loss = 0.0445\n",
      "epoch 6 batch 34/185 loss = 0.0363\n",
      "epoch 6 batch 35/185 loss = 0.0385\n",
      "epoch 6 batch 36/185 loss = 0.0400\n",
      "epoch 6 batch 37/185 loss = 0.0376\n",
      "epoch 6 batch 38/185 loss = 0.0381\n",
      "epoch 6 batch 39/185 loss = 0.0414\n",
      "epoch 6 batch 40/185 loss = 0.0397\n",
      "epoch 6 batch 41/185 loss = 0.0378\n",
      "epoch 6 batch 42/185 loss = 0.0401\n",
      "epoch 6 batch 43/185 loss = 0.0422\n",
      "epoch 6 batch 44/185 loss = 0.0422\n",
      "epoch 6 batch 45/185 loss = 0.0410\n",
      "epoch 6 batch 46/185 loss = 0.0432\n",
      "epoch 6 batch 47/185 loss = 0.0383\n",
      "epoch 6 batch 48/185 loss = 0.0396\n",
      "epoch 6 batch 49/185 loss = 0.0371\n",
      "epoch 6 batch 50/185 loss = 0.0435\n",
      "epoch 6 batch 51/185 loss = 0.0354\n",
      "epoch 6 batch 52/185 loss = 0.0411\n",
      "epoch 6 batch 53/185 loss = 0.0352\n",
      "epoch 6 batch 54/185 loss = 0.0399\n",
      "epoch 6 batch 55/185 loss = 0.0406\n",
      "epoch 6 batch 56/185 loss = 0.0398\n",
      "epoch 6 batch 57/185 loss = 0.0330\n",
      "epoch 6 batch 58/185 loss = 0.0380\n",
      "epoch 6 batch 59/185 loss = 0.0377\n",
      "epoch 6 batch 60/185 loss = 0.0390\n",
      "epoch 6 batch 61/185 loss = 0.0374\n",
      "epoch 6 batch 62/185 loss = 0.0373\n",
      "epoch 6 batch 63/185 loss = 0.0401\n",
      "epoch 6 batch 64/185 loss = 0.0370\n",
      "epoch 6 batch 65/185 loss = 0.0393\n",
      "epoch 6 batch 66/185 loss = 0.0343\n",
      "epoch 6 batch 67/185 loss = 0.0379\n",
      "epoch 6 batch 68/185 loss = 0.0388\n",
      "epoch 6 batch 69/185 loss = 0.0347\n",
      "epoch 6 batch 70/185 loss = 0.0369\n",
      "epoch 6 batch 71/185 loss = 0.0356\n",
      "epoch 6 batch 72/185 loss = 0.0373\n",
      "epoch 6 batch 73/185 loss = 0.0353\n",
      "epoch 6 batch 74/185 loss = 0.0365\n",
      "epoch 6 batch 75/185 loss = 0.0340\n",
      "epoch 6 batch 76/185 loss = 0.0322\n",
      "epoch 6 batch 77/185 loss = 0.0349\n",
      "epoch 6 batch 78/185 loss = 0.0318\n",
      "epoch 6 batch 79/185 loss = 0.0381\n",
      "epoch 6 batch 80/185 loss = 0.0389\n",
      "epoch 6 batch 81/185 loss = 0.0318\n",
      "epoch 6 batch 82/185 loss = 0.0385\n",
      "epoch 6 batch 83/185 loss = 0.0324\n",
      "epoch 6 batch 84/185 loss = 0.0332\n",
      "epoch 6 batch 85/185 loss = 0.0333\n",
      "epoch 6 batch 86/185 loss = 0.0330\n",
      "epoch 6 batch 87/185 loss = 0.0374\n",
      "epoch 6 batch 88/185 loss = 0.0314\n",
      "epoch 6 batch 89/185 loss = 0.0340\n",
      "epoch 6 batch 90/185 loss = 0.0357\n",
      "epoch 6 batch 91/185 loss = 0.0325\n",
      "epoch 6 batch 92/185 loss = 0.0383\n",
      "epoch 6 batch 93/185 loss = 0.0366\n",
      "epoch 6 batch 94/185 loss = 0.0289\n",
      "epoch 6 batch 95/185 loss = 0.0328\n",
      "epoch 6 batch 96/185 loss = 0.0283\n",
      "epoch 6 batch 97/185 loss = 0.0370\n",
      "epoch 6 batch 98/185 loss = 0.0366\n",
      "epoch 6 batch 99/185 loss = 0.0366\n",
      "epoch 6 batch 100/185 loss = 0.0304\n",
      "epoch 6 batch 101/185 loss = 0.0362\n",
      "epoch 6 batch 102/185 loss = 0.0305\n",
      "epoch 6 batch 103/185 loss = 0.0291\n",
      "epoch 6 batch 104/185 loss = 0.0329\n",
      "epoch 6 batch 105/185 loss = 0.0313\n",
      "epoch 6 batch 106/185 loss = 0.0299\n",
      "epoch 6 batch 107/185 loss = 0.0360\n",
      "epoch 6 batch 108/185 loss = 0.0308\n",
      "epoch 6 batch 109/185 loss = 0.0291\n",
      "epoch 6 batch 110/185 loss = 0.0298\n",
      "epoch 6 batch 111/185 loss = 0.0317\n",
      "epoch 6 batch 112/185 loss = 0.0314\n",
      "epoch 6 batch 113/185 loss = 0.0305\n",
      "epoch 6 batch 114/185 loss = 0.0338\n",
      "epoch 6 batch 115/185 loss = 0.0308\n",
      "epoch 6 batch 116/185 loss = 0.0299\n",
      "epoch 6 batch 117/185 loss = 0.0357\n",
      "epoch 6 batch 118/185 loss = 0.0322\n",
      "epoch 6 batch 119/185 loss = 0.0341\n",
      "epoch 6 batch 120/185 loss = 0.0324\n",
      "epoch 6 batch 121/185 loss = 0.0315\n",
      "epoch 6 batch 122/185 loss = 0.0311\n",
      "epoch 6 batch 123/185 loss = 0.0332\n",
      "epoch 6 batch 124/185 loss = 0.0318\n",
      "epoch 6 batch 125/185 loss = 0.0313\n",
      "epoch 6 batch 126/185 loss = 0.0306\n",
      "epoch 6 batch 127/185 loss = 0.0272\n",
      "epoch 6 batch 128/185 loss = 0.0281\n",
      "epoch 6 batch 129/185 loss = 0.0303\n",
      "epoch 6 batch 130/185 loss = 0.0288\n",
      "epoch 6 batch 131/185 loss = 0.0306\n",
      "epoch 6 batch 132/185 loss = 0.0314\n",
      "epoch 6 batch 133/185 loss = 0.0263\n",
      "epoch 6 batch 134/185 loss = 0.0337\n",
      "epoch 6 batch 135/185 loss = 0.0324\n",
      "epoch 6 batch 136/185 loss = 0.0293\n",
      "epoch 6 batch 137/185 loss = 0.0312\n",
      "epoch 6 batch 138/185 loss = 0.0266\n",
      "epoch 6 batch 139/185 loss = 0.0313\n",
      "epoch 6 batch 140/185 loss = 0.0318\n",
      "epoch 6 batch 141/185 loss = 0.0314\n",
      "epoch 6 batch 142/185 loss = 0.0280\n",
      "epoch 6 batch 143/185 loss = 0.0316\n",
      "epoch 6 batch 144/185 loss = 0.0304\n",
      "epoch 6 batch 145/185 loss = 0.0357\n",
      "epoch 6 batch 146/185 loss = 0.0299\n",
      "epoch 6 batch 147/185 loss = 0.0247\n",
      "epoch 6 batch 148/185 loss = 0.0259\n",
      "epoch 6 batch 149/185 loss = 0.0332\n",
      "epoch 6 batch 150/185 loss = 0.0305\n",
      "epoch 6 batch 151/185 loss = 0.0324\n",
      "epoch 6 batch 152/185 loss = 0.0262\n",
      "epoch 6 batch 153/185 loss = 0.0309\n",
      "epoch 6 batch 154/185 loss = 0.0289\n",
      "epoch 6 batch 155/185 loss = 0.0285\n",
      "epoch 6 batch 156/185 loss = 0.0277\n",
      "epoch 6 batch 157/185 loss = 0.0246\n",
      "epoch 6 batch 158/185 loss = 0.0314\n",
      "epoch 6 batch 159/185 loss = 0.0252\n",
      "epoch 6 batch 160/185 loss = 0.0279\n",
      "epoch 6 batch 161/185 loss = 0.0265\n",
      "epoch 6 batch 162/185 loss = 0.0261\n",
      "epoch 6 batch 163/185 loss = 0.0303\n",
      "epoch 6 batch 164/185 loss = 0.0270\n",
      "epoch 6 batch 165/185 loss = 0.0252\n",
      "epoch 6 batch 166/185 loss = 0.0272\n",
      "epoch 6 batch 167/185 loss = 0.0287\n",
      "epoch 6 batch 168/185 loss = 0.0271\n",
      "epoch 6 batch 169/185 loss = 0.0297\n",
      "epoch 6 batch 170/185 loss = 0.0296\n",
      "epoch 6 batch 171/185 loss = 0.0295\n",
      "epoch 6 batch 172/185 loss = 0.0260\n",
      "epoch 6 batch 173/185 loss = 0.0242\n",
      "epoch 6 batch 174/185 loss = 0.0212\n",
      "epoch 6 batch 175/185 loss = 0.0243\n",
      "epoch 6 batch 176/185 loss = 0.0304\n",
      "epoch 6 batch 177/185 loss = 0.0218\n",
      "epoch 6 batch 178/185 loss = 0.0294\n",
      "epoch 6 batch 179/185 loss = 0.0267\n",
      "epoch 6 batch 180/185 loss = 0.0265\n",
      "epoch 6 batch 181/185 loss = 0.0281\n",
      "epoch 6 batch 182/185 loss = 0.0290\n",
      "epoch 6 batch 183/185 loss = 0.0231\n",
      "epoch 6 batch 184/185 loss = 0.0324\n",
      "epoch 6 batch 185/185 loss = 0.0306\n",
      "epoch 6 train loss = 0.0346 valid loss = 0.0308\n",
      "epoch 7 batch 1/185 loss = 0.0208\n",
      "epoch 7 batch 2/185 loss = 0.0227\n",
      "epoch 7 batch 3/185 loss = 0.0279\n",
      "epoch 7 batch 4/185 loss = 0.0269\n",
      "epoch 7 batch 5/185 loss = 0.0293\n",
      "epoch 7 batch 6/185 loss = 0.0288\n",
      "epoch 7 batch 7/185 loss = 0.0204\n",
      "epoch 7 batch 8/185 loss = 0.0281\n",
      "epoch 7 batch 9/185 loss = 0.0276\n",
      "epoch 7 batch 10/185 loss = 0.0251\n",
      "epoch 7 batch 11/185 loss = 0.0230\n",
      "epoch 7 batch 12/185 loss = 0.0244\n",
      "epoch 7 batch 13/185 loss = 0.0243\n",
      "epoch 7 batch 14/185 loss = 0.0256\n",
      "epoch 7 batch 15/185 loss = 0.0253\n",
      "epoch 7 batch 16/185 loss = 0.0260\n",
      "epoch 7 batch 17/185 loss = 0.0282\n",
      "epoch 7 batch 18/185 loss = 0.0254\n",
      "epoch 7 batch 19/185 loss = 0.0232\n",
      "epoch 7 batch 20/185 loss = 0.0266\n",
      "epoch 7 batch 21/185 loss = 0.0240\n",
      "epoch 7 batch 22/185 loss = 0.0229\n",
      "epoch 7 batch 23/185 loss = 0.0236\n",
      "epoch 7 batch 24/185 loss = 0.0227\n",
      "epoch 7 batch 25/185 loss = 0.0237\n",
      "epoch 7 batch 26/185 loss = 0.0234\n",
      "epoch 7 batch 27/185 loss = 0.0241\n",
      "epoch 7 batch 28/185 loss = 0.0217\n",
      "epoch 7 batch 29/185 loss = 0.0212\n",
      "epoch 7 batch 30/185 loss = 0.0215\n",
      "epoch 7 batch 31/185 loss = 0.0260\n",
      "epoch 7 batch 32/185 loss = 0.0253\n",
      "epoch 7 batch 33/185 loss = 0.0244\n",
      "epoch 7 batch 34/185 loss = 0.0198\n",
      "epoch 7 batch 35/185 loss = 0.0229\n",
      "epoch 7 batch 36/185 loss = 0.0209\n",
      "epoch 7 batch 37/185 loss = 0.0228\n",
      "epoch 7 batch 38/185 loss = 0.0233\n",
      "epoch 7 batch 39/185 loss = 0.0210\n",
      "epoch 7 batch 40/185 loss = 0.0220\n",
      "epoch 7 batch 41/185 loss = 0.0268\n",
      "epoch 7 batch 42/185 loss = 0.0199\n",
      "epoch 7 batch 43/185 loss = 0.0237\n",
      "epoch 7 batch 44/185 loss = 0.0191\n",
      "epoch 7 batch 45/185 loss = 0.0242\n",
      "epoch 7 batch 46/185 loss = 0.0220\n",
      "epoch 7 batch 47/185 loss = 0.0236\n",
      "epoch 7 batch 48/185 loss = 0.0237\n",
      "epoch 7 batch 49/185 loss = 0.0224\n",
      "epoch 7 batch 50/185 loss = 0.0255\n",
      "epoch 7 batch 51/185 loss = 0.0212\n",
      "epoch 7 batch 52/185 loss = 0.0253\n",
      "epoch 7 batch 53/185 loss = 0.0235\n",
      "epoch 7 batch 54/185 loss = 0.0236\n",
      "epoch 7 batch 55/185 loss = 0.0211\n",
      "epoch 7 batch 56/185 loss = 0.0233\n",
      "epoch 7 batch 57/185 loss = 0.0197\n",
      "epoch 7 batch 58/185 loss = 0.0226\n",
      "epoch 7 batch 59/185 loss = 0.0221\n",
      "epoch 7 batch 60/185 loss = 0.0235\n",
      "epoch 7 batch 61/185 loss = 0.0200\n",
      "epoch 7 batch 62/185 loss = 0.0251\n",
      "epoch 7 batch 63/185 loss = 0.0211\n",
      "epoch 7 batch 64/185 loss = 0.0181\n",
      "epoch 7 batch 65/185 loss = 0.0266\n",
      "epoch 7 batch 66/185 loss = 0.0259\n",
      "epoch 7 batch 67/185 loss = 0.0221\n",
      "epoch 7 batch 68/185 loss = 0.0218\n",
      "epoch 7 batch 69/185 loss = 0.0220\n",
      "epoch 7 batch 70/185 loss = 0.0255\n",
      "epoch 7 batch 71/185 loss = 0.0218\n",
      "epoch 7 batch 72/185 loss = 0.0220\n",
      "epoch 7 batch 73/185 loss = 0.0194\n",
      "epoch 7 batch 74/185 loss = 0.0172\n",
      "epoch 7 batch 75/185 loss = 0.0230\n",
      "epoch 7 batch 76/185 loss = 0.0178\n",
      "epoch 7 batch 77/185 loss = 0.0232\n",
      "epoch 7 batch 78/185 loss = 0.0207\n",
      "epoch 7 batch 79/185 loss = 0.0193\n",
      "epoch 7 batch 80/185 loss = 0.0247\n",
      "epoch 7 batch 81/185 loss = 0.0220\n",
      "epoch 7 batch 82/185 loss = 0.0178\n",
      "epoch 7 batch 83/185 loss = 0.0275\n",
      "epoch 7 batch 84/185 loss = 0.0231\n",
      "epoch 7 batch 85/185 loss = 0.0203\n",
      "epoch 7 batch 86/185 loss = 0.0179\n",
      "epoch 7 batch 87/185 loss = 0.0187\n",
      "epoch 7 batch 88/185 loss = 0.0185\n",
      "epoch 7 batch 89/185 loss = 0.0192\n",
      "epoch 7 batch 90/185 loss = 0.0196\n",
      "epoch 7 batch 91/185 loss = 0.0219\n",
      "epoch 7 batch 92/185 loss = 0.0179\n",
      "epoch 7 batch 93/185 loss = 0.0249\n",
      "epoch 7 batch 94/185 loss = 0.0197\n",
      "epoch 7 batch 95/185 loss = 0.0197\n",
      "epoch 7 batch 96/185 loss = 0.0198\n",
      "epoch 7 batch 97/185 loss = 0.0218\n",
      "epoch 7 batch 98/185 loss = 0.0217\n",
      "epoch 7 batch 99/185 loss = 0.0241\n",
      "epoch 7 batch 100/185 loss = 0.0185\n",
      "epoch 7 batch 101/185 loss = 0.0211\n",
      "epoch 7 batch 102/185 loss = 0.0246\n",
      "epoch 7 batch 103/185 loss = 0.0220\n",
      "epoch 7 batch 104/185 loss = 0.0234\n",
      "epoch 7 batch 105/185 loss = 0.0189\n",
      "epoch 7 batch 106/185 loss = 0.0200\n",
      "epoch 7 batch 107/185 loss = 0.0193\n",
      "epoch 7 batch 108/185 loss = 0.0202\n",
      "epoch 7 batch 109/185 loss = 0.0230\n",
      "epoch 7 batch 110/185 loss = 0.0217\n",
      "epoch 7 batch 111/185 loss = 0.0215\n",
      "epoch 7 batch 112/185 loss = 0.0192\n",
      "epoch 7 batch 113/185 loss = 0.0191\n",
      "epoch 7 batch 114/185 loss = 0.0170\n",
      "epoch 7 batch 115/185 loss = 0.0157\n",
      "epoch 7 batch 116/185 loss = 0.0160\n",
      "epoch 7 batch 117/185 loss = 0.0249\n",
      "epoch 7 batch 118/185 loss = 0.0190\n",
      "epoch 7 batch 119/185 loss = 0.0239\n",
      "epoch 7 batch 120/185 loss = 0.0195\n",
      "epoch 7 batch 121/185 loss = 0.0173\n",
      "epoch 7 batch 122/185 loss = 0.0201\n",
      "epoch 7 batch 123/185 loss = 0.0175\n",
      "epoch 7 batch 124/185 loss = 0.0181\n",
      "epoch 7 batch 125/185 loss = 0.0222\n",
      "epoch 7 batch 126/185 loss = 0.0193\n",
      "epoch 7 batch 127/185 loss = 0.0172\n",
      "epoch 7 batch 128/185 loss = 0.0213\n",
      "epoch 7 batch 129/185 loss = 0.0193\n",
      "epoch 7 batch 130/185 loss = 0.0207\n",
      "epoch 7 batch 131/185 loss = 0.0205\n",
      "epoch 7 batch 132/185 loss = 0.0177\n",
      "epoch 7 batch 133/185 loss = 0.0226\n",
      "epoch 7 batch 134/185 loss = 0.0240\n",
      "epoch 7 batch 135/185 loss = 0.0185\n",
      "epoch 7 batch 136/185 loss = 0.0210\n",
      "epoch 7 batch 137/185 loss = 0.0195\n",
      "epoch 7 batch 138/185 loss = 0.0153\n",
      "epoch 7 batch 139/185 loss = 0.0182\n",
      "epoch 7 batch 140/185 loss = 0.0180\n",
      "epoch 7 batch 141/185 loss = 0.0201\n",
      "epoch 7 batch 142/185 loss = 0.0226\n",
      "epoch 7 batch 143/185 loss = 0.0173\n",
      "epoch 7 batch 144/185 loss = 0.0176\n",
      "epoch 7 batch 145/185 loss = 0.0193\n",
      "epoch 7 batch 146/185 loss = 0.0200\n",
      "epoch 7 batch 147/185 loss = 0.0200\n",
      "epoch 7 batch 148/185 loss = 0.0184\n",
      "epoch 7 batch 149/185 loss = 0.0176\n",
      "epoch 7 batch 150/185 loss = 0.0190\n",
      "epoch 7 batch 151/185 loss = 0.0163\n",
      "epoch 7 batch 152/185 loss = 0.0176\n",
      "epoch 7 batch 153/185 loss = 0.0188\n",
      "epoch 7 batch 154/185 loss = 0.0211\n",
      "epoch 7 batch 155/185 loss = 0.0194\n",
      "epoch 7 batch 156/185 loss = 0.0152\n",
      "epoch 7 batch 157/185 loss = 0.0144\n",
      "epoch 7 batch 158/185 loss = 0.0164\n",
      "epoch 7 batch 159/185 loss = 0.0186\n",
      "epoch 7 batch 160/185 loss = 0.0203\n",
      "epoch 7 batch 161/185 loss = 0.0258\n",
      "epoch 7 batch 162/185 loss = 0.0220\n",
      "epoch 7 batch 163/185 loss = 0.0172\n",
      "epoch 7 batch 164/185 loss = 0.0188\n",
      "epoch 7 batch 165/185 loss = 0.0175\n",
      "epoch 7 batch 166/185 loss = 0.0164\n",
      "epoch 7 batch 167/185 loss = 0.0166\n",
      "epoch 7 batch 168/185 loss = 0.0188\n",
      "epoch 7 batch 169/185 loss = 0.0176\n",
      "epoch 7 batch 170/185 loss = 0.0197\n",
      "epoch 7 batch 171/185 loss = 0.0169\n",
      "epoch 7 batch 172/185 loss = 0.0189\n",
      "epoch 7 batch 173/185 loss = 0.0177\n",
      "epoch 7 batch 174/185 loss = 0.0198\n",
      "epoch 7 batch 175/185 loss = 0.0173\n",
      "epoch 7 batch 176/185 loss = 0.0182\n",
      "epoch 7 batch 177/185 loss = 0.0173\n",
      "epoch 7 batch 178/185 loss = 0.0173\n",
      "epoch 7 batch 179/185 loss = 0.0184\n",
      "epoch 7 batch 180/185 loss = 0.0188\n",
      "epoch 7 batch 181/185 loss = 0.0137\n",
      "epoch 7 batch 182/185 loss = 0.0168\n",
      "epoch 7 batch 183/185 loss = 0.0172\n",
      "epoch 7 batch 184/185 loss = 0.0172\n",
      "epoch 7 batch 185/185 loss = 0.0153\n",
      "epoch 7 train loss = 0.0211 valid loss = 0.0250\n",
      "epoch 8 batch 1/185 loss = 0.0200\n",
      "epoch 8 batch 2/185 loss = 0.0158\n",
      "epoch 8 batch 3/185 loss = 0.0195\n",
      "epoch 8 batch 4/185 loss = 0.0186\n",
      "epoch 8 batch 5/185 loss = 0.0186\n",
      "epoch 8 batch 6/185 loss = 0.0152\n",
      "epoch 8 batch 7/185 loss = 0.0168\n",
      "epoch 8 batch 8/185 loss = 0.0148\n",
      "epoch 8 batch 9/185 loss = 0.0172\n",
      "epoch 8 batch 10/185 loss = 0.0174\n",
      "epoch 8 batch 11/185 loss = 0.0147\n",
      "epoch 8 batch 12/185 loss = 0.0170\n",
      "epoch 8 batch 13/185 loss = 0.0144\n",
      "epoch 8 batch 14/185 loss = 0.0152\n",
      "epoch 8 batch 15/185 loss = 0.0152\n",
      "epoch 8 batch 16/185 loss = 0.0176\n",
      "epoch 8 batch 17/185 loss = 0.0171\n",
      "epoch 8 batch 18/185 loss = 0.0202\n",
      "epoch 8 batch 19/185 loss = 0.0172\n",
      "epoch 8 batch 20/185 loss = 0.0182\n",
      "epoch 8 batch 21/185 loss = 0.0173\n",
      "epoch 8 batch 22/185 loss = 0.0176\n",
      "epoch 8 batch 23/185 loss = 0.0193\n",
      "epoch 8 batch 24/185 loss = 0.0173\n",
      "epoch 8 batch 25/185 loss = 0.0182\n",
      "epoch 8 batch 26/185 loss = 0.0179\n",
      "epoch 8 batch 27/185 loss = 0.0160\n",
      "epoch 8 batch 28/185 loss = 0.0196\n",
      "epoch 8 batch 29/185 loss = 0.0185\n",
      "epoch 8 batch 30/185 loss = 0.0177\n",
      "epoch 8 batch 31/185 loss = 0.0165\n",
      "epoch 8 batch 32/185 loss = 0.0143\n",
      "epoch 8 batch 33/185 loss = 0.0188\n",
      "epoch 8 batch 34/185 loss = 0.0146\n",
      "epoch 8 batch 35/185 loss = 0.0161\n",
      "epoch 8 batch 36/185 loss = 0.0158\n",
      "epoch 8 batch 37/185 loss = 0.0181\n",
      "epoch 8 batch 38/185 loss = 0.0171\n",
      "epoch 8 batch 39/185 loss = 0.0200\n",
      "epoch 8 batch 40/185 loss = 0.0132\n",
      "epoch 8 batch 41/185 loss = 0.0147\n",
      "epoch 8 batch 42/185 loss = 0.0132\n",
      "epoch 8 batch 43/185 loss = 0.0187\n",
      "epoch 8 batch 44/185 loss = 0.0181\n",
      "epoch 8 batch 45/185 loss = 0.0133\n",
      "epoch 8 batch 46/185 loss = 0.0165\n",
      "epoch 8 batch 47/185 loss = 0.0171\n",
      "epoch 8 batch 48/185 loss = 0.0141\n",
      "epoch 8 batch 49/185 loss = 0.0202\n",
      "epoch 8 batch 50/185 loss = 0.0196\n",
      "epoch 8 batch 51/185 loss = 0.0163\n",
      "epoch 8 batch 52/185 loss = 0.0184\n",
      "epoch 8 batch 53/185 loss = 0.0144\n",
      "epoch 8 batch 54/185 loss = 0.0177\n",
      "epoch 8 batch 55/185 loss = 0.0170\n",
      "epoch 8 batch 56/185 loss = 0.0136\n",
      "epoch 8 batch 57/185 loss = 0.0178\n",
      "epoch 8 batch 58/185 loss = 0.0150\n",
      "epoch 8 batch 59/185 loss = 0.0164\n",
      "epoch 8 batch 60/185 loss = 0.0158\n",
      "epoch 8 batch 61/185 loss = 0.0180\n",
      "epoch 8 batch 62/185 loss = 0.0200\n",
      "epoch 8 batch 63/185 loss = 0.0135\n",
      "epoch 8 batch 64/185 loss = 0.0172\n",
      "epoch 8 batch 65/185 loss = 0.0136\n",
      "epoch 8 batch 66/185 loss = 0.0106\n",
      "epoch 8 batch 67/185 loss = 0.0145\n",
      "epoch 8 batch 68/185 loss = 0.0167\n",
      "epoch 8 batch 69/185 loss = 0.0122\n",
      "epoch 8 batch 70/185 loss = 0.0173\n",
      "epoch 8 batch 71/185 loss = 0.0126\n",
      "epoch 8 batch 72/185 loss = 0.0145\n",
      "epoch 8 batch 73/185 loss = 0.0138\n",
      "epoch 8 batch 74/185 loss = 0.0163\n",
      "epoch 8 batch 75/185 loss = 0.0160\n",
      "epoch 8 batch 76/185 loss = 0.0144\n",
      "epoch 8 batch 77/185 loss = 0.0174\n",
      "epoch 8 batch 78/185 loss = 0.0196\n",
      "epoch 8 batch 79/185 loss = 0.0130\n",
      "epoch 8 batch 80/185 loss = 0.0165\n",
      "epoch 8 batch 81/185 loss = 0.0185\n",
      "epoch 8 batch 82/185 loss = 0.0172\n",
      "epoch 8 batch 83/185 loss = 0.0139\n",
      "epoch 8 batch 84/185 loss = 0.0203\n",
      "epoch 8 batch 85/185 loss = 0.0192\n",
      "epoch 8 batch 86/185 loss = 0.0173\n",
      "epoch 8 batch 87/185 loss = 0.0148\n",
      "epoch 8 batch 88/185 loss = 0.0151\n",
      "epoch 8 batch 89/185 loss = 0.0167\n",
      "epoch 8 batch 90/185 loss = 0.0131\n",
      "epoch 8 batch 91/185 loss = 0.0146\n",
      "epoch 8 batch 92/185 loss = 0.0167\n",
      "epoch 8 batch 93/185 loss = 0.0139\n",
      "epoch 8 batch 94/185 loss = 0.0150\n",
      "epoch 8 batch 95/185 loss = 0.0153\n",
      "epoch 8 batch 96/185 loss = 0.0152\n",
      "epoch 8 batch 97/185 loss = 0.0146\n",
      "epoch 8 batch 98/185 loss = 0.0127\n",
      "epoch 8 batch 99/185 loss = 0.0170\n",
      "epoch 8 batch 100/185 loss = 0.0170\n",
      "epoch 8 batch 101/185 loss = 0.0215\n",
      "epoch 8 batch 102/185 loss = 0.0123\n",
      "epoch 8 batch 103/185 loss = 0.0156\n",
      "epoch 8 batch 104/185 loss = 0.0153\n",
      "epoch 8 batch 105/185 loss = 0.0139\n",
      "epoch 8 batch 106/185 loss = 0.0166\n",
      "epoch 8 batch 107/185 loss = 0.0165\n",
      "epoch 8 batch 108/185 loss = 0.0150\n",
      "epoch 8 batch 109/185 loss = 0.0165\n",
      "epoch 8 batch 110/185 loss = 0.0158\n",
      "epoch 8 batch 111/185 loss = 0.0138\n",
      "epoch 8 batch 112/185 loss = 0.0115\n",
      "epoch 8 batch 113/185 loss = 0.0153\n",
      "epoch 8 batch 114/185 loss = 0.0160\n",
      "epoch 8 batch 115/185 loss = 0.0130\n",
      "epoch 8 batch 116/185 loss = 0.0139\n",
      "epoch 8 batch 117/185 loss = 0.0149\n",
      "epoch 8 batch 118/185 loss = 0.0154\n",
      "epoch 8 batch 119/185 loss = 0.0179\n",
      "epoch 8 batch 120/185 loss = 0.0119\n",
      "epoch 8 batch 121/185 loss = 0.0130\n",
      "epoch 8 batch 122/185 loss = 0.0152\n",
      "epoch 8 batch 123/185 loss = 0.0139\n",
      "epoch 8 batch 124/185 loss = 0.0120\n",
      "epoch 8 batch 125/185 loss = 0.0135\n",
      "epoch 8 batch 126/185 loss = 0.0175\n",
      "epoch 8 batch 127/185 loss = 0.0130\n",
      "epoch 8 batch 128/185 loss = 0.0129\n",
      "epoch 8 batch 129/185 loss = 0.0149\n",
      "epoch 8 batch 130/185 loss = 0.0134\n",
      "epoch 8 batch 131/185 loss = 0.0151\n",
      "epoch 8 batch 132/185 loss = 0.0176\n",
      "epoch 8 batch 133/185 loss = 0.0152\n",
      "epoch 8 batch 134/185 loss = 0.0159\n",
      "epoch 8 batch 135/185 loss = 0.0182\n",
      "epoch 8 batch 136/185 loss = 0.0183\n",
      "epoch 8 batch 137/185 loss = 0.0154\n",
      "epoch 8 batch 138/185 loss = 0.0137\n",
      "epoch 8 batch 139/185 loss = 0.0149\n",
      "epoch 8 batch 140/185 loss = 0.0159\n",
      "epoch 8 batch 141/185 loss = 0.0143\n",
      "epoch 8 batch 142/185 loss = 0.0133\n",
      "epoch 8 batch 143/185 loss = 0.0160\n",
      "epoch 8 batch 144/185 loss = 0.0155\n",
      "epoch 8 batch 145/185 loss = 0.0165\n",
      "epoch 8 batch 146/185 loss = 0.0172\n",
      "epoch 8 batch 147/185 loss = 0.0163\n",
      "epoch 8 batch 148/185 loss = 0.0144\n",
      "epoch 8 batch 149/185 loss = 0.0168\n",
      "epoch 8 batch 150/185 loss = 0.0114\n",
      "epoch 8 batch 151/185 loss = 0.0116\n",
      "epoch 8 batch 152/185 loss = 0.0155\n",
      "epoch 8 batch 153/185 loss = 0.0133\n",
      "epoch 8 batch 154/185 loss = 0.0148\n",
      "epoch 8 batch 155/185 loss = 0.0140\n",
      "epoch 8 batch 156/185 loss = 0.0161\n",
      "epoch 8 batch 157/185 loss = 0.0185\n",
      "epoch 8 batch 158/185 loss = 0.0140\n",
      "epoch 8 batch 159/185 loss = 0.0145\n",
      "epoch 8 batch 160/185 loss = 0.0123\n",
      "epoch 8 batch 161/185 loss = 0.0122\n",
      "epoch 8 batch 162/185 loss = 0.0131\n",
      "epoch 8 batch 163/185 loss = 0.0145\n",
      "epoch 8 batch 164/185 loss = 0.0140\n",
      "epoch 8 batch 165/185 loss = 0.0145\n",
      "epoch 8 batch 166/185 loss = 0.0157\n",
      "epoch 8 batch 167/185 loss = 0.0116\n",
      "epoch 8 batch 168/185 loss = 0.0166\n",
      "epoch 8 batch 169/185 loss = 0.0118\n",
      "epoch 8 batch 170/185 loss = 0.0135\n",
      "epoch 8 batch 171/185 loss = 0.0141\n",
      "epoch 8 batch 172/185 loss = 0.0130\n",
      "epoch 8 batch 173/185 loss = 0.0131\n",
      "epoch 8 batch 174/185 loss = 0.0142\n",
      "epoch 8 batch 175/185 loss = 0.0148\n",
      "epoch 8 batch 176/185 loss = 0.0156\n",
      "epoch 8 batch 177/185 loss = 0.0148\n",
      "epoch 8 batch 178/185 loss = 0.0150\n",
      "epoch 8 batch 179/185 loss = 0.0143\n",
      "epoch 8 batch 180/185 loss = 0.0150\n",
      "epoch 8 batch 181/185 loss = 0.0153\n",
      "epoch 8 batch 182/185 loss = 0.0157\n",
      "epoch 8 batch 183/185 loss = 0.0137\n",
      "epoch 8 batch 184/185 loss = 0.0148\n",
      "epoch 8 batch 185/185 loss = 0.0127\n",
      "epoch 8 train loss = 0.0156 valid loss = 0.0203\n",
      "epoch 9 batch 1/185 loss = 0.0158\n",
      "epoch 9 batch 2/185 loss = 0.0110\n",
      "epoch 9 batch 3/185 loss = 0.0137\n",
      "epoch 9 batch 4/185 loss = 0.0119\n",
      "epoch 9 batch 5/185 loss = 0.0131\n",
      "epoch 9 batch 6/185 loss = 0.0117\n",
      "epoch 9 batch 7/185 loss = 0.0142\n",
      "epoch 9 batch 8/185 loss = 0.0110\n",
      "epoch 9 batch 9/185 loss = 0.0127\n",
      "epoch 9 batch 10/185 loss = 0.0167\n",
      "epoch 9 batch 11/185 loss = 0.0142\n",
      "epoch 9 batch 12/185 loss = 0.0121\n",
      "epoch 9 batch 13/185 loss = 0.0141\n",
      "epoch 9 batch 14/185 loss = 0.0121\n",
      "epoch 9 batch 15/185 loss = 0.0149\n",
      "epoch 9 batch 16/185 loss = 0.0133\n",
      "epoch 9 batch 17/185 loss = 0.0140\n",
      "epoch 9 batch 18/185 loss = 0.0107\n",
      "epoch 9 batch 19/185 loss = 0.0158\n",
      "epoch 9 batch 20/185 loss = 0.0135\n",
      "epoch 9 batch 21/185 loss = 0.0121\n",
      "epoch 9 batch 22/185 loss = 0.0153\n",
      "epoch 9 batch 23/185 loss = 0.0180\n",
      "epoch 9 batch 24/185 loss = 0.0152\n",
      "epoch 9 batch 25/185 loss = 0.0150\n",
      "epoch 9 batch 26/185 loss = 0.0145\n",
      "epoch 9 batch 27/185 loss = 0.0161\n",
      "epoch 9 batch 28/185 loss = 0.0131\n",
      "epoch 9 batch 29/185 loss = 0.0147\n",
      "epoch 9 batch 30/185 loss = 0.0133\n",
      "epoch 9 batch 31/185 loss = 0.0132\n",
      "epoch 9 batch 32/185 loss = 0.0114\n",
      "epoch 9 batch 33/185 loss = 0.0149\n",
      "epoch 9 batch 34/185 loss = 0.0140\n",
      "epoch 9 batch 35/185 loss = 0.0142\n",
      "epoch 9 batch 36/185 loss = 0.0150\n",
      "epoch 9 batch 37/185 loss = 0.0131\n",
      "epoch 9 batch 38/185 loss = 0.0130\n",
      "epoch 9 batch 39/185 loss = 0.0150\n",
      "epoch 9 batch 40/185 loss = 0.0121\n",
      "epoch 9 batch 41/185 loss = 0.0135\n",
      "epoch 9 batch 42/185 loss = 0.0125\n",
      "epoch 9 batch 43/185 loss = 0.0134\n",
      "epoch 9 batch 44/185 loss = 0.0117\n",
      "epoch 9 batch 45/185 loss = 0.0153\n",
      "epoch 9 batch 46/185 loss = 0.0144\n",
      "epoch 9 batch 47/185 loss = 0.0128\n",
      "epoch 9 batch 48/185 loss = 0.0115\n",
      "epoch 9 batch 49/185 loss = 0.0163\n",
      "epoch 9 batch 50/185 loss = 0.0134\n",
      "epoch 9 batch 51/185 loss = 0.0138\n",
      "epoch 9 batch 52/185 loss = 0.0142\n",
      "epoch 9 batch 53/185 loss = 0.0142\n",
      "epoch 9 batch 54/185 loss = 0.0151\n",
      "epoch 9 batch 55/185 loss = 0.0181\n",
      "epoch 9 batch 56/185 loss = 0.0170\n",
      "epoch 9 batch 57/185 loss = 0.0146\n",
      "epoch 9 batch 58/185 loss = 0.0126\n",
      "epoch 9 batch 59/185 loss = 0.0130\n",
      "epoch 9 batch 60/185 loss = 0.0115\n",
      "epoch 9 batch 61/185 loss = 0.0147\n",
      "epoch 9 batch 62/185 loss = 0.0129\n",
      "epoch 9 batch 63/185 loss = 0.0133\n",
      "epoch 9 batch 64/185 loss = 0.0129\n",
      "epoch 9 batch 65/185 loss = 0.0163\n",
      "epoch 9 batch 66/185 loss = 0.0160\n",
      "epoch 9 batch 67/185 loss = 0.0153\n",
      "epoch 9 batch 68/185 loss = 0.0141\n",
      "epoch 9 batch 69/185 loss = 0.0160\n",
      "epoch 9 batch 70/185 loss = 0.0111\n",
      "epoch 9 batch 71/185 loss = 0.0124\n",
      "epoch 9 batch 72/185 loss = 0.0133\n",
      "epoch 9 batch 73/185 loss = 0.0112\n",
      "epoch 9 batch 74/185 loss = 0.0139\n",
      "epoch 9 batch 75/185 loss = 0.0133\n",
      "epoch 9 batch 76/185 loss = 0.0154\n",
      "epoch 9 batch 77/185 loss = 0.0126\n",
      "epoch 9 batch 78/185 loss = 0.0132\n",
      "epoch 9 batch 79/185 loss = 0.0129\n",
      "epoch 9 batch 80/185 loss = 0.0141\n",
      "epoch 9 batch 81/185 loss = 0.0127\n",
      "epoch 9 batch 82/185 loss = 0.0127\n",
      "epoch 9 batch 83/185 loss = 0.0138\n",
      "epoch 9 batch 84/185 loss = 0.0126\n",
      "epoch 9 batch 85/185 loss = 0.0142\n",
      "epoch 9 batch 86/185 loss = 0.0138\n",
      "epoch 9 batch 87/185 loss = 0.0105\n",
      "epoch 9 batch 88/185 loss = 0.0109\n",
      "epoch 9 batch 89/185 loss = 0.0127\n",
      "epoch 9 batch 90/185 loss = 0.0125\n",
      "epoch 9 batch 91/185 loss = 0.0117\n",
      "epoch 9 batch 92/185 loss = 0.0115\n",
      "epoch 9 batch 93/185 loss = 0.0126\n",
      "epoch 9 batch 94/185 loss = 0.0141\n",
      "epoch 9 batch 95/185 loss = 0.0136\n",
      "epoch 9 batch 96/185 loss = 0.0110\n",
      "epoch 9 batch 97/185 loss = 0.0138\n",
      "epoch 9 batch 98/185 loss = 0.0133\n",
      "epoch 9 batch 99/185 loss = 0.0124\n",
      "epoch 9 batch 100/185 loss = 0.0157\n",
      "epoch 9 batch 101/185 loss = 0.0161\n",
      "epoch 9 batch 102/185 loss = 0.0136\n",
      "epoch 9 batch 103/185 loss = 0.0145\n",
      "epoch 9 batch 104/185 loss = 0.0142\n",
      "epoch 9 batch 105/185 loss = 0.0114\n",
      "epoch 9 batch 106/185 loss = 0.0166\n",
      "epoch 9 batch 107/185 loss = 0.0126\n",
      "epoch 9 batch 108/185 loss = 0.0133\n",
      "epoch 9 batch 109/185 loss = 0.0140\n",
      "epoch 9 batch 110/185 loss = 0.0138\n",
      "epoch 9 batch 111/185 loss = 0.0132\n",
      "epoch 9 batch 112/185 loss = 0.0150\n",
      "epoch 9 batch 113/185 loss = 0.0128\n",
      "epoch 9 batch 114/185 loss = 0.0136\n",
      "epoch 9 batch 115/185 loss = 0.0133\n",
      "epoch 9 batch 116/185 loss = 0.0141\n",
      "epoch 9 batch 117/185 loss = 0.0171\n",
      "epoch 9 batch 118/185 loss = 0.0146\n",
      "epoch 9 batch 119/185 loss = 0.0147\n",
      "epoch 9 batch 120/185 loss = 0.0129\n",
      "epoch 9 batch 121/185 loss = 0.0122\n",
      "epoch 9 batch 122/185 loss = 0.0150\n",
      "epoch 9 batch 123/185 loss = 0.0161\n",
      "epoch 9 batch 124/185 loss = 0.0115\n",
      "epoch 9 batch 125/185 loss = 0.0124\n",
      "epoch 9 batch 126/185 loss = 0.0122\n",
      "epoch 9 batch 127/185 loss = 0.0132\n",
      "epoch 9 batch 128/185 loss = 0.0155\n",
      "epoch 9 batch 129/185 loss = 0.0173\n",
      "epoch 9 batch 130/185 loss = 0.0116\n",
      "epoch 9 batch 131/185 loss = 0.0151\n",
      "epoch 9 batch 132/185 loss = 0.0132\n",
      "epoch 9 batch 133/185 loss = 0.0128\n",
      "epoch 9 batch 134/185 loss = 0.0115\n",
      "epoch 9 batch 135/185 loss = 0.0138\n",
      "epoch 9 batch 136/185 loss = 0.0139\n",
      "epoch 9 batch 137/185 loss = 0.0142\n",
      "epoch 9 batch 138/185 loss = 0.0102\n",
      "epoch 9 batch 139/185 loss = 0.0122\n",
      "epoch 9 batch 140/185 loss = 0.0146\n",
      "epoch 9 batch 141/185 loss = 0.0127\n",
      "epoch 9 batch 142/185 loss = 0.0119\n",
      "epoch 9 batch 143/185 loss = 0.0140\n",
      "epoch 9 batch 144/185 loss = 0.0143\n",
      "epoch 9 batch 145/185 loss = 0.0098\n",
      "epoch 9 batch 146/185 loss = 0.0120\n",
      "epoch 9 batch 147/185 loss = 0.0147\n",
      "epoch 9 batch 148/185 loss = 0.0147\n",
      "epoch 9 batch 149/185 loss = 0.0140\n",
      "epoch 9 batch 150/185 loss = 0.0108\n",
      "epoch 9 batch 151/185 loss = 0.0140\n",
      "epoch 9 batch 152/185 loss = 0.0146\n",
      "epoch 9 batch 153/185 loss = 0.0139\n",
      "epoch 9 batch 154/185 loss = 0.0102\n",
      "epoch 9 batch 155/185 loss = 0.0147\n",
      "epoch 9 batch 156/185 loss = 0.0106\n",
      "epoch 9 batch 157/185 loss = 0.0115\n",
      "epoch 9 batch 158/185 loss = 0.0132\n",
      "epoch 9 batch 159/185 loss = 0.0153\n",
      "epoch 9 batch 160/185 loss = 0.0117\n",
      "epoch 9 batch 161/185 loss = 0.0115\n",
      "epoch 9 batch 162/185 loss = 0.0117\n",
      "epoch 9 batch 163/185 loss = 0.0110\n",
      "epoch 9 batch 164/185 loss = 0.0102\n",
      "epoch 9 batch 165/185 loss = 0.0132\n",
      "epoch 9 batch 166/185 loss = 0.0109\n",
      "epoch 9 batch 167/185 loss = 0.0153\n",
      "epoch 9 batch 168/185 loss = 0.0134\n",
      "epoch 9 batch 169/185 loss = 0.0117\n",
      "epoch 9 batch 170/185 loss = 0.0114\n",
      "epoch 9 batch 171/185 loss = 0.0132\n",
      "epoch 9 batch 172/185 loss = 0.0139\n",
      "epoch 9 batch 173/185 loss = 0.0101\n",
      "epoch 9 batch 174/185 loss = 0.0123\n",
      "epoch 9 batch 175/185 loss = 0.0136\n",
      "epoch 9 batch 176/185 loss = 0.0147\n",
      "epoch 9 batch 177/185 loss = 0.0148\n",
      "epoch 9 batch 178/185 loss = 0.0104\n",
      "epoch 9 batch 179/185 loss = 0.0140\n",
      "epoch 9 batch 180/185 loss = 0.0102\n",
      "epoch 9 batch 181/185 loss = 0.0136\n",
      "epoch 9 batch 182/185 loss = 0.0122\n",
      "epoch 9 batch 183/185 loss = 0.0124\n",
      "epoch 9 batch 184/185 loss = 0.0113\n",
      "epoch 9 batch 185/185 loss = 0.0137\n",
      "epoch 9 train loss = 0.0134 valid loss = 0.0227\n",
      "performance reducing: counter 1\n",
      "epoch 10 batch 1/185 loss = 0.0127\n",
      "epoch 10 batch 2/185 loss = 0.0117\n",
      "epoch 10 batch 3/185 loss = 0.0139\n",
      "epoch 10 batch 4/185 loss = 0.0123\n",
      "epoch 10 batch 5/185 loss = 0.0126\n",
      "epoch 10 batch 6/185 loss = 0.0109\n",
      "epoch 10 batch 7/185 loss = 0.0159\n",
      "epoch 10 batch 8/185 loss = 0.0109\n",
      "epoch 10 batch 9/185 loss = 0.0147\n",
      "epoch 10 batch 10/185 loss = 0.0130\n",
      "epoch 10 batch 11/185 loss = 0.0110\n",
      "epoch 10 batch 12/185 loss = 0.0125\n",
      "epoch 10 batch 13/185 loss = 0.0140\n",
      "epoch 10 batch 14/185 loss = 0.0101\n",
      "epoch 10 batch 15/185 loss = 0.0128\n",
      "epoch 10 batch 16/185 loss = 0.0106\n",
      "epoch 10 batch 17/185 loss = 0.0130\n",
      "epoch 10 batch 18/185 loss = 0.0138\n",
      "epoch 10 batch 19/185 loss = 0.0118\n",
      "epoch 10 batch 20/185 loss = 0.0144\n",
      "epoch 10 batch 21/185 loss = 0.0112\n",
      "epoch 10 batch 22/185 loss = 0.0107\n",
      "epoch 10 batch 23/185 loss = 0.0126\n",
      "epoch 10 batch 24/185 loss = 0.0109\n",
      "epoch 10 batch 25/185 loss = 0.0118\n",
      "epoch 10 batch 26/185 loss = 0.0125\n",
      "epoch 10 batch 27/185 loss = 0.0111\n",
      "epoch 10 batch 28/185 loss = 0.0112\n",
      "epoch 10 batch 29/185 loss = 0.0120\n",
      "epoch 10 batch 30/185 loss = 0.0113\n",
      "epoch 10 batch 31/185 loss = 0.0144\n",
      "epoch 10 batch 32/185 loss = 0.0132\n",
      "epoch 10 batch 33/185 loss = 0.0151\n",
      "epoch 10 batch 34/185 loss = 0.0111\n",
      "epoch 10 batch 35/185 loss = 0.0138\n",
      "epoch 10 batch 36/185 loss = 0.0116\n",
      "epoch 10 batch 37/185 loss = 0.0128\n",
      "epoch 10 batch 38/185 loss = 0.0137\n",
      "epoch 10 batch 39/185 loss = 0.0122\n",
      "epoch 10 batch 40/185 loss = 0.0109\n",
      "epoch 10 batch 41/185 loss = 0.0112\n",
      "epoch 10 batch 42/185 loss = 0.0121\n",
      "epoch 10 batch 43/185 loss = 0.0127\n",
      "epoch 10 batch 44/185 loss = 0.0129\n",
      "epoch 10 batch 45/185 loss = 0.0128\n",
      "epoch 10 batch 46/185 loss = 0.0126\n",
      "epoch 10 batch 47/185 loss = 0.0100\n",
      "epoch 10 batch 48/185 loss = 0.0138\n",
      "epoch 10 batch 49/185 loss = 0.0113\n",
      "epoch 10 batch 50/185 loss = 0.0144\n",
      "epoch 10 batch 51/185 loss = 0.0110\n",
      "epoch 10 batch 52/185 loss = 0.0113\n",
      "epoch 10 batch 53/185 loss = 0.0149\n",
      "epoch 10 batch 54/185 loss = 0.0135\n",
      "epoch 10 batch 55/185 loss = 0.0148\n",
      "epoch 10 batch 56/185 loss = 0.0123\n",
      "epoch 10 batch 57/185 loss = 0.0116\n",
      "epoch 10 batch 58/185 loss = 0.0172\n",
      "epoch 10 batch 59/185 loss = 0.0101\n",
      "epoch 10 batch 60/185 loss = 0.0125\n",
      "epoch 10 batch 61/185 loss = 0.0140\n",
      "epoch 10 batch 62/185 loss = 0.0129\n",
      "epoch 10 batch 63/185 loss = 0.0116\n",
      "epoch 10 batch 64/185 loss = 0.0125\n",
      "epoch 10 batch 65/185 loss = 0.0119\n",
      "epoch 10 batch 66/185 loss = 0.0126\n",
      "epoch 10 batch 67/185 loss = 0.0132\n",
      "epoch 10 batch 68/185 loss = 0.0123\n",
      "epoch 10 batch 69/185 loss = 0.0115\n",
      "epoch 10 batch 70/185 loss = 0.0111\n",
      "epoch 10 batch 71/185 loss = 0.0142\n",
      "epoch 10 batch 72/185 loss = 0.0103\n",
      "epoch 10 batch 73/185 loss = 0.0121\n",
      "epoch 10 batch 74/185 loss = 0.0124\n",
      "epoch 10 batch 75/185 loss = 0.0101\n",
      "epoch 10 batch 76/185 loss = 0.0146\n",
      "epoch 10 batch 77/185 loss = 0.0104\n",
      "epoch 10 batch 78/185 loss = 0.0100\n",
      "epoch 10 batch 79/185 loss = 0.0158\n",
      "epoch 10 batch 80/185 loss = 0.0108\n",
      "epoch 10 batch 81/185 loss = 0.0096\n",
      "epoch 10 batch 82/185 loss = 0.0143\n",
      "epoch 10 batch 83/185 loss = 0.0137\n",
      "epoch 10 batch 84/185 loss = 0.0103\n",
      "epoch 10 batch 85/185 loss = 0.0102\n",
      "epoch 10 batch 86/185 loss = 0.0131\n",
      "epoch 10 batch 87/185 loss = 0.0180\n",
      "epoch 10 batch 88/185 loss = 0.0121\n",
      "epoch 10 batch 89/185 loss = 0.0101\n",
      "epoch 10 batch 90/185 loss = 0.0110\n",
      "epoch 10 batch 91/185 loss = 0.0137\n",
      "epoch 10 batch 92/185 loss = 0.0125\n",
      "epoch 10 batch 93/185 loss = 0.0132\n",
      "epoch 10 batch 94/185 loss = 0.0120\n",
      "epoch 10 batch 95/185 loss = 0.0132\n",
      "epoch 10 batch 96/185 loss = 0.0145\n",
      "epoch 10 batch 97/185 loss = 0.0095\n",
      "epoch 10 batch 98/185 loss = 0.0125\n",
      "epoch 10 batch 99/185 loss = 0.0135\n",
      "epoch 10 batch 100/185 loss = 0.0134\n",
      "epoch 10 batch 101/185 loss = 0.0128\n",
      "epoch 10 batch 102/185 loss = 0.0145\n",
      "epoch 10 batch 103/185 loss = 0.0115\n",
      "epoch 10 batch 104/185 loss = 0.0139\n",
      "epoch 10 batch 105/185 loss = 0.0165\n",
      "epoch 10 batch 106/185 loss = 0.0121\n",
      "epoch 10 batch 107/185 loss = 0.0114\n",
      "epoch 10 batch 108/185 loss = 0.0128\n",
      "epoch 10 batch 109/185 loss = 0.0098\n",
      "epoch 10 batch 110/185 loss = 0.0110\n",
      "epoch 10 batch 111/185 loss = 0.0136\n",
      "epoch 10 batch 112/185 loss = 0.0131\n",
      "epoch 10 batch 113/185 loss = 0.0144\n",
      "epoch 10 batch 114/185 loss = 0.0125\n",
      "epoch 10 batch 115/185 loss = 0.0131\n",
      "epoch 10 batch 116/185 loss = 0.0113\n",
      "epoch 10 batch 117/185 loss = 0.0135\n",
      "epoch 10 batch 118/185 loss = 0.0141\n",
      "epoch 10 batch 119/185 loss = 0.0104\n",
      "epoch 10 batch 120/185 loss = 0.0131\n",
      "epoch 10 batch 121/185 loss = 0.0122\n",
      "epoch 10 batch 122/185 loss = 0.0109\n",
      "epoch 10 batch 123/185 loss = 0.0126\n",
      "epoch 10 batch 124/185 loss = 0.0158\n",
      "epoch 10 batch 125/185 loss = 0.0135\n",
      "epoch 10 batch 126/185 loss = 0.0116\n",
      "epoch 10 batch 127/185 loss = 0.0113\n",
      "epoch 10 batch 128/185 loss = 0.0108\n",
      "epoch 10 batch 129/185 loss = 0.0143\n",
      "epoch 10 batch 130/185 loss = 0.0140\n",
      "epoch 10 batch 131/185 loss = 0.0136\n",
      "epoch 10 batch 132/185 loss = 0.0158\n",
      "epoch 10 batch 133/185 loss = 0.0127\n",
      "epoch 10 batch 134/185 loss = 0.0120\n",
      "epoch 10 batch 135/185 loss = 0.0148\n",
      "epoch 10 batch 136/185 loss = 0.0155\n",
      "epoch 10 batch 137/185 loss = 0.0129\n",
      "epoch 10 batch 138/185 loss = 0.0119\n",
      "epoch 10 batch 139/185 loss = 0.0112\n",
      "epoch 10 batch 140/185 loss = 0.0123\n",
      "epoch 10 batch 141/185 loss = 0.0161\n",
      "epoch 10 batch 142/185 loss = 0.0144\n",
      "epoch 10 batch 143/185 loss = 0.0121\n",
      "epoch 10 batch 144/185 loss = 0.0131\n",
      "epoch 10 batch 145/185 loss = 0.0135\n",
      "epoch 10 batch 146/185 loss = 0.0131\n",
      "epoch 10 batch 147/185 loss = 0.0125\n",
      "epoch 10 batch 148/185 loss = 0.0098\n",
      "epoch 10 batch 149/185 loss = 0.0136\n",
      "epoch 10 batch 150/185 loss = 0.0131\n",
      "epoch 10 batch 151/185 loss = 0.0118\n",
      "epoch 10 batch 152/185 loss = 0.0127\n",
      "epoch 10 batch 153/185 loss = 0.0133\n",
      "epoch 10 batch 154/185 loss = 0.0120\n",
      "epoch 10 batch 155/185 loss = 0.0115\n",
      "epoch 10 batch 156/185 loss = 0.0123\n",
      "epoch 10 batch 157/185 loss = 0.0119\n",
      "epoch 10 batch 158/185 loss = 0.0125\n",
      "epoch 10 batch 159/185 loss = 0.0122\n",
      "epoch 10 batch 160/185 loss = 0.0111\n",
      "epoch 10 batch 161/185 loss = 0.0120\n",
      "epoch 10 batch 162/185 loss = 0.0120\n",
      "epoch 10 batch 163/185 loss = 0.0125\n",
      "epoch 10 batch 164/185 loss = 0.0140\n",
      "epoch 10 batch 165/185 loss = 0.0125\n",
      "epoch 10 batch 166/185 loss = 0.0125\n",
      "epoch 10 batch 167/185 loss = 0.0107\n",
      "epoch 10 batch 168/185 loss = 0.0126\n",
      "epoch 10 batch 169/185 loss = 0.0128\n",
      "epoch 10 batch 170/185 loss = 0.0141\n",
      "epoch 10 batch 171/185 loss = 0.0159\n",
      "epoch 10 batch 172/185 loss = 0.0142\n",
      "epoch 10 batch 173/185 loss = 0.0113\n",
      "epoch 10 batch 174/185 loss = 0.0103\n",
      "epoch 10 batch 175/185 loss = 0.0098\n",
      "epoch 10 batch 176/185 loss = 0.0121\n",
      "epoch 10 batch 177/185 loss = 0.0136\n",
      "epoch 10 batch 178/185 loss = 0.0126\n",
      "epoch 10 batch 179/185 loss = 0.0136\n",
      "epoch 10 batch 180/185 loss = 0.0127\n",
      "epoch 10 batch 181/185 loss = 0.0161\n",
      "epoch 10 batch 182/185 loss = 0.0105\n",
      "epoch 10 batch 183/185 loss = 0.0125\n",
      "epoch 10 batch 184/185 loss = 0.0112\n",
      "epoch 10 batch 185/185 loss = 0.0137\n",
      "epoch 10 train loss = 0.0126 valid loss = 0.0248\n",
      "performance reducing: counter 2\n",
      "epoch 11 batch 1/185 loss = 0.0129\n",
      "epoch 11 batch 2/185 loss = 0.0123\n",
      "epoch 11 batch 3/185 loss = 0.0111\n",
      "epoch 11 batch 4/185 loss = 0.0118\n",
      "epoch 11 batch 5/185 loss = 0.0122\n",
      "epoch 11 batch 6/185 loss = 0.0118\n",
      "epoch 11 batch 7/185 loss = 0.0131\n",
      "epoch 11 batch 8/185 loss = 0.0123\n",
      "epoch 11 batch 9/185 loss = 0.0122\n",
      "epoch 11 batch 10/185 loss = 0.0117\n",
      "epoch 11 batch 11/185 loss = 0.0146\n",
      "epoch 11 batch 12/185 loss = 0.0112\n",
      "epoch 11 batch 13/185 loss = 0.0127\n",
      "epoch 11 batch 14/185 loss = 0.0119\n",
      "epoch 11 batch 15/185 loss = 0.0119\n",
      "epoch 11 batch 16/185 loss = 0.0130\n",
      "epoch 11 batch 17/185 loss = 0.0131\n",
      "epoch 11 batch 18/185 loss = 0.0099\n",
      "epoch 11 batch 19/185 loss = 0.0122\n",
      "epoch 11 batch 20/185 loss = 0.0109\n",
      "epoch 11 batch 21/185 loss = 0.0142\n",
      "epoch 11 batch 22/185 loss = 0.0155\n",
      "epoch 11 batch 23/185 loss = 0.0097\n",
      "epoch 11 batch 24/185 loss = 0.0110\n",
      "epoch 11 batch 25/185 loss = 0.0120\n",
      "epoch 11 batch 26/185 loss = 0.0114\n",
      "epoch 11 batch 27/185 loss = 0.0133\n",
      "epoch 11 batch 28/185 loss = 0.0143\n",
      "epoch 11 batch 29/185 loss = 0.0119\n",
      "epoch 11 batch 30/185 loss = 0.0103\n",
      "epoch 11 batch 31/185 loss = 0.0122\n",
      "epoch 11 batch 32/185 loss = 0.0144\n",
      "epoch 11 batch 33/185 loss = 0.0119\n",
      "epoch 11 batch 34/185 loss = 0.0123\n",
      "epoch 11 batch 35/185 loss = 0.0112\n",
      "epoch 11 batch 36/185 loss = 0.0109\n",
      "epoch 11 batch 37/185 loss = 0.0128\n",
      "epoch 11 batch 38/185 loss = 0.0130\n",
      "epoch 11 batch 39/185 loss = 0.0094\n",
      "epoch 11 batch 40/185 loss = 0.0110\n",
      "epoch 11 batch 41/185 loss = 0.0126\n",
      "epoch 11 batch 42/185 loss = 0.0107\n",
      "epoch 11 batch 43/185 loss = 0.0134\n",
      "epoch 11 batch 44/185 loss = 0.0104\n",
      "epoch 11 batch 45/185 loss = 0.0135\n",
      "epoch 11 batch 46/185 loss = 0.0129\n",
      "epoch 11 batch 47/185 loss = 0.0172\n",
      "epoch 11 batch 48/185 loss = 0.0143\n",
      "epoch 11 batch 49/185 loss = 0.0108\n",
      "epoch 11 batch 50/185 loss = 0.0138\n",
      "epoch 11 batch 51/185 loss = 0.0104\n",
      "epoch 11 batch 52/185 loss = 0.0114\n",
      "epoch 11 batch 53/185 loss = 0.0098\n",
      "epoch 11 batch 54/185 loss = 0.0125\n",
      "epoch 11 batch 55/185 loss = 0.0111\n",
      "epoch 11 batch 56/185 loss = 0.0111\n",
      "epoch 11 batch 57/185 loss = 0.0126\n",
      "epoch 11 batch 58/185 loss = 0.0122\n",
      "epoch 11 batch 59/185 loss = 0.0166\n",
      "epoch 11 batch 60/185 loss = 0.0139\n",
      "epoch 11 batch 61/185 loss = 0.0149\n",
      "epoch 11 batch 62/185 loss = 0.0140\n",
      "epoch 11 batch 63/185 loss = 0.0127\n",
      "epoch 11 batch 64/185 loss = 0.0123\n",
      "epoch 11 batch 65/185 loss = 0.0124\n",
      "epoch 11 batch 66/185 loss = 0.0139\n",
      "epoch 11 batch 67/185 loss = 0.0131\n",
      "epoch 11 batch 68/185 loss = 0.0100\n",
      "epoch 11 batch 69/185 loss = 0.0151\n",
      "epoch 11 batch 70/185 loss = 0.0135\n",
      "epoch 11 batch 71/185 loss = 0.0122\n",
      "epoch 11 batch 72/185 loss = 0.0119\n",
      "epoch 11 batch 73/185 loss = 0.0119\n",
      "epoch 11 batch 74/185 loss = 0.0120\n",
      "epoch 11 batch 75/185 loss = 0.0116\n",
      "epoch 11 batch 76/185 loss = 0.0163\n",
      "epoch 11 batch 77/185 loss = 0.0118\n",
      "epoch 11 batch 78/185 loss = 0.0134\n",
      "epoch 11 batch 79/185 loss = 0.0170\n",
      "epoch 11 batch 80/185 loss = 0.0148\n",
      "epoch 11 batch 81/185 loss = 0.0127\n",
      "epoch 11 batch 82/185 loss = 0.0139\n",
      "epoch 11 batch 83/185 loss = 0.0117\n",
      "epoch 11 batch 84/185 loss = 0.0139\n",
      "epoch 11 batch 85/185 loss = 0.0103\n",
      "epoch 11 batch 86/185 loss = 0.0123\n",
      "epoch 11 batch 87/185 loss = 0.0136\n",
      "epoch 11 batch 88/185 loss = 0.0120\n",
      "epoch 11 batch 89/185 loss = 0.0120\n",
      "epoch 11 batch 90/185 loss = 0.0106\n",
      "epoch 11 batch 91/185 loss = 0.0145\n",
      "epoch 11 batch 92/185 loss = 0.0099\n",
      "epoch 11 batch 93/185 loss = 0.0105\n",
      "epoch 11 batch 94/185 loss = 0.0125\n",
      "epoch 11 batch 95/185 loss = 0.0160\n",
      "epoch 11 batch 96/185 loss = 0.0114\n",
      "epoch 11 batch 97/185 loss = 0.0113\n",
      "epoch 11 batch 98/185 loss = 0.0109\n",
      "epoch 11 batch 99/185 loss = 0.0125\n",
      "epoch 11 batch 100/185 loss = 0.0129\n",
      "epoch 11 batch 101/185 loss = 0.0126\n",
      "epoch 11 batch 102/185 loss = 0.0109\n",
      "epoch 11 batch 103/185 loss = 0.0143\n",
      "epoch 11 batch 104/185 loss = 0.0113\n",
      "epoch 11 batch 105/185 loss = 0.0121\n",
      "epoch 11 batch 106/185 loss = 0.0121\n",
      "epoch 11 batch 107/185 loss = 0.0128\n",
      "epoch 11 batch 108/185 loss = 0.0110\n",
      "epoch 11 batch 109/185 loss = 0.0134\n",
      "epoch 11 batch 110/185 loss = 0.0108\n",
      "epoch 11 batch 111/185 loss = 0.0109\n",
      "epoch 11 batch 112/185 loss = 0.0113\n",
      "epoch 11 batch 113/185 loss = 0.0139\n",
      "epoch 11 batch 114/185 loss = 0.0101\n",
      "epoch 11 batch 115/185 loss = 0.0126\n",
      "epoch 11 batch 116/185 loss = 0.0134\n",
      "epoch 11 batch 117/185 loss = 0.0138\n",
      "epoch 11 batch 118/185 loss = 0.0153\n",
      "epoch 11 batch 119/185 loss = 0.0109\n",
      "epoch 11 batch 120/185 loss = 0.0121\n",
      "epoch 11 batch 121/185 loss = 0.0134\n",
      "epoch 11 batch 122/185 loss = 0.0115\n",
      "epoch 11 batch 123/185 loss = 0.0136\n",
      "epoch 11 batch 124/185 loss = 0.0120\n",
      "epoch 11 batch 125/185 loss = 0.0140\n",
      "epoch 11 batch 126/185 loss = 0.0126\n",
      "epoch 11 batch 127/185 loss = 0.0144\n",
      "epoch 11 batch 128/185 loss = 0.0116\n",
      "epoch 11 batch 129/185 loss = 0.0109\n",
      "epoch 11 batch 130/185 loss = 0.0103\n",
      "epoch 11 batch 131/185 loss = 0.0132\n",
      "epoch 11 batch 132/185 loss = 0.0109\n",
      "epoch 11 batch 133/185 loss = 0.0098\n",
      "epoch 11 batch 134/185 loss = 0.0115\n",
      "epoch 11 batch 135/185 loss = 0.0100\n",
      "epoch 11 batch 136/185 loss = 0.0153\n",
      "epoch 11 batch 137/185 loss = 0.0108\n",
      "epoch 11 batch 138/185 loss = 0.0118\n",
      "epoch 11 batch 139/185 loss = 0.0121\n",
      "epoch 11 batch 140/185 loss = 0.0131\n",
      "epoch 11 batch 141/185 loss = 0.0106\n",
      "epoch 11 batch 142/185 loss = 0.0099\n",
      "epoch 11 batch 143/185 loss = 0.0110\n",
      "epoch 11 batch 144/185 loss = 0.0112\n",
      "epoch 11 batch 145/185 loss = 0.0134\n",
      "epoch 11 batch 146/185 loss = 0.0115\n",
      "epoch 11 batch 147/185 loss = 0.0117\n",
      "epoch 11 batch 148/185 loss = 0.0139\n",
      "epoch 11 batch 149/185 loss = 0.0114\n",
      "epoch 11 batch 150/185 loss = 0.0142\n",
      "epoch 11 batch 151/185 loss = 0.0128\n",
      "epoch 11 batch 152/185 loss = 0.0099\n",
      "epoch 11 batch 153/185 loss = 0.0125\n",
      "epoch 11 batch 154/185 loss = 0.0116\n",
      "epoch 11 batch 155/185 loss = 0.0104\n",
      "epoch 11 batch 156/185 loss = 0.0150\n",
      "epoch 11 batch 157/185 loss = 0.0103\n",
      "epoch 11 batch 158/185 loss = 0.0140\n",
      "epoch 11 batch 159/185 loss = 0.0114\n",
      "epoch 11 batch 160/185 loss = 0.0130\n",
      "epoch 11 batch 161/185 loss = 0.0106\n",
      "epoch 11 batch 162/185 loss = 0.0105\n",
      "epoch 11 batch 163/185 loss = 0.0093\n",
      "epoch 11 batch 164/185 loss = 0.0135\n",
      "epoch 11 batch 165/185 loss = 0.0119\n",
      "epoch 11 batch 166/185 loss = 0.0166\n",
      "epoch 11 batch 167/185 loss = 0.0124\n",
      "epoch 11 batch 168/185 loss = 0.0143\n",
      "epoch 11 batch 169/185 loss = 0.0163\n",
      "epoch 11 batch 170/185 loss = 0.0123\n",
      "epoch 11 batch 171/185 loss = 0.0130\n",
      "epoch 11 batch 172/185 loss = 0.0096\n",
      "epoch 11 batch 173/185 loss = 0.0127\n",
      "epoch 11 batch 174/185 loss = 0.0118\n",
      "epoch 11 batch 175/185 loss = 0.0117\n",
      "epoch 11 batch 176/185 loss = 0.0099\n",
      "epoch 11 batch 177/185 loss = 0.0117\n",
      "epoch 11 batch 178/185 loss = 0.0096\n",
      "epoch 11 batch 179/185 loss = 0.0119\n",
      "epoch 11 batch 180/185 loss = 0.0118\n",
      "epoch 11 batch 181/185 loss = 0.0125\n",
      "epoch 11 batch 182/185 loss = 0.0118\n",
      "epoch 11 batch 183/185 loss = 0.0127\n",
      "epoch 11 batch 184/185 loss = 0.0134\n",
      "epoch 11 batch 185/185 loss = 0.0124\n",
      "epoch 11 train loss = 0.0123 valid loss = 0.0182\n",
      "epoch 12 batch 1/185 loss = 0.0131\n",
      "epoch 12 batch 2/185 loss = 0.0126\n",
      "epoch 12 batch 3/185 loss = 0.0113\n",
      "epoch 12 batch 4/185 loss = 0.0123\n",
      "epoch 12 batch 5/185 loss = 0.0110\n",
      "epoch 12 batch 6/185 loss = 0.0109\n",
      "epoch 12 batch 7/185 loss = 0.0121\n",
      "epoch 12 batch 8/185 loss = 0.0142\n",
      "epoch 12 batch 9/185 loss = 0.0118\n",
      "epoch 12 batch 10/185 loss = 0.0136\n",
      "epoch 12 batch 11/185 loss = 0.0112\n",
      "epoch 12 batch 12/185 loss = 0.0094\n",
      "epoch 12 batch 13/185 loss = 0.0122\n",
      "epoch 12 batch 14/185 loss = 0.0128\n",
      "epoch 12 batch 15/185 loss = 0.0112\n",
      "epoch 12 batch 16/185 loss = 0.0129\n",
      "epoch 12 batch 17/185 loss = 0.0127\n",
      "epoch 12 batch 18/185 loss = 0.0142\n",
      "epoch 12 batch 19/185 loss = 0.0138\n",
      "epoch 12 batch 20/185 loss = 0.0138\n",
      "epoch 12 batch 21/185 loss = 0.0114\n",
      "epoch 12 batch 22/185 loss = 0.0105\n",
      "epoch 12 batch 23/185 loss = 0.0144\n",
      "epoch 12 batch 24/185 loss = 0.0119\n",
      "epoch 12 batch 25/185 loss = 0.0127\n",
      "epoch 12 batch 26/185 loss = 0.0144\n",
      "epoch 12 batch 27/185 loss = 0.0113\n",
      "epoch 12 batch 28/185 loss = 0.0114\n",
      "epoch 12 batch 29/185 loss = 0.0113\n",
      "epoch 12 batch 30/185 loss = 0.0132\n",
      "epoch 12 batch 31/185 loss = 0.0104\n",
      "epoch 12 batch 32/185 loss = 0.0151\n",
      "epoch 12 batch 33/185 loss = 0.0141\n",
      "epoch 12 batch 34/185 loss = 0.0122\n",
      "epoch 12 batch 35/185 loss = 0.0091\n",
      "epoch 12 batch 36/185 loss = 0.0127\n",
      "epoch 12 batch 37/185 loss = 0.0122\n",
      "epoch 12 batch 38/185 loss = 0.0120\n",
      "epoch 12 batch 39/185 loss = 0.0113\n",
      "epoch 12 batch 40/185 loss = 0.0130\n",
      "epoch 12 batch 41/185 loss = 0.0099\n",
      "epoch 12 batch 42/185 loss = 0.0110\n",
      "epoch 12 batch 43/185 loss = 0.0128\n",
      "epoch 12 batch 44/185 loss = 0.0095\n",
      "epoch 12 batch 45/185 loss = 0.0097\n",
      "epoch 12 batch 46/185 loss = 0.0162\n",
      "epoch 12 batch 47/185 loss = 0.0141\n",
      "epoch 12 batch 48/185 loss = 0.0124\n",
      "epoch 12 batch 49/185 loss = 0.0099\n",
      "epoch 12 batch 50/185 loss = 0.0131\n",
      "epoch 12 batch 51/185 loss = 0.0115\n",
      "epoch 12 batch 52/185 loss = 0.0117\n",
      "epoch 12 batch 53/185 loss = 0.0116\n",
      "epoch 12 batch 54/185 loss = 0.0093\n",
      "epoch 12 batch 55/185 loss = 0.0111\n",
      "epoch 12 batch 56/185 loss = 0.0131\n",
      "epoch 12 batch 57/185 loss = 0.0099\n",
      "epoch 12 batch 58/185 loss = 0.0140\n",
      "epoch 12 batch 59/185 loss = 0.0116\n",
      "epoch 12 batch 60/185 loss = 0.0108\n",
      "epoch 12 batch 61/185 loss = 0.0131\n",
      "epoch 12 batch 62/185 loss = 0.0101\n",
      "epoch 12 batch 63/185 loss = 0.0140\n",
      "epoch 12 batch 64/185 loss = 0.0113\n",
      "epoch 12 batch 65/185 loss = 0.0117\n",
      "epoch 12 batch 66/185 loss = 0.0129\n",
      "epoch 12 batch 67/185 loss = 0.0120\n",
      "epoch 12 batch 68/185 loss = 0.0098\n",
      "epoch 12 batch 69/185 loss = 0.0110\n",
      "epoch 12 batch 70/185 loss = 0.0138\n",
      "epoch 12 batch 71/185 loss = 0.0123\n",
      "epoch 12 batch 72/185 loss = 0.0123\n",
      "epoch 12 batch 73/185 loss = 0.0112\n",
      "epoch 12 batch 74/185 loss = 0.0101\n",
      "epoch 12 batch 75/185 loss = 0.0099\n",
      "epoch 12 batch 76/185 loss = 0.0109\n",
      "epoch 12 batch 77/185 loss = 0.0109\n",
      "epoch 12 batch 78/185 loss = 0.0111\n",
      "epoch 12 batch 79/185 loss = 0.0120\n",
      "epoch 12 batch 80/185 loss = 0.0111\n",
      "epoch 12 batch 81/185 loss = 0.0134\n",
      "epoch 12 batch 82/185 loss = 0.0118\n",
      "epoch 12 batch 83/185 loss = 0.0124\n",
      "epoch 12 batch 84/185 loss = 0.0102\n",
      "epoch 12 batch 85/185 loss = 0.0125\n",
      "epoch 12 batch 86/185 loss = 0.0128\n",
      "epoch 12 batch 87/185 loss = 0.0114\n",
      "epoch 12 batch 88/185 loss = 0.0146\n",
      "epoch 12 batch 89/185 loss = 0.0128\n",
      "epoch 12 batch 90/185 loss = 0.0122\n",
      "epoch 12 batch 91/185 loss = 0.0150\n",
      "epoch 12 batch 92/185 loss = 0.0124\n",
      "epoch 12 batch 93/185 loss = 0.0137\n",
      "epoch 12 batch 94/185 loss = 0.0120\n",
      "epoch 12 batch 95/185 loss = 0.0126\n",
      "epoch 12 batch 96/185 loss = 0.0115\n",
      "epoch 12 batch 97/185 loss = 0.0116\n",
      "epoch 12 batch 98/185 loss = 0.0089\n",
      "epoch 12 batch 99/185 loss = 0.0126\n",
      "epoch 12 batch 100/185 loss = 0.0109\n",
      "epoch 12 batch 101/185 loss = 0.0123\n",
      "epoch 12 batch 102/185 loss = 0.0121\n",
      "epoch 12 batch 103/185 loss = 0.0125\n",
      "epoch 12 batch 104/185 loss = 0.0119\n",
      "epoch 12 batch 105/185 loss = 0.0131\n",
      "epoch 12 batch 106/185 loss = 0.0118\n",
      "epoch 12 batch 107/185 loss = 0.0103\n",
      "epoch 12 batch 108/185 loss = 0.0124\n",
      "epoch 12 batch 109/185 loss = 0.0125\n",
      "epoch 12 batch 110/185 loss = 0.0133\n",
      "epoch 12 batch 111/185 loss = 0.0134\n",
      "epoch 12 batch 112/185 loss = 0.0137\n",
      "epoch 12 batch 113/185 loss = 0.0124\n",
      "epoch 12 batch 114/185 loss = 0.0115\n",
      "epoch 12 batch 115/185 loss = 0.0097\n",
      "epoch 12 batch 116/185 loss = 0.0128\n",
      "epoch 12 batch 117/185 loss = 0.0158\n",
      "epoch 12 batch 118/185 loss = 0.0113\n",
      "epoch 12 batch 119/185 loss = 0.0126\n",
      "epoch 12 batch 120/185 loss = 0.0127\n",
      "epoch 12 batch 121/185 loss = 0.0092\n",
      "epoch 12 batch 122/185 loss = 0.0103\n",
      "epoch 12 batch 123/185 loss = 0.0119\n",
      "epoch 12 batch 124/185 loss = 0.0112\n",
      "epoch 12 batch 125/185 loss = 0.0142\n",
      "epoch 12 batch 126/185 loss = 0.0104\n",
      "epoch 12 batch 127/185 loss = 0.0140\n",
      "epoch 12 batch 128/185 loss = 0.0094\n",
      "epoch 12 batch 129/185 loss = 0.0122\n",
      "epoch 12 batch 130/185 loss = 0.0109\n",
      "epoch 12 batch 131/185 loss = 0.0104\n",
      "epoch 12 batch 132/185 loss = 0.0104\n",
      "epoch 12 batch 133/185 loss = 0.0105\n",
      "epoch 12 batch 134/185 loss = 0.0125\n",
      "epoch 12 batch 135/185 loss = 0.0116\n",
      "epoch 12 batch 136/185 loss = 0.0110\n",
      "epoch 12 batch 137/185 loss = 0.0120\n",
      "epoch 12 batch 138/185 loss = 0.0119\n",
      "epoch 12 batch 139/185 loss = 0.0114\n",
      "epoch 12 batch 140/185 loss = 0.0124\n",
      "epoch 12 batch 141/185 loss = 0.0127\n",
      "epoch 12 batch 142/185 loss = 0.0092\n",
      "epoch 12 batch 143/185 loss = 0.0104\n",
      "epoch 12 batch 144/185 loss = 0.0103\n",
      "epoch 12 batch 145/185 loss = 0.0137\n",
      "epoch 12 batch 146/185 loss = 0.0134\n",
      "epoch 12 batch 147/185 loss = 0.0104\n",
      "epoch 12 batch 148/185 loss = 0.0125\n",
      "epoch 12 batch 149/185 loss = 0.0112\n",
      "epoch 12 batch 150/185 loss = 0.0102\n",
      "epoch 12 batch 151/185 loss = 0.0106\n",
      "epoch 12 batch 152/185 loss = 0.0148\n",
      "epoch 12 batch 153/185 loss = 0.0140\n",
      "epoch 12 batch 154/185 loss = 0.0100\n",
      "epoch 12 batch 155/185 loss = 0.0111\n",
      "epoch 12 batch 156/185 loss = 0.0135\n",
      "epoch 12 batch 157/185 loss = 0.0138\n",
      "epoch 12 batch 158/185 loss = 0.0170\n",
      "epoch 12 batch 159/185 loss = 0.0152\n",
      "epoch 12 batch 160/185 loss = 0.0120\n",
      "epoch 12 batch 161/185 loss = 0.0135\n",
      "epoch 12 batch 162/185 loss = 0.0116\n",
      "epoch 12 batch 163/185 loss = 0.0135\n",
      "epoch 12 batch 164/185 loss = 0.0106\n",
      "epoch 12 batch 165/185 loss = 0.0149\n",
      "epoch 12 batch 166/185 loss = 0.0120\n",
      "epoch 12 batch 167/185 loss = 0.0129\n",
      "epoch 12 batch 168/185 loss = 0.0150\n",
      "epoch 12 batch 169/185 loss = 0.0139\n",
      "epoch 12 batch 170/185 loss = 0.0169\n",
      "epoch 12 batch 171/185 loss = 0.0112\n",
      "epoch 12 batch 172/185 loss = 0.0113\n",
      "epoch 12 batch 173/185 loss = 0.0104\n",
      "epoch 12 batch 174/185 loss = 0.0102\n",
      "epoch 12 batch 175/185 loss = 0.0141\n",
      "epoch 12 batch 176/185 loss = 0.0134\n",
      "epoch 12 batch 177/185 loss = 0.0115\n",
      "epoch 12 batch 178/185 loss = 0.0112\n",
      "epoch 12 batch 179/185 loss = 0.0119\n",
      "epoch 12 batch 180/185 loss = 0.0115\n",
      "epoch 12 batch 181/185 loss = 0.0123\n",
      "epoch 12 batch 182/185 loss = 0.0129\n",
      "epoch 12 batch 183/185 loss = 0.0153\n",
      "epoch 12 batch 184/185 loss = 0.0118\n",
      "epoch 12 batch 185/185 loss = 0.0096\n",
      "epoch 12 train loss = 0.0121 valid loss = 0.0201\n",
      "performance reducing: counter 1\n",
      "epoch 13 batch 1/185 loss = 0.0097\n",
      "epoch 13 batch 2/185 loss = 0.0145\n",
      "epoch 13 batch 3/185 loss = 0.0105\n",
      "epoch 13 batch 4/185 loss = 0.0129\n",
      "epoch 13 batch 5/185 loss = 0.0137\n",
      "epoch 13 batch 6/185 loss = 0.0103\n",
      "epoch 13 batch 7/185 loss = 0.0122\n",
      "epoch 13 batch 8/185 loss = 0.0112\n",
      "epoch 13 batch 9/185 loss = 0.0143\n",
      "epoch 13 batch 10/185 loss = 0.0105\n",
      "epoch 13 batch 11/185 loss = 0.0123\n",
      "epoch 13 batch 12/185 loss = 0.0100\n",
      "epoch 13 batch 13/185 loss = 0.0132\n",
      "epoch 13 batch 14/185 loss = 0.0104\n",
      "epoch 13 batch 15/185 loss = 0.0159\n",
      "epoch 13 batch 16/185 loss = 0.0119\n",
      "epoch 13 batch 17/185 loss = 0.0107\n",
      "epoch 13 batch 18/185 loss = 0.0115\n",
      "epoch 13 batch 19/185 loss = 0.0114\n",
      "epoch 13 batch 20/185 loss = 0.0111\n",
      "epoch 13 batch 21/185 loss = 0.0105\n",
      "epoch 13 batch 22/185 loss = 0.0135\n",
      "epoch 13 batch 23/185 loss = 0.0121\n",
      "epoch 13 batch 24/185 loss = 0.0148\n",
      "epoch 13 batch 25/185 loss = 0.0113\n",
      "epoch 13 batch 26/185 loss = 0.0153\n",
      "epoch 13 batch 27/185 loss = 0.0134\n",
      "epoch 13 batch 28/185 loss = 0.0104\n",
      "epoch 13 batch 29/185 loss = 0.0135\n",
      "epoch 13 batch 30/185 loss = 0.0100\n",
      "epoch 13 batch 31/185 loss = 0.0133\n",
      "epoch 13 batch 32/185 loss = 0.0108\n",
      "epoch 13 batch 33/185 loss = 0.0108\n",
      "epoch 13 batch 34/185 loss = 0.0117\n",
      "epoch 13 batch 35/185 loss = 0.0111\n",
      "epoch 13 batch 36/185 loss = 0.0099\n",
      "epoch 13 batch 37/185 loss = 0.0117\n",
      "epoch 13 batch 38/185 loss = 0.0113\n",
      "epoch 13 batch 39/185 loss = 0.0101\n",
      "epoch 13 batch 40/185 loss = 0.0135\n",
      "epoch 13 batch 41/185 loss = 0.0096\n",
      "epoch 13 batch 42/185 loss = 0.0138\n",
      "epoch 13 batch 43/185 loss = 0.0154\n",
      "epoch 13 batch 44/185 loss = 0.0119\n",
      "epoch 13 batch 45/185 loss = 0.0135\n",
      "epoch 13 batch 46/185 loss = 0.0133\n",
      "epoch 13 batch 47/185 loss = 0.0124\n",
      "epoch 13 batch 48/185 loss = 0.0148\n",
      "epoch 13 batch 49/185 loss = 0.0120\n",
      "epoch 13 batch 50/185 loss = 0.0141\n",
      "epoch 13 batch 51/185 loss = 0.0138\n",
      "epoch 13 batch 52/185 loss = 0.0114\n",
      "epoch 13 batch 53/185 loss = 0.0131\n",
      "epoch 13 batch 54/185 loss = 0.0130\n",
      "epoch 13 batch 55/185 loss = 0.0115\n",
      "epoch 13 batch 56/185 loss = 0.0135\n",
      "epoch 13 batch 57/185 loss = 0.0121\n",
      "epoch 13 batch 58/185 loss = 0.0112\n",
      "epoch 13 batch 59/185 loss = 0.0127\n",
      "epoch 13 batch 60/185 loss = 0.0108\n",
      "epoch 13 batch 61/185 loss = 0.0110\n",
      "epoch 13 batch 62/185 loss = 0.0128\n",
      "epoch 13 batch 63/185 loss = 0.0100\n",
      "epoch 13 batch 64/185 loss = 0.0117\n",
      "epoch 13 batch 65/185 loss = 0.0113\n",
      "epoch 13 batch 66/185 loss = 0.0145\n",
      "epoch 13 batch 67/185 loss = 0.0134\n",
      "epoch 13 batch 68/185 loss = 0.0126\n",
      "epoch 13 batch 69/185 loss = 0.0148\n",
      "epoch 13 batch 70/185 loss = 0.0107\n",
      "epoch 13 batch 71/185 loss = 0.0110\n",
      "epoch 13 batch 72/185 loss = 0.0129\n",
      "epoch 13 batch 73/185 loss = 0.0103\n",
      "epoch 13 batch 74/185 loss = 0.0118\n",
      "epoch 13 batch 75/185 loss = 0.0133\n",
      "epoch 13 batch 76/185 loss = 0.0140\n",
      "epoch 13 batch 77/185 loss = 0.0123\n",
      "epoch 13 batch 78/185 loss = 0.0121\n",
      "epoch 13 batch 79/185 loss = 0.0145\n",
      "epoch 13 batch 80/185 loss = 0.0123\n",
      "epoch 13 batch 81/185 loss = 0.0139\n",
      "epoch 13 batch 82/185 loss = 0.0138\n",
      "epoch 13 batch 83/185 loss = 0.0137\n",
      "epoch 13 batch 84/185 loss = 0.0133\n",
      "epoch 13 batch 85/185 loss = 0.0100\n",
      "epoch 13 batch 86/185 loss = 0.0121\n",
      "epoch 13 batch 87/185 loss = 0.0112\n",
      "epoch 13 batch 88/185 loss = 0.0112\n",
      "epoch 13 batch 89/185 loss = 0.0110\n",
      "epoch 13 batch 90/185 loss = 0.0101\n",
      "epoch 13 batch 91/185 loss = 0.0121\n",
      "epoch 13 batch 92/185 loss = 0.0117\n",
      "epoch 13 batch 93/185 loss = 0.0095\n",
      "epoch 13 batch 94/185 loss = 0.0116\n",
      "epoch 13 batch 95/185 loss = 0.0110\n",
      "epoch 13 batch 96/185 loss = 0.0115\n",
      "epoch 13 batch 97/185 loss = 0.0106\n",
      "epoch 13 batch 98/185 loss = 0.0130\n",
      "epoch 13 batch 99/185 loss = 0.0101\n",
      "epoch 13 batch 100/185 loss = 0.0120\n",
      "epoch 13 batch 101/185 loss = 0.0123\n",
      "epoch 13 batch 102/185 loss = 0.0105\n",
      "epoch 13 batch 103/185 loss = 0.0121\n",
      "epoch 13 batch 104/185 loss = 0.0124\n",
      "epoch 13 batch 105/185 loss = 0.0146\n",
      "epoch 13 batch 106/185 loss = 0.0122\n",
      "epoch 13 batch 107/185 loss = 0.0117\n",
      "epoch 13 batch 108/185 loss = 0.0126\n",
      "epoch 13 batch 109/185 loss = 0.0121\n",
      "epoch 13 batch 110/185 loss = 0.0131\n",
      "epoch 13 batch 111/185 loss = 0.0116\n",
      "epoch 13 batch 112/185 loss = 0.0105\n",
      "epoch 13 batch 113/185 loss = 0.0121\n",
      "epoch 13 batch 114/185 loss = 0.0125\n",
      "epoch 13 batch 115/185 loss = 0.0127\n",
      "epoch 13 batch 116/185 loss = 0.0115\n",
      "epoch 13 batch 117/185 loss = 0.0102\n",
      "epoch 13 batch 118/185 loss = 0.0158\n",
      "epoch 13 batch 119/185 loss = 0.0096\n",
      "epoch 13 batch 120/185 loss = 0.0108\n",
      "epoch 13 batch 121/185 loss = 0.0124\n",
      "epoch 13 batch 122/185 loss = 0.0118\n",
      "epoch 13 batch 123/185 loss = 0.0131\n",
      "epoch 13 batch 124/185 loss = 0.0143\n",
      "epoch 13 batch 125/185 loss = 0.0114\n",
      "epoch 13 batch 126/185 loss = 0.0108\n",
      "epoch 13 batch 127/185 loss = 0.0150\n",
      "epoch 13 batch 128/185 loss = 0.0111\n",
      "epoch 13 batch 129/185 loss = 0.0154\n",
      "epoch 13 batch 130/185 loss = 0.0105\n",
      "epoch 13 batch 131/185 loss = 0.0111\n",
      "epoch 13 batch 132/185 loss = 0.0127\n",
      "epoch 13 batch 133/185 loss = 0.0114\n",
      "epoch 13 batch 134/185 loss = 0.0133\n",
      "epoch 13 batch 135/185 loss = 0.0110\n",
      "epoch 13 batch 136/185 loss = 0.0129\n",
      "epoch 13 batch 137/185 loss = 0.0111\n",
      "epoch 13 batch 138/185 loss = 0.0132\n",
      "epoch 13 batch 139/185 loss = 0.0113\n",
      "epoch 13 batch 140/185 loss = 0.0126\n",
      "epoch 13 batch 141/185 loss = 0.0123\n",
      "epoch 13 batch 142/185 loss = 0.0128\n",
      "epoch 13 batch 143/185 loss = 0.0120\n",
      "epoch 13 batch 144/185 loss = 0.0081\n",
      "epoch 13 batch 145/185 loss = 0.0152\n",
      "epoch 13 batch 146/185 loss = 0.0107\n",
      "epoch 13 batch 147/185 loss = 0.0129\n",
      "epoch 13 batch 148/185 loss = 0.0134\n",
      "epoch 13 batch 149/185 loss = 0.0127\n",
      "epoch 13 batch 150/185 loss = 0.0112\n",
      "epoch 13 batch 151/185 loss = 0.0117\n",
      "epoch 13 batch 152/185 loss = 0.0111\n",
      "epoch 13 batch 153/185 loss = 0.0137\n",
      "epoch 13 batch 154/185 loss = 0.0103\n",
      "epoch 13 batch 155/185 loss = 0.0140\n",
      "epoch 13 batch 156/185 loss = 0.0135\n",
      "epoch 13 batch 157/185 loss = 0.0125\n",
      "epoch 13 batch 158/185 loss = 0.0109\n",
      "epoch 13 batch 159/185 loss = 0.0139\n",
      "epoch 13 batch 160/185 loss = 0.0128\n",
      "epoch 13 batch 161/185 loss = 0.0118\n",
      "epoch 13 batch 162/185 loss = 0.0124\n",
      "epoch 13 batch 163/185 loss = 0.0130\n",
      "epoch 13 batch 164/185 loss = 0.0108\n",
      "epoch 13 batch 165/185 loss = 0.0106\n",
      "epoch 13 batch 166/185 loss = 0.0113\n",
      "epoch 13 batch 167/185 loss = 0.0117\n",
      "epoch 13 batch 168/185 loss = 0.0119\n",
      "epoch 13 batch 169/185 loss = 0.0114\n",
      "epoch 13 batch 170/185 loss = 0.0140\n",
      "epoch 13 batch 171/185 loss = 0.0141\n",
      "epoch 13 batch 172/185 loss = 0.0113\n",
      "epoch 13 batch 173/185 loss = 0.0096\n",
      "epoch 13 batch 174/185 loss = 0.0129\n",
      "epoch 13 batch 175/185 loss = 0.0151\n",
      "epoch 13 batch 176/185 loss = 0.0115\n",
      "epoch 13 batch 177/185 loss = 0.0110\n",
      "epoch 13 batch 178/185 loss = 0.0137\n",
      "epoch 13 batch 179/185 loss = 0.0097\n",
      "epoch 13 batch 180/185 loss = 0.0142\n",
      "epoch 13 batch 181/185 loss = 0.0124\n",
      "epoch 13 batch 182/185 loss = 0.0097\n",
      "epoch 13 batch 183/185 loss = 0.0104\n",
      "epoch 13 batch 184/185 loss = 0.0143\n",
      "epoch 13 batch 185/185 loss = 0.0142\n",
      "epoch 13 train loss = 0.0121 valid loss = 0.0179\n",
      "epoch 14 batch 1/185 loss = 0.0117\n",
      "epoch 14 batch 2/185 loss = 0.0107\n",
      "epoch 14 batch 3/185 loss = 0.0119\n",
      "epoch 14 batch 4/185 loss = 0.0113\n",
      "epoch 14 batch 5/185 loss = 0.0109\n",
      "epoch 14 batch 6/185 loss = 0.0116\n",
      "epoch 14 batch 7/185 loss = 0.0102\n",
      "epoch 14 batch 8/185 loss = 0.0128\n",
      "epoch 14 batch 9/185 loss = 0.0124\n",
      "epoch 14 batch 10/185 loss = 0.0123\n",
      "epoch 14 batch 11/185 loss = 0.0109\n",
      "epoch 14 batch 12/185 loss = 0.0101\n",
      "epoch 14 batch 13/185 loss = 0.0122\n",
      "epoch 14 batch 14/185 loss = 0.0116\n",
      "epoch 14 batch 15/185 loss = 0.0142\n",
      "epoch 14 batch 16/185 loss = 0.0127\n",
      "epoch 14 batch 17/185 loss = 0.0145\n",
      "epoch 14 batch 18/185 loss = 0.0122\n",
      "epoch 14 batch 19/185 loss = 0.0140\n",
      "epoch 14 batch 20/185 loss = 0.0100\n",
      "epoch 14 batch 21/185 loss = 0.0112\n",
      "epoch 14 batch 22/185 loss = 0.0126\n",
      "epoch 14 batch 23/185 loss = 0.0135\n",
      "epoch 14 batch 24/185 loss = 0.0099\n",
      "epoch 14 batch 25/185 loss = 0.0142\n",
      "epoch 14 batch 26/185 loss = 0.0121\n",
      "epoch 14 batch 27/185 loss = 0.0102\n",
      "epoch 14 batch 28/185 loss = 0.0106\n",
      "epoch 14 batch 29/185 loss = 0.0120\n",
      "epoch 14 batch 30/185 loss = 0.0111\n",
      "epoch 14 batch 31/185 loss = 0.0109\n",
      "epoch 14 batch 32/185 loss = 0.0126\n",
      "epoch 14 batch 33/185 loss = 0.0125\n",
      "epoch 14 batch 34/185 loss = 0.0107\n",
      "epoch 14 batch 35/185 loss = 0.0101\n",
      "epoch 14 batch 36/185 loss = 0.0119\n",
      "epoch 14 batch 37/185 loss = 0.0112\n",
      "epoch 14 batch 38/185 loss = 0.0112\n",
      "epoch 14 batch 39/185 loss = 0.0114\n",
      "epoch 14 batch 40/185 loss = 0.0123\n",
      "epoch 14 batch 41/185 loss = 0.0099\n",
      "epoch 14 batch 42/185 loss = 0.0124\n",
      "epoch 14 batch 43/185 loss = 0.0115\n",
      "epoch 14 batch 44/185 loss = 0.0140\n",
      "epoch 14 batch 45/185 loss = 0.0120\n",
      "epoch 14 batch 46/185 loss = 0.0141\n",
      "epoch 14 batch 47/185 loss = 0.0102\n",
      "epoch 14 batch 48/185 loss = 0.0126\n",
      "epoch 14 batch 49/185 loss = 0.0123\n",
      "epoch 14 batch 50/185 loss = 0.0107\n",
      "epoch 14 batch 51/185 loss = 0.0106\n",
      "epoch 14 batch 52/185 loss = 0.0134\n",
      "epoch 14 batch 53/185 loss = 0.0125\n",
      "epoch 14 batch 54/185 loss = 0.0105\n",
      "epoch 14 batch 55/185 loss = 0.0098\n",
      "epoch 14 batch 56/185 loss = 0.0099\n",
      "epoch 14 batch 57/185 loss = 0.0157\n",
      "epoch 14 batch 58/185 loss = 0.0151\n",
      "epoch 14 batch 59/185 loss = 0.0135\n",
      "epoch 14 batch 60/185 loss = 0.0122\n",
      "epoch 14 batch 61/185 loss = 0.0128\n",
      "epoch 14 batch 62/185 loss = 0.0120\n",
      "epoch 14 batch 63/185 loss = 0.0153\n",
      "epoch 14 batch 64/185 loss = 0.0153\n",
      "epoch 14 batch 65/185 loss = 0.0113\n",
      "epoch 14 batch 66/185 loss = 0.0125\n",
      "epoch 14 batch 67/185 loss = 0.0113\n",
      "epoch 14 batch 68/185 loss = 0.0118\n",
      "epoch 14 batch 69/185 loss = 0.0126\n",
      "epoch 14 batch 70/185 loss = 0.0118\n",
      "epoch 14 batch 71/185 loss = 0.0125\n",
      "epoch 14 batch 72/185 loss = 0.0140\n",
      "epoch 14 batch 73/185 loss = 0.0124\n",
      "epoch 14 batch 74/185 loss = 0.0135\n",
      "epoch 14 batch 75/185 loss = 0.0136\n",
      "epoch 14 batch 76/185 loss = 0.0131\n",
      "epoch 14 batch 77/185 loss = 0.0122\n",
      "epoch 14 batch 78/185 loss = 0.0116\n",
      "epoch 14 batch 79/185 loss = 0.0117\n",
      "epoch 14 batch 80/185 loss = 0.0117\n",
      "epoch 14 batch 81/185 loss = 0.0106\n",
      "epoch 14 batch 82/185 loss = 0.0130\n",
      "epoch 14 batch 83/185 loss = 0.0113\n",
      "epoch 14 batch 84/185 loss = 0.0141\n",
      "epoch 14 batch 85/185 loss = 0.0138\n",
      "epoch 14 batch 86/185 loss = 0.0146\n",
      "epoch 14 batch 87/185 loss = 0.0140\n",
      "epoch 14 batch 88/185 loss = 0.0101\n",
      "epoch 14 batch 89/185 loss = 0.0091\n",
      "epoch 14 batch 90/185 loss = 0.0086\n",
      "epoch 14 batch 91/185 loss = 0.0123\n",
      "epoch 14 batch 92/185 loss = 0.0132\n",
      "epoch 14 batch 93/185 loss = 0.0136\n",
      "epoch 14 batch 94/185 loss = 0.0130\n",
      "epoch 14 batch 95/185 loss = 0.0125\n",
      "epoch 14 batch 96/185 loss = 0.0091\n",
      "epoch 14 batch 97/185 loss = 0.0118\n",
      "epoch 14 batch 98/185 loss = 0.0106\n",
      "epoch 14 batch 99/185 loss = 0.0116\n",
      "epoch 14 batch 100/185 loss = 0.0112\n",
      "epoch 14 batch 101/185 loss = 0.0122\n",
      "epoch 14 batch 102/185 loss = 0.0102\n",
      "epoch 14 batch 103/185 loss = 0.0111\n",
      "epoch 14 batch 104/185 loss = 0.0129\n",
      "epoch 14 batch 105/185 loss = 0.0121\n",
      "epoch 14 batch 106/185 loss = 0.0127\n",
      "epoch 14 batch 107/185 loss = 0.0111\n",
      "epoch 14 batch 108/185 loss = 0.0120\n",
      "epoch 14 batch 109/185 loss = 0.0111\n",
      "epoch 14 batch 110/185 loss = 0.0124\n",
      "epoch 14 batch 111/185 loss = 0.0122\n",
      "epoch 14 batch 112/185 loss = 0.0119\n",
      "epoch 14 batch 113/185 loss = 0.0147\n",
      "epoch 14 batch 114/185 loss = 0.0126\n",
      "epoch 14 batch 115/185 loss = 0.0111\n",
      "epoch 14 batch 116/185 loss = 0.0094\n",
      "epoch 14 batch 117/185 loss = 0.0131\n",
      "epoch 14 batch 118/185 loss = 0.0097\n",
      "epoch 14 batch 119/185 loss = 0.0105\n",
      "epoch 14 batch 120/185 loss = 0.0115\n",
      "epoch 14 batch 121/185 loss = 0.0122\n",
      "epoch 14 batch 122/185 loss = 0.0108\n",
      "epoch 14 batch 123/185 loss = 0.0110\n",
      "epoch 14 batch 124/185 loss = 0.0094\n",
      "epoch 14 batch 125/185 loss = 0.0159\n",
      "epoch 14 batch 126/185 loss = 0.0115\n",
      "epoch 14 batch 127/185 loss = 0.0095\n",
      "epoch 14 batch 128/185 loss = 0.0145\n",
      "epoch 14 batch 129/185 loss = 0.0110\n",
      "epoch 14 batch 130/185 loss = 0.0128\n",
      "epoch 14 batch 131/185 loss = 0.0116\n",
      "epoch 14 batch 132/185 loss = 0.0145\n",
      "epoch 14 batch 133/185 loss = 0.0134\n",
      "epoch 14 batch 134/185 loss = 0.0086\n",
      "epoch 14 batch 135/185 loss = 0.0133\n",
      "epoch 14 batch 136/185 loss = 0.0133\n",
      "epoch 14 batch 137/185 loss = 0.0114\n",
      "epoch 14 batch 138/185 loss = 0.0134\n",
      "epoch 14 batch 139/185 loss = 0.0103\n",
      "epoch 14 batch 140/185 loss = 0.0137\n",
      "epoch 14 batch 141/185 loss = 0.0094\n",
      "epoch 14 batch 142/185 loss = 0.0118\n",
      "epoch 14 batch 143/185 loss = 0.0119\n",
      "epoch 14 batch 144/185 loss = 0.0107\n",
      "epoch 14 batch 145/185 loss = 0.0131\n",
      "epoch 14 batch 146/185 loss = 0.0130\n",
      "epoch 14 batch 147/185 loss = 0.0094\n",
      "epoch 14 batch 148/185 loss = 0.0147\n",
      "epoch 14 batch 149/185 loss = 0.0112\n",
      "epoch 14 batch 150/185 loss = 0.0111\n",
      "epoch 14 batch 151/185 loss = 0.0101\n",
      "epoch 14 batch 152/185 loss = 0.0108\n",
      "epoch 14 batch 153/185 loss = 0.0110\n",
      "epoch 14 batch 154/185 loss = 0.0133\n",
      "epoch 14 batch 155/185 loss = 0.0089\n",
      "epoch 14 batch 156/185 loss = 0.0099\n",
      "epoch 14 batch 157/185 loss = 0.0149\n",
      "epoch 14 batch 158/185 loss = 0.0102\n",
      "epoch 14 batch 159/185 loss = 0.0113\n",
      "epoch 14 batch 160/185 loss = 0.0120\n",
      "epoch 14 batch 161/185 loss = 0.0116\n",
      "epoch 14 batch 162/185 loss = 0.0102\n",
      "epoch 14 batch 163/185 loss = 0.0125\n",
      "epoch 14 batch 164/185 loss = 0.0089\n",
      "epoch 14 batch 165/185 loss = 0.0106\n",
      "epoch 14 batch 166/185 loss = 0.0122\n",
      "epoch 14 batch 167/185 loss = 0.0107\n",
      "epoch 14 batch 168/185 loss = 0.0114\n",
      "epoch 14 batch 169/185 loss = 0.0116\n",
      "epoch 14 batch 170/185 loss = 0.0106\n",
      "epoch 14 batch 171/185 loss = 0.0122\n",
      "epoch 14 batch 172/185 loss = 0.0131\n",
      "epoch 14 batch 173/185 loss = 0.0102\n",
      "epoch 14 batch 174/185 loss = 0.0116\n",
      "epoch 14 batch 175/185 loss = 0.0102\n",
      "epoch 14 batch 176/185 loss = 0.0121\n",
      "epoch 14 batch 177/185 loss = 0.0133\n",
      "epoch 14 batch 178/185 loss = 0.0140\n",
      "epoch 14 batch 179/185 loss = 0.0112\n",
      "epoch 14 batch 180/185 loss = 0.0101\n",
      "epoch 14 batch 181/185 loss = 0.0102\n",
      "epoch 14 batch 182/185 loss = 0.0119\n",
      "epoch 14 batch 183/185 loss = 0.0122\n",
      "epoch 14 batch 184/185 loss = 0.0107\n",
      "epoch 14 batch 185/185 loss = 0.0135\n",
      "epoch 14 train loss = 0.0119 valid loss = 0.0202\n",
      "performance reducing: counter 1\n",
      "epoch 15 batch 1/185 loss = 0.0132\n",
      "epoch 15 batch 2/185 loss = 0.0135\n",
      "epoch 15 batch 3/185 loss = 0.0108\n",
      "epoch 15 batch 4/185 loss = 0.0110\n",
      "epoch 15 batch 5/185 loss = 0.0106\n",
      "epoch 15 batch 6/185 loss = 0.0093\n",
      "epoch 15 batch 7/185 loss = 0.0098\n",
      "epoch 15 batch 8/185 loss = 0.0122\n",
      "epoch 15 batch 9/185 loss = 0.0093\n",
      "epoch 15 batch 10/185 loss = 0.0105\n",
      "epoch 15 batch 11/185 loss = 0.0122\n",
      "epoch 15 batch 12/185 loss = 0.0130\n",
      "epoch 15 batch 13/185 loss = 0.0121\n",
      "epoch 15 batch 14/185 loss = 0.0125\n",
      "epoch 15 batch 15/185 loss = 0.0105\n",
      "epoch 15 batch 16/185 loss = 0.0099\n",
      "epoch 15 batch 17/185 loss = 0.0111\n",
      "epoch 15 batch 18/185 loss = 0.0095\n",
      "epoch 15 batch 19/185 loss = 0.0129\n",
      "epoch 15 batch 20/185 loss = 0.0102\n",
      "epoch 15 batch 21/185 loss = 0.0122\n",
      "epoch 15 batch 22/185 loss = 0.0111\n",
      "epoch 15 batch 23/185 loss = 0.0127\n",
      "epoch 15 batch 24/185 loss = 0.0137\n",
      "epoch 15 batch 25/185 loss = 0.0117\n",
      "epoch 15 batch 26/185 loss = 0.0095\n",
      "epoch 15 batch 27/185 loss = 0.0113\n",
      "epoch 15 batch 28/185 loss = 0.0127\n",
      "epoch 15 batch 29/185 loss = 0.0109\n",
      "epoch 15 batch 30/185 loss = 0.0098\n",
      "epoch 15 batch 31/185 loss = 0.0104\n",
      "epoch 15 batch 32/185 loss = 0.0125\n",
      "epoch 15 batch 33/185 loss = 0.0127\n",
      "epoch 15 batch 34/185 loss = 0.0104\n",
      "epoch 15 batch 35/185 loss = 0.0117\n",
      "epoch 15 batch 36/185 loss = 0.0112\n",
      "epoch 15 batch 37/185 loss = 0.0122\n",
      "epoch 15 batch 38/185 loss = 0.0117\n",
      "epoch 15 batch 39/185 loss = 0.0104\n",
      "epoch 15 batch 40/185 loss = 0.0121\n",
      "epoch 15 batch 41/185 loss = 0.0130\n",
      "epoch 15 batch 42/185 loss = 0.0116\n",
      "epoch 15 batch 43/185 loss = 0.0139\n",
      "epoch 15 batch 44/185 loss = 0.0138\n",
      "epoch 15 batch 45/185 loss = 0.0119\n",
      "epoch 15 batch 46/185 loss = 0.0098\n",
      "epoch 15 batch 47/185 loss = 0.0120\n",
      "epoch 15 batch 48/185 loss = 0.0100\n",
      "epoch 15 batch 49/185 loss = 0.0097\n",
      "epoch 15 batch 50/185 loss = 0.0105\n",
      "epoch 15 batch 51/185 loss = 0.0109\n",
      "epoch 15 batch 52/185 loss = 0.0115\n",
      "epoch 15 batch 53/185 loss = 0.0102\n",
      "epoch 15 batch 54/185 loss = 0.0106\n",
      "epoch 15 batch 55/185 loss = 0.0103\n",
      "epoch 15 batch 56/185 loss = 0.0127\n",
      "epoch 15 batch 57/185 loss = 0.0095\n",
      "epoch 15 batch 58/185 loss = 0.0152\n",
      "epoch 15 batch 59/185 loss = 0.0106\n",
      "epoch 15 batch 60/185 loss = 0.0110\n",
      "epoch 15 batch 61/185 loss = 0.0102\n",
      "epoch 15 batch 62/185 loss = 0.0111\n",
      "epoch 15 batch 63/185 loss = 0.0091\n",
      "epoch 15 batch 64/185 loss = 0.0138\n",
      "epoch 15 batch 65/185 loss = 0.0100\n",
      "epoch 15 batch 66/185 loss = 0.0099\n",
      "epoch 15 batch 67/185 loss = 0.0134\n",
      "epoch 15 batch 68/185 loss = 0.0110\n",
      "epoch 15 batch 69/185 loss = 0.0113\n",
      "epoch 15 batch 70/185 loss = 0.0111\n",
      "epoch 15 batch 71/185 loss = 0.0121\n",
      "epoch 15 batch 72/185 loss = 0.0115\n",
      "epoch 15 batch 73/185 loss = 0.0118\n",
      "epoch 15 batch 74/185 loss = 0.0124\n",
      "epoch 15 batch 75/185 loss = 0.0129\n",
      "epoch 15 batch 76/185 loss = 0.0111\n",
      "epoch 15 batch 77/185 loss = 0.0117\n",
      "epoch 15 batch 78/185 loss = 0.0089\n",
      "epoch 15 batch 79/185 loss = 0.0107\n",
      "epoch 15 batch 80/185 loss = 0.0098\n",
      "epoch 15 batch 81/185 loss = 0.0077\n",
      "epoch 15 batch 82/185 loss = 0.0133\n",
      "epoch 15 batch 83/185 loss = 0.0099\n",
      "epoch 15 batch 84/185 loss = 0.0128\n",
      "epoch 15 batch 85/185 loss = 0.0110\n",
      "epoch 15 batch 86/185 loss = 0.0111\n",
      "epoch 15 batch 87/185 loss = 0.0093\n",
      "epoch 15 batch 88/185 loss = 0.0144\n",
      "epoch 15 batch 89/185 loss = 0.0114\n",
      "epoch 15 batch 90/185 loss = 0.0106\n",
      "epoch 15 batch 91/185 loss = 0.0109\n",
      "epoch 15 batch 92/185 loss = 0.0114\n",
      "epoch 15 batch 93/185 loss = 0.0131\n",
      "epoch 15 batch 94/185 loss = 0.0110\n",
      "epoch 15 batch 95/185 loss = 0.0101\n",
      "epoch 15 batch 96/185 loss = 0.0111\n",
      "epoch 15 batch 97/185 loss = 0.0108\n",
      "epoch 15 batch 98/185 loss = 0.0111\n",
      "epoch 15 batch 99/185 loss = 0.0170\n",
      "epoch 15 batch 100/185 loss = 0.0134\n",
      "epoch 15 batch 101/185 loss = 0.0123\n",
      "epoch 15 batch 102/185 loss = 0.0124\n",
      "epoch 15 batch 103/185 loss = 0.0111\n",
      "epoch 15 batch 104/185 loss = 0.0100\n",
      "epoch 15 batch 105/185 loss = 0.0111\n",
      "epoch 15 batch 106/185 loss = 0.0175\n",
      "epoch 15 batch 107/185 loss = 0.0098\n",
      "epoch 15 batch 108/185 loss = 0.0154\n",
      "epoch 15 batch 109/185 loss = 0.0112\n",
      "epoch 15 batch 110/185 loss = 0.0097\n",
      "epoch 15 batch 111/185 loss = 0.0107\n",
      "epoch 15 batch 112/185 loss = 0.0112\n",
      "epoch 15 batch 113/185 loss = 0.0126\n",
      "epoch 15 batch 114/185 loss = 0.0129\n",
      "epoch 15 batch 115/185 loss = 0.0118\n",
      "epoch 15 batch 116/185 loss = 0.0127\n",
      "epoch 15 batch 117/185 loss = 0.0121\n",
      "epoch 15 batch 118/185 loss = 0.0102\n",
      "epoch 15 batch 119/185 loss = 0.0122\n",
      "epoch 15 batch 120/185 loss = 0.0145\n",
      "epoch 15 batch 121/185 loss = 0.0149\n",
      "epoch 15 batch 122/185 loss = 0.0093\n",
      "epoch 15 batch 123/185 loss = 0.0096\n",
      "epoch 15 batch 124/185 loss = 0.0105\n",
      "epoch 15 batch 125/185 loss = 0.0105\n",
      "epoch 15 batch 126/185 loss = 0.0114\n",
      "epoch 15 batch 127/185 loss = 0.0128\n",
      "epoch 15 batch 128/185 loss = 0.0113\n",
      "epoch 15 batch 129/185 loss = 0.0120\n",
      "epoch 15 batch 130/185 loss = 0.0099\n",
      "epoch 15 batch 131/185 loss = 0.0115\n",
      "epoch 15 batch 132/185 loss = 0.0124\n",
      "epoch 15 batch 133/185 loss = 0.0094\n",
      "epoch 15 batch 134/185 loss = 0.0096\n",
      "epoch 15 batch 135/185 loss = 0.0111\n",
      "epoch 15 batch 136/185 loss = 0.0113\n",
      "epoch 15 batch 137/185 loss = 0.0099\n",
      "epoch 15 batch 138/185 loss = 0.0122\n",
      "epoch 15 batch 139/185 loss = 0.0150\n",
      "epoch 15 batch 140/185 loss = 0.0158\n",
      "epoch 15 batch 141/185 loss = 0.0120\n",
      "epoch 15 batch 142/185 loss = 0.0096\n",
      "epoch 15 batch 143/185 loss = 0.0119\n",
      "epoch 15 batch 144/185 loss = 0.0133\n",
      "epoch 15 batch 145/185 loss = 0.0120\n",
      "epoch 15 batch 146/185 loss = 0.0125\n",
      "epoch 15 batch 147/185 loss = 0.0098\n",
      "epoch 15 batch 148/185 loss = 0.0138\n",
      "epoch 15 batch 149/185 loss = 0.0105\n",
      "epoch 15 batch 150/185 loss = 0.0093\n",
      "epoch 15 batch 151/185 loss = 0.0116\n",
      "epoch 15 batch 152/185 loss = 0.0149\n",
      "epoch 15 batch 153/185 loss = 0.0151\n",
      "epoch 15 batch 154/185 loss = 0.0126\n",
      "epoch 15 batch 155/185 loss = 0.0129\n",
      "epoch 15 batch 156/185 loss = 0.0111\n",
      "epoch 15 batch 157/185 loss = 0.0126\n",
      "epoch 15 batch 158/185 loss = 0.0104\n",
      "epoch 15 batch 159/185 loss = 0.0093\n",
      "epoch 15 batch 160/185 loss = 0.0107\n",
      "epoch 15 batch 161/185 loss = 0.0110\n",
      "epoch 15 batch 162/185 loss = 0.0117\n",
      "epoch 15 batch 163/185 loss = 0.0103\n",
      "epoch 15 batch 164/185 loss = 0.0105\n",
      "epoch 15 batch 165/185 loss = 0.0174\n",
      "epoch 15 batch 166/185 loss = 0.0118\n",
      "epoch 15 batch 167/185 loss = 0.0108\n",
      "epoch 15 batch 168/185 loss = 0.0124\n",
      "epoch 15 batch 169/185 loss = 0.0136\n",
      "epoch 15 batch 170/185 loss = 0.0126\n",
      "epoch 15 batch 171/185 loss = 0.0132\n",
      "epoch 15 batch 172/185 loss = 0.0124\n",
      "epoch 15 batch 173/185 loss = 0.0102\n",
      "epoch 15 batch 174/185 loss = 0.0120\n",
      "epoch 15 batch 175/185 loss = 0.0137\n",
      "epoch 15 batch 176/185 loss = 0.0119\n",
      "epoch 15 batch 177/185 loss = 0.0122\n",
      "epoch 15 batch 178/185 loss = 0.0124\n",
      "epoch 15 batch 179/185 loss = 0.0142\n",
      "epoch 15 batch 180/185 loss = 0.0118\n",
      "epoch 15 batch 181/185 loss = 0.0116\n",
      "epoch 15 batch 182/185 loss = 0.0111\n",
      "epoch 15 batch 183/185 loss = 0.0125\n",
      "epoch 15 batch 184/185 loss = 0.0106\n",
      "epoch 15 batch 185/185 loss = 0.0121\n",
      "epoch 15 train loss = 0.0116 valid loss = 0.0196\n",
      "performance reducing: counter 2\n",
      "epoch 16 batch 1/185 loss = 0.0117\n",
      "epoch 16 batch 2/185 loss = 0.0125\n",
      "epoch 16 batch 3/185 loss = 0.0124\n",
      "epoch 16 batch 4/185 loss = 0.0128\n",
      "epoch 16 batch 5/185 loss = 0.0096\n",
      "epoch 16 batch 6/185 loss = 0.0109\n",
      "epoch 16 batch 7/185 loss = 0.0115\n",
      "epoch 16 batch 8/185 loss = 0.0092\n",
      "epoch 16 batch 9/185 loss = 0.0127\n",
      "epoch 16 batch 10/185 loss = 0.0095\n",
      "epoch 16 batch 11/185 loss = 0.0117\n",
      "epoch 16 batch 12/185 loss = 0.0116\n",
      "epoch 16 batch 13/185 loss = 0.0120\n",
      "epoch 16 batch 14/185 loss = 0.0107\n",
      "epoch 16 batch 15/185 loss = 0.0118\n",
      "epoch 16 batch 16/185 loss = 0.0126\n",
      "epoch 16 batch 17/185 loss = 0.0101\n",
      "epoch 16 batch 18/185 loss = 0.0110\n",
      "epoch 16 batch 19/185 loss = 0.0147\n",
      "epoch 16 batch 20/185 loss = 0.0135\n",
      "epoch 16 batch 21/185 loss = 0.0088\n",
      "epoch 16 batch 22/185 loss = 0.0137\n",
      "epoch 16 batch 23/185 loss = 0.0108\n",
      "epoch 16 batch 24/185 loss = 0.0126\n",
      "epoch 16 batch 25/185 loss = 0.0115\n",
      "epoch 16 batch 26/185 loss = 0.0174\n",
      "epoch 16 batch 27/185 loss = 0.0090\n",
      "epoch 16 batch 28/185 loss = 0.0136\n",
      "epoch 16 batch 29/185 loss = 0.0116\n",
      "epoch 16 batch 30/185 loss = 0.0119\n",
      "epoch 16 batch 31/185 loss = 0.0113\n",
      "epoch 16 batch 32/185 loss = 0.0120\n",
      "epoch 16 batch 33/185 loss = 0.0115\n",
      "epoch 16 batch 34/185 loss = 0.0094\n",
      "epoch 16 batch 35/185 loss = 0.0110\n",
      "epoch 16 batch 36/185 loss = 0.0115\n",
      "epoch 16 batch 37/185 loss = 0.0113\n",
      "epoch 16 batch 38/185 loss = 0.0109\n",
      "epoch 16 batch 39/185 loss = 0.0114\n",
      "epoch 16 batch 40/185 loss = 0.0109\n",
      "epoch 16 batch 41/185 loss = 0.0128\n",
      "epoch 16 batch 42/185 loss = 0.0106\n",
      "epoch 16 batch 43/185 loss = 0.0127\n",
      "epoch 16 batch 44/185 loss = 0.0110\n",
      "epoch 16 batch 45/185 loss = 0.0120\n",
      "epoch 16 batch 46/185 loss = 0.0128\n",
      "epoch 16 batch 47/185 loss = 0.0105\n",
      "epoch 16 batch 48/185 loss = 0.0144\n",
      "epoch 16 batch 49/185 loss = 0.0132\n",
      "epoch 16 batch 50/185 loss = 0.0105\n",
      "epoch 16 batch 51/185 loss = 0.0105\n",
      "epoch 16 batch 52/185 loss = 0.0099\n",
      "epoch 16 batch 53/185 loss = 0.0101\n",
      "epoch 16 batch 54/185 loss = 0.0112\n",
      "epoch 16 batch 55/185 loss = 0.0139\n",
      "epoch 16 batch 56/185 loss = 0.0119\n",
      "epoch 16 batch 57/185 loss = 0.0119\n",
      "epoch 16 batch 58/185 loss = 0.0110\n",
      "epoch 16 batch 59/185 loss = 0.0095\n",
      "epoch 16 batch 60/185 loss = 0.0100\n",
      "epoch 16 batch 61/185 loss = 0.0100\n",
      "epoch 16 batch 62/185 loss = 0.0152\n",
      "epoch 16 batch 63/185 loss = 0.0103\n",
      "epoch 16 batch 64/185 loss = 0.0117\n",
      "epoch 16 batch 65/185 loss = 0.0121\n",
      "epoch 16 batch 66/185 loss = 0.0087\n",
      "epoch 16 batch 67/185 loss = 0.0127\n",
      "epoch 16 batch 68/185 loss = 0.0091\n",
      "epoch 16 batch 69/185 loss = 0.0101\n",
      "epoch 16 batch 70/185 loss = 0.0099\n",
      "epoch 16 batch 71/185 loss = 0.0113\n",
      "epoch 16 batch 72/185 loss = 0.0115\n",
      "epoch 16 batch 73/185 loss = 0.0097\n",
      "epoch 16 batch 74/185 loss = 0.0112\n",
      "epoch 16 batch 75/185 loss = 0.0122\n",
      "epoch 16 batch 76/185 loss = 0.0122\n",
      "epoch 16 batch 77/185 loss = 0.0145\n",
      "epoch 16 batch 78/185 loss = 0.0115\n",
      "epoch 16 batch 79/185 loss = 0.0116\n",
      "epoch 16 batch 80/185 loss = 0.0126\n",
      "epoch 16 batch 81/185 loss = 0.0099\n",
      "epoch 16 batch 82/185 loss = 0.0104\n",
      "epoch 16 batch 83/185 loss = 0.0117\n",
      "epoch 16 batch 84/185 loss = 0.0106\n",
      "epoch 16 batch 85/185 loss = 0.0090\n",
      "epoch 16 batch 86/185 loss = 0.0103\n",
      "epoch 16 batch 87/185 loss = 0.0113\n",
      "epoch 16 batch 88/185 loss = 0.0131\n",
      "epoch 16 batch 89/185 loss = 0.0125\n",
      "epoch 16 batch 90/185 loss = 0.0106\n",
      "epoch 16 batch 91/185 loss = 0.0115\n",
      "epoch 16 batch 92/185 loss = 0.0097\n",
      "epoch 16 batch 93/185 loss = 0.0122\n",
      "epoch 16 batch 94/185 loss = 0.0124\n",
      "epoch 16 batch 95/185 loss = 0.0091\n",
      "epoch 16 batch 96/185 loss = 0.0132\n",
      "epoch 16 batch 97/185 loss = 0.0115\n",
      "epoch 16 batch 98/185 loss = 0.0118\n",
      "epoch 16 batch 99/185 loss = 0.0103\n",
      "epoch 16 batch 100/185 loss = 0.0152\n",
      "epoch 16 batch 101/185 loss = 0.0132\n",
      "epoch 16 batch 102/185 loss = 0.0129\n",
      "epoch 16 batch 103/185 loss = 0.0107\n",
      "epoch 16 batch 104/185 loss = 0.0134\n",
      "epoch 16 batch 105/185 loss = 0.0101\n",
      "epoch 16 batch 106/185 loss = 0.0130\n",
      "epoch 16 batch 107/185 loss = 0.0111\n",
      "epoch 16 batch 108/185 loss = 0.0124\n",
      "epoch 16 batch 109/185 loss = 0.0127\n",
      "epoch 16 batch 110/185 loss = 0.0130\n",
      "epoch 16 batch 111/185 loss = 0.0121\n",
      "epoch 16 batch 112/185 loss = 0.0095\n",
      "epoch 16 batch 113/185 loss = 0.0132\n",
      "epoch 16 batch 114/185 loss = 0.0097\n",
      "epoch 16 batch 115/185 loss = 0.0114\n",
      "epoch 16 batch 116/185 loss = 0.0087\n",
      "epoch 16 batch 117/185 loss = 0.0104\n",
      "epoch 16 batch 118/185 loss = 0.0098\n",
      "epoch 16 batch 119/185 loss = 0.0114\n",
      "epoch 16 batch 120/185 loss = 0.0103\n",
      "epoch 16 batch 121/185 loss = 0.0087\n",
      "epoch 16 batch 122/185 loss = 0.0110\n",
      "epoch 16 batch 123/185 loss = 0.0094\n",
      "epoch 16 batch 124/185 loss = 0.0124\n",
      "epoch 16 batch 125/185 loss = 0.0105\n",
      "epoch 16 batch 126/185 loss = 0.0134\n",
      "epoch 16 batch 127/185 loss = 0.0128\n",
      "epoch 16 batch 128/185 loss = 0.0137\n",
      "epoch 16 batch 129/185 loss = 0.0094\n",
      "epoch 16 batch 130/185 loss = 0.0105\n",
      "epoch 16 batch 131/185 loss = 0.0112\n",
      "epoch 16 batch 132/185 loss = 0.0105\n",
      "epoch 16 batch 133/185 loss = 0.0120\n",
      "epoch 16 batch 134/185 loss = 0.0134\n",
      "epoch 16 batch 135/185 loss = 0.0126\n",
      "epoch 16 batch 136/185 loss = 0.0124\n",
      "epoch 16 batch 137/185 loss = 0.0114\n",
      "epoch 16 batch 138/185 loss = 0.0091\n",
      "epoch 16 batch 139/185 loss = 0.0126\n",
      "epoch 16 batch 140/185 loss = 0.0116\n",
      "epoch 16 batch 141/185 loss = 0.0121\n",
      "epoch 16 batch 142/185 loss = 0.0124\n",
      "epoch 16 batch 143/185 loss = 0.0118\n",
      "epoch 16 batch 144/185 loss = 0.0123\n",
      "epoch 16 batch 145/185 loss = 0.0109\n",
      "epoch 16 batch 146/185 loss = 0.0105\n",
      "epoch 16 batch 147/185 loss = 0.0099\n",
      "epoch 16 batch 148/185 loss = 0.0104\n",
      "epoch 16 batch 149/185 loss = 0.0101\n",
      "epoch 16 batch 150/185 loss = 0.0127\n",
      "epoch 16 batch 151/185 loss = 0.0108\n",
      "epoch 16 batch 152/185 loss = 0.0126\n",
      "epoch 16 batch 153/185 loss = 0.0103\n",
      "epoch 16 batch 154/185 loss = 0.0102\n",
      "epoch 16 batch 155/185 loss = 0.0135\n",
      "epoch 16 batch 156/185 loss = 0.0110\n",
      "epoch 16 batch 157/185 loss = 0.0114\n",
      "epoch 16 batch 158/185 loss = 0.0135\n",
      "epoch 16 batch 159/185 loss = 0.0102\n",
      "epoch 16 batch 160/185 loss = 0.0126\n",
      "epoch 16 batch 161/185 loss = 0.0110\n",
      "epoch 16 batch 162/185 loss = 0.0128\n",
      "epoch 16 batch 163/185 loss = 0.0120\n",
      "epoch 16 batch 164/185 loss = 0.0123\n",
      "epoch 16 batch 165/185 loss = 0.0127\n",
      "epoch 16 batch 166/185 loss = 0.0116\n",
      "epoch 16 batch 167/185 loss = 0.0119\n",
      "epoch 16 batch 168/185 loss = 0.0109\n",
      "epoch 16 batch 169/185 loss = 0.0100\n",
      "epoch 16 batch 170/185 loss = 0.0116\n",
      "epoch 16 batch 171/185 loss = 0.0132\n",
      "epoch 16 batch 172/185 loss = 0.0128\n",
      "epoch 16 batch 173/185 loss = 0.0100\n",
      "epoch 16 batch 174/185 loss = 0.0112\n",
      "epoch 16 batch 175/185 loss = 0.0107\n",
      "epoch 16 batch 176/185 loss = 0.0122\n",
      "epoch 16 batch 177/185 loss = 0.0119\n",
      "epoch 16 batch 178/185 loss = 0.0103\n",
      "epoch 16 batch 179/185 loss = 0.0129\n",
      "epoch 16 batch 180/185 loss = 0.0101\n",
      "epoch 16 batch 181/185 loss = 0.0116\n",
      "epoch 16 batch 182/185 loss = 0.0113\n",
      "epoch 16 batch 183/185 loss = 0.0128\n",
      "epoch 16 batch 184/185 loss = 0.0100\n",
      "epoch 16 batch 185/185 loss = 0.0120\n",
      "epoch 16 train loss = 0.0115 valid loss = 0.0245\n",
      "performance reducing: counter 3\n",
      "epoch 17 batch 1/185 loss = 0.0102\n",
      "epoch 17 batch 2/185 loss = 0.0138\n",
      "epoch 17 batch 3/185 loss = 0.0091\n",
      "epoch 17 batch 4/185 loss = 0.0122\n",
      "epoch 17 batch 5/185 loss = 0.0103\n",
      "epoch 17 batch 6/185 loss = 0.0093\n",
      "epoch 17 batch 7/185 loss = 0.0091\n",
      "epoch 17 batch 8/185 loss = 0.0106\n",
      "epoch 17 batch 9/185 loss = 0.0089\n",
      "epoch 17 batch 10/185 loss = 0.0133\n",
      "epoch 17 batch 11/185 loss = 0.0110\n",
      "epoch 17 batch 12/185 loss = 0.0095\n",
      "epoch 17 batch 13/185 loss = 0.0127\n",
      "epoch 17 batch 14/185 loss = 0.0114\n",
      "epoch 17 batch 15/185 loss = 0.0135\n",
      "epoch 17 batch 16/185 loss = 0.0104\n",
      "epoch 17 batch 17/185 loss = 0.0118\n",
      "epoch 17 batch 18/185 loss = 0.0106\n",
      "epoch 17 batch 19/185 loss = 0.0114\n",
      "epoch 17 batch 20/185 loss = 0.0136\n",
      "epoch 17 batch 21/185 loss = 0.0114\n",
      "epoch 17 batch 22/185 loss = 0.0127\n",
      "epoch 17 batch 23/185 loss = 0.0126\n",
      "epoch 17 batch 24/185 loss = 0.0115\n",
      "epoch 17 batch 25/185 loss = 0.0095\n",
      "epoch 17 batch 26/185 loss = 0.0134\n",
      "epoch 17 batch 27/185 loss = 0.0151\n",
      "epoch 17 batch 28/185 loss = 0.0118\n",
      "epoch 17 batch 29/185 loss = 0.0113\n",
      "epoch 17 batch 30/185 loss = 0.0115\n",
      "epoch 17 batch 31/185 loss = 0.0086\n",
      "epoch 17 batch 32/185 loss = 0.0094\n",
      "epoch 17 batch 33/185 loss = 0.0087\n",
      "epoch 17 batch 34/185 loss = 0.0104\n",
      "epoch 17 batch 35/185 loss = 0.0117\n",
      "epoch 17 batch 36/185 loss = 0.0088\n",
      "epoch 17 batch 37/185 loss = 0.0101\n",
      "epoch 17 batch 38/185 loss = 0.0125\n",
      "epoch 17 batch 39/185 loss = 0.0085\n",
      "epoch 17 batch 40/185 loss = 0.0124\n",
      "epoch 17 batch 41/185 loss = 0.0096\n",
      "epoch 17 batch 42/185 loss = 0.0120\n",
      "epoch 17 batch 43/185 loss = 0.0135\n",
      "epoch 17 batch 44/185 loss = 0.0104\n",
      "epoch 17 batch 45/185 loss = 0.0104\n",
      "epoch 17 batch 46/185 loss = 0.0117\n",
      "epoch 17 batch 47/185 loss = 0.0110\n",
      "epoch 17 batch 48/185 loss = 0.0111\n",
      "epoch 17 batch 49/185 loss = 0.0110\n",
      "epoch 17 batch 50/185 loss = 0.0147\n",
      "epoch 17 batch 51/185 loss = 0.0100\n",
      "epoch 17 batch 52/185 loss = 0.0142\n",
      "epoch 17 batch 53/185 loss = 0.0114\n",
      "epoch 17 batch 54/185 loss = 0.0167\n",
      "epoch 17 batch 55/185 loss = 0.0097\n",
      "epoch 17 batch 56/185 loss = 0.0102\n",
      "epoch 17 batch 57/185 loss = 0.0115\n",
      "epoch 17 batch 58/185 loss = 0.0121\n",
      "epoch 17 batch 59/185 loss = 0.0109\n",
      "epoch 17 batch 60/185 loss = 0.0102\n",
      "epoch 17 batch 61/185 loss = 0.0108\n",
      "epoch 17 batch 62/185 loss = 0.0106\n",
      "epoch 17 batch 63/185 loss = 0.0116\n",
      "epoch 17 batch 64/185 loss = 0.0105\n",
      "epoch 17 batch 65/185 loss = 0.0095\n",
      "epoch 17 batch 66/185 loss = 0.0121\n",
      "epoch 17 batch 67/185 loss = 0.0108\n",
      "epoch 17 batch 68/185 loss = 0.0097\n",
      "epoch 17 batch 69/185 loss = 0.0098\n",
      "epoch 17 batch 70/185 loss = 0.0110\n",
      "epoch 17 batch 71/185 loss = 0.0116\n",
      "epoch 17 batch 72/185 loss = 0.0105\n",
      "epoch 17 batch 73/185 loss = 0.0098\n",
      "epoch 17 batch 74/185 loss = 0.0088\n",
      "epoch 17 batch 75/185 loss = 0.0130\n",
      "epoch 17 batch 76/185 loss = 0.0126\n",
      "epoch 17 batch 77/185 loss = 0.0118\n",
      "epoch 17 batch 78/185 loss = 0.0114\n",
      "epoch 17 batch 79/185 loss = 0.0089\n",
      "epoch 17 batch 80/185 loss = 0.0123\n",
      "epoch 17 batch 81/185 loss = 0.0114\n",
      "epoch 17 batch 82/185 loss = 0.0138\n",
      "epoch 17 batch 83/185 loss = 0.0140\n",
      "epoch 17 batch 84/185 loss = 0.0143\n",
      "epoch 17 batch 85/185 loss = 0.0125\n",
      "epoch 17 batch 86/185 loss = 0.0112\n",
      "epoch 17 batch 87/185 loss = 0.0105\n",
      "epoch 17 batch 88/185 loss = 0.0135\n",
      "epoch 17 batch 89/185 loss = 0.0126\n",
      "epoch 17 batch 90/185 loss = 0.0131\n",
      "epoch 17 batch 91/185 loss = 0.0125\n",
      "epoch 17 batch 92/185 loss = 0.0117\n",
      "epoch 17 batch 93/185 loss = 0.0127\n",
      "epoch 17 batch 94/185 loss = 0.0106\n",
      "epoch 17 batch 95/185 loss = 0.0121\n",
      "epoch 17 batch 96/185 loss = 0.0106\n",
      "epoch 17 batch 97/185 loss = 0.0092\n",
      "epoch 17 batch 98/185 loss = 0.0113\n",
      "epoch 17 batch 99/185 loss = 0.0099\n",
      "epoch 17 batch 100/185 loss = 0.0124\n",
      "epoch 17 batch 101/185 loss = 0.0120\n",
      "epoch 17 batch 102/185 loss = 0.0106\n",
      "epoch 17 batch 103/185 loss = 0.0099\n",
      "epoch 17 batch 104/185 loss = 0.0130\n",
      "epoch 17 batch 105/185 loss = 0.0121\n",
      "epoch 17 batch 106/185 loss = 0.0115\n",
      "epoch 17 batch 107/185 loss = 0.0105\n",
      "epoch 17 batch 108/185 loss = 0.0131\n",
      "epoch 17 batch 109/185 loss = 0.0107\n",
      "epoch 17 batch 110/185 loss = 0.0108\n",
      "epoch 17 batch 111/185 loss = 0.0107\n",
      "epoch 17 batch 112/185 loss = 0.0136\n",
      "epoch 17 batch 113/185 loss = 0.0117\n",
      "epoch 17 batch 114/185 loss = 0.0109\n",
      "epoch 17 batch 115/185 loss = 0.0128\n",
      "epoch 17 batch 116/185 loss = 0.0117\n",
      "epoch 17 batch 117/185 loss = 0.0127\n",
      "epoch 17 batch 118/185 loss = 0.0105\n",
      "epoch 17 batch 119/185 loss = 0.0127\n",
      "epoch 17 batch 120/185 loss = 0.0123\n",
      "epoch 17 batch 121/185 loss = 0.0135\n",
      "epoch 17 batch 122/185 loss = 0.0128\n",
      "epoch 17 batch 123/185 loss = 0.0124\n",
      "epoch 17 batch 124/185 loss = 0.0136\n",
      "epoch 17 batch 125/185 loss = 0.0100\n",
      "epoch 17 batch 126/185 loss = 0.0133\n",
      "epoch 17 batch 127/185 loss = 0.0116\n",
      "epoch 17 batch 128/185 loss = 0.0118\n",
      "epoch 17 batch 129/185 loss = 0.0102\n",
      "epoch 17 batch 130/185 loss = 0.0127\n",
      "epoch 17 batch 131/185 loss = 0.0102\n",
      "epoch 17 batch 132/185 loss = 0.0126\n",
      "epoch 17 batch 133/185 loss = 0.0126\n",
      "epoch 17 batch 134/185 loss = 0.0104\n",
      "epoch 17 batch 135/185 loss = 0.0094\n",
      "epoch 17 batch 136/185 loss = 0.0124\n",
      "epoch 17 batch 137/185 loss = 0.0149\n",
      "epoch 17 batch 138/185 loss = 0.0139\n",
      "epoch 17 batch 139/185 loss = 0.0112\n",
      "epoch 17 batch 140/185 loss = 0.0125\n",
      "epoch 17 batch 141/185 loss = 0.0129\n",
      "epoch 17 batch 142/185 loss = 0.0109\n",
      "epoch 17 batch 143/185 loss = 0.0128\n",
      "epoch 17 batch 144/185 loss = 0.0115\n",
      "epoch 17 batch 145/185 loss = 0.0091\n",
      "epoch 17 batch 146/185 loss = 0.0123\n",
      "epoch 17 batch 147/185 loss = 0.0108\n",
      "epoch 17 batch 148/185 loss = 0.0124\n",
      "epoch 17 batch 149/185 loss = 0.0114\n",
      "epoch 17 batch 150/185 loss = 0.0113\n",
      "epoch 17 batch 151/185 loss = 0.0120\n",
      "epoch 17 batch 152/185 loss = 0.0126\n",
      "epoch 17 batch 153/185 loss = 0.0108\n",
      "epoch 17 batch 154/185 loss = 0.0100\n",
      "epoch 17 batch 155/185 loss = 0.0109\n",
      "epoch 17 batch 156/185 loss = 0.0130\n",
      "epoch 17 batch 157/185 loss = 0.0108\n",
      "epoch 17 batch 158/185 loss = 0.0089\n",
      "epoch 17 batch 159/185 loss = 0.0103\n",
      "epoch 17 batch 160/185 loss = 0.0110\n",
      "epoch 17 batch 161/185 loss = 0.0122\n",
      "epoch 17 batch 162/185 loss = 0.0104\n",
      "epoch 17 batch 163/185 loss = 0.0119\n",
      "epoch 17 batch 164/185 loss = 0.0107\n",
      "epoch 17 batch 165/185 loss = 0.0102\n",
      "epoch 17 batch 166/185 loss = 0.0126\n",
      "epoch 17 batch 167/185 loss = 0.0108\n",
      "epoch 17 batch 168/185 loss = 0.0102\n",
      "epoch 17 batch 169/185 loss = 0.0135\n",
      "epoch 17 batch 170/185 loss = 0.0127\n",
      "epoch 17 batch 171/185 loss = 0.0109\n",
      "epoch 17 batch 172/185 loss = 0.0114\n",
      "epoch 17 batch 173/185 loss = 0.0086\n",
      "epoch 17 batch 174/185 loss = 0.0137\n",
      "epoch 17 batch 175/185 loss = 0.0095\n",
      "epoch 17 batch 176/185 loss = 0.0124\n",
      "epoch 17 batch 177/185 loss = 0.0106\n",
      "epoch 17 batch 178/185 loss = 0.0098\n",
      "epoch 17 batch 179/185 loss = 0.0124\n",
      "epoch 17 batch 180/185 loss = 0.0129\n",
      "epoch 17 batch 181/185 loss = 0.0115\n",
      "epoch 17 batch 182/185 loss = 0.0125\n",
      "epoch 17 batch 183/185 loss = 0.0111\n",
      "epoch 17 batch 184/185 loss = 0.0098\n",
      "epoch 17 batch 185/185 loss = 0.0100\n",
      "epoch 17 train loss = 0.0114 valid loss = 0.0193\n",
      "performance reducing: counter 4\n",
      "epoch 18 batch 1/185 loss = 0.0107\n",
      "epoch 18 batch 2/185 loss = 0.0113\n",
      "epoch 18 batch 3/185 loss = 0.0116\n",
      "epoch 18 batch 4/185 loss = 0.0118\n",
      "epoch 18 batch 5/185 loss = 0.0116\n",
      "epoch 18 batch 6/185 loss = 0.0120\n",
      "epoch 18 batch 7/185 loss = 0.0119\n",
      "epoch 18 batch 8/185 loss = 0.0107\n",
      "epoch 18 batch 9/185 loss = 0.0107\n",
      "epoch 18 batch 10/185 loss = 0.0101\n",
      "epoch 18 batch 11/185 loss = 0.0119\n",
      "epoch 18 batch 12/185 loss = 0.0111\n",
      "epoch 18 batch 13/185 loss = 0.0109\n",
      "epoch 18 batch 14/185 loss = 0.0114\n",
      "epoch 18 batch 15/185 loss = 0.0106\n",
      "epoch 18 batch 16/185 loss = 0.0114\n",
      "epoch 18 batch 17/185 loss = 0.0100\n",
      "epoch 18 batch 18/185 loss = 0.0105\n",
      "epoch 18 batch 19/185 loss = 0.0094\n",
      "epoch 18 batch 20/185 loss = 0.0111\n",
      "epoch 18 batch 21/185 loss = 0.0108\n",
      "epoch 18 batch 22/185 loss = 0.0087\n",
      "epoch 18 batch 23/185 loss = 0.0115\n",
      "epoch 18 batch 24/185 loss = 0.0091\n",
      "epoch 18 batch 25/185 loss = 0.0113\n",
      "epoch 18 batch 26/185 loss = 0.0122\n",
      "epoch 18 batch 27/185 loss = 0.0100\n",
      "epoch 18 batch 28/185 loss = 0.0103\n",
      "epoch 18 batch 29/185 loss = 0.0114\n",
      "epoch 18 batch 30/185 loss = 0.0100\n",
      "epoch 18 batch 31/185 loss = 0.0130\n",
      "epoch 18 batch 32/185 loss = 0.0115\n",
      "epoch 18 batch 33/185 loss = 0.0115\n",
      "epoch 18 batch 34/185 loss = 0.0116\n",
      "epoch 18 batch 35/185 loss = 0.0111\n",
      "epoch 18 batch 36/185 loss = 0.0109\n",
      "epoch 18 batch 37/185 loss = 0.0086\n",
      "epoch 18 batch 38/185 loss = 0.0099\n",
      "epoch 18 batch 39/185 loss = 0.0093\n",
      "epoch 18 batch 40/185 loss = 0.0090\n",
      "epoch 18 batch 41/185 loss = 0.0109\n",
      "epoch 18 batch 42/185 loss = 0.0124\n",
      "epoch 18 batch 43/185 loss = 0.0110\n",
      "epoch 18 batch 44/185 loss = 0.0135\n",
      "epoch 18 batch 45/185 loss = 0.0115\n",
      "epoch 18 batch 46/185 loss = 0.0115\n",
      "epoch 18 batch 47/185 loss = 0.0131\n",
      "epoch 18 batch 48/185 loss = 0.0120\n",
      "epoch 18 batch 49/185 loss = 0.0105\n",
      "epoch 18 batch 50/185 loss = 0.0099\n",
      "epoch 18 batch 51/185 loss = 0.0123\n",
      "epoch 18 batch 52/185 loss = 0.0112\n",
      "epoch 18 batch 53/185 loss = 0.0093\n",
      "epoch 18 batch 54/185 loss = 0.0136\n",
      "epoch 18 batch 55/185 loss = 0.0124\n",
      "epoch 18 batch 56/185 loss = 0.0106\n",
      "epoch 18 batch 57/185 loss = 0.0117\n",
      "epoch 18 batch 58/185 loss = 0.0085\n",
      "epoch 18 batch 59/185 loss = 0.0127\n",
      "epoch 18 batch 60/185 loss = 0.0128\n",
      "epoch 18 batch 61/185 loss = 0.0113\n",
      "epoch 18 batch 62/185 loss = 0.0098\n",
      "epoch 18 batch 63/185 loss = 0.0131\n",
      "epoch 18 batch 64/185 loss = 0.0104\n",
      "epoch 18 batch 65/185 loss = 0.0100\n",
      "epoch 18 batch 66/185 loss = 0.0121\n",
      "epoch 18 batch 67/185 loss = 0.0133\n",
      "epoch 18 batch 68/185 loss = 0.0108\n",
      "epoch 18 batch 69/185 loss = 0.0118\n",
      "epoch 18 batch 70/185 loss = 0.0142\n",
      "epoch 18 batch 71/185 loss = 0.0123\n",
      "epoch 18 batch 72/185 loss = 0.0161\n",
      "epoch 18 batch 73/185 loss = 0.0106\n",
      "epoch 18 batch 74/185 loss = 0.0124\n",
      "epoch 18 batch 75/185 loss = 0.0103\n",
      "epoch 18 batch 76/185 loss = 0.0125\n",
      "epoch 18 batch 77/185 loss = 0.0097\n",
      "epoch 18 batch 78/185 loss = 0.0127\n",
      "epoch 18 batch 79/185 loss = 0.0146\n",
      "epoch 18 batch 80/185 loss = 0.0140\n",
      "epoch 18 batch 81/185 loss = 0.0095\n",
      "epoch 18 batch 82/185 loss = 0.0146\n",
      "epoch 18 batch 83/185 loss = 0.0108\n",
      "epoch 18 batch 84/185 loss = 0.0112\n",
      "epoch 18 batch 85/185 loss = 0.0102\n",
      "epoch 18 batch 86/185 loss = 0.0135\n",
      "epoch 18 batch 87/185 loss = 0.0127\n",
      "epoch 18 batch 88/185 loss = 0.0125\n",
      "epoch 18 batch 89/185 loss = 0.0097\n",
      "epoch 18 batch 90/185 loss = 0.0114\n",
      "epoch 18 batch 91/185 loss = 0.0123\n",
      "epoch 18 batch 92/185 loss = 0.0106\n",
      "epoch 18 batch 93/185 loss = 0.0089\n",
      "epoch 18 batch 94/185 loss = 0.0102\n",
      "epoch 18 batch 95/185 loss = 0.0117\n",
      "epoch 18 batch 96/185 loss = 0.0120\n",
      "epoch 18 batch 97/185 loss = 0.0141\n",
      "epoch 18 batch 98/185 loss = 0.0105\n",
      "epoch 18 batch 99/185 loss = 0.0118\n",
      "epoch 18 batch 100/185 loss = 0.0088\n",
      "epoch 18 batch 101/185 loss = 0.0122\n",
      "epoch 18 batch 102/185 loss = 0.0106\n",
      "epoch 18 batch 103/185 loss = 0.0110\n",
      "epoch 18 batch 104/185 loss = 0.0113\n",
      "epoch 18 batch 105/185 loss = 0.0112\n",
      "epoch 18 batch 106/185 loss = 0.0121\n",
      "epoch 18 batch 107/185 loss = 0.0115\n",
      "epoch 18 batch 108/185 loss = 0.0094\n",
      "epoch 18 batch 109/185 loss = 0.0104\n",
      "epoch 18 batch 110/185 loss = 0.0090\n",
      "epoch 18 batch 111/185 loss = 0.0097\n",
      "epoch 18 batch 112/185 loss = 0.0114\n",
      "epoch 18 batch 113/185 loss = 0.0102\n",
      "epoch 18 batch 114/185 loss = 0.0113\n",
      "epoch 18 batch 115/185 loss = 0.0117\n",
      "epoch 18 batch 116/185 loss = 0.0118\n",
      "epoch 18 batch 117/185 loss = 0.0108\n",
      "epoch 18 batch 118/185 loss = 0.0114\n",
      "epoch 18 batch 119/185 loss = 0.0113\n",
      "epoch 18 batch 120/185 loss = 0.0100\n",
      "epoch 18 batch 121/185 loss = 0.0102\n",
      "epoch 18 batch 122/185 loss = 0.0083\n",
      "epoch 18 batch 123/185 loss = 0.0117\n",
      "epoch 18 batch 124/185 loss = 0.0110\n",
      "epoch 18 batch 125/185 loss = 0.0105\n",
      "epoch 18 batch 126/185 loss = 0.0083\n",
      "epoch 18 batch 127/185 loss = 0.0116\n",
      "epoch 18 batch 128/185 loss = 0.0133\n",
      "epoch 18 batch 129/185 loss = 0.0106\n",
      "epoch 18 batch 130/185 loss = 0.0147\n",
      "epoch 18 batch 131/185 loss = 0.0094\n",
      "epoch 18 batch 132/185 loss = 0.0087\n",
      "epoch 18 batch 133/185 loss = 0.0086\n",
      "epoch 18 batch 134/185 loss = 0.0117\n",
      "epoch 18 batch 135/185 loss = 0.0113\n",
      "epoch 18 batch 136/185 loss = 0.0137\n",
      "epoch 18 batch 137/185 loss = 0.0113\n",
      "epoch 18 batch 138/185 loss = 0.0114\n",
      "epoch 18 batch 139/185 loss = 0.0128\n",
      "epoch 18 batch 140/185 loss = 0.0121\n",
      "epoch 18 batch 141/185 loss = 0.0095\n",
      "epoch 18 batch 142/185 loss = 0.0101\n",
      "epoch 18 batch 143/185 loss = 0.0113\n",
      "epoch 18 batch 144/185 loss = 0.0115\n",
      "epoch 18 batch 145/185 loss = 0.0108\n",
      "epoch 18 batch 146/185 loss = 0.0123\n",
      "epoch 18 batch 147/185 loss = 0.0121\n",
      "epoch 18 batch 148/185 loss = 0.0119\n",
      "epoch 18 batch 149/185 loss = 0.0111\n",
      "epoch 18 batch 150/185 loss = 0.0135\n",
      "epoch 18 batch 151/185 loss = 0.0129\n",
      "epoch 18 batch 152/185 loss = 0.0132\n",
      "epoch 18 batch 153/185 loss = 0.0101\n",
      "epoch 18 batch 154/185 loss = 0.0121\n",
      "epoch 18 batch 155/185 loss = 0.0123\n",
      "epoch 18 batch 156/185 loss = 0.0113\n",
      "epoch 18 batch 157/185 loss = 0.0125\n",
      "epoch 18 batch 158/185 loss = 0.0117\n",
      "epoch 18 batch 159/185 loss = 0.0127\n",
      "epoch 18 batch 160/185 loss = 0.0129\n",
      "epoch 18 batch 161/185 loss = 0.0093\n",
      "epoch 18 batch 162/185 loss = 0.0110\n",
      "epoch 18 batch 163/185 loss = 0.0122\n",
      "epoch 18 batch 164/185 loss = 0.0094\n",
      "epoch 18 batch 165/185 loss = 0.0115\n",
      "epoch 18 batch 166/185 loss = 0.0116\n",
      "epoch 18 batch 167/185 loss = 0.0115\n",
      "epoch 18 batch 168/185 loss = 0.0112\n",
      "epoch 18 batch 169/185 loss = 0.0104\n",
      "epoch 18 batch 170/185 loss = 0.0131\n",
      "epoch 18 batch 171/185 loss = 0.0103\n",
      "epoch 18 batch 172/185 loss = 0.0099\n",
      "epoch 18 batch 173/185 loss = 0.0084\n",
      "epoch 18 batch 174/185 loss = 0.0109\n",
      "epoch 18 batch 175/185 loss = 0.0093\n",
      "epoch 18 batch 176/185 loss = 0.0100\n",
      "epoch 18 batch 177/185 loss = 0.0138\n",
      "epoch 18 batch 178/185 loss = 0.0101\n",
      "epoch 18 batch 179/185 loss = 0.0127\n",
      "epoch 18 batch 180/185 loss = 0.0130\n",
      "epoch 18 batch 181/185 loss = 0.0153\n",
      "epoch 18 batch 182/185 loss = 0.0110\n",
      "epoch 18 batch 183/185 loss = 0.0111\n",
      "epoch 18 batch 184/185 loss = 0.0106\n",
      "epoch 18 batch 185/185 loss = 0.0096\n",
      "epoch 18 train loss = 0.0113 valid loss = 0.0208\n",
      "performance reducing: counter 5\n",
      "epoch 19 batch 1/185 loss = 0.0100\n",
      "epoch 19 batch 2/185 loss = 0.0093\n",
      "epoch 19 batch 3/185 loss = 0.0094\n",
      "epoch 19 batch 4/185 loss = 0.0121\n",
      "epoch 19 batch 5/185 loss = 0.0127\n",
      "epoch 19 batch 6/185 loss = 0.0121\n",
      "epoch 19 batch 7/185 loss = 0.0091\n",
      "epoch 19 batch 8/185 loss = 0.0103\n",
      "epoch 19 batch 9/185 loss = 0.0106\n",
      "epoch 19 batch 10/185 loss = 0.0127\n",
      "epoch 19 batch 11/185 loss = 0.0105\n",
      "epoch 19 batch 12/185 loss = 0.0087\n",
      "epoch 19 batch 13/185 loss = 0.0113\n",
      "epoch 19 batch 14/185 loss = 0.0100\n",
      "epoch 19 batch 15/185 loss = 0.0117\n",
      "epoch 19 batch 16/185 loss = 0.0096\n",
      "epoch 19 batch 17/185 loss = 0.0106\n",
      "epoch 19 batch 18/185 loss = 0.0116\n",
      "epoch 19 batch 19/185 loss = 0.0124\n",
      "epoch 19 batch 20/185 loss = 0.0092\n",
      "epoch 19 batch 21/185 loss = 0.0111\n",
      "epoch 19 batch 22/185 loss = 0.0109\n",
      "epoch 19 batch 23/185 loss = 0.0094\n",
      "epoch 19 batch 24/185 loss = 0.0092\n",
      "epoch 19 batch 25/185 loss = 0.0104\n",
      "epoch 19 batch 26/185 loss = 0.0126\n",
      "epoch 19 batch 27/185 loss = 0.0111\n",
      "epoch 19 batch 28/185 loss = 0.0088\n",
      "epoch 19 batch 29/185 loss = 0.0122\n",
      "epoch 19 batch 30/185 loss = 0.0096\n",
      "epoch 19 batch 31/185 loss = 0.0132\n",
      "epoch 19 batch 32/185 loss = 0.0115\n",
      "epoch 19 batch 33/185 loss = 0.0104\n",
      "epoch 19 batch 34/185 loss = 0.0118\n",
      "epoch 19 batch 35/185 loss = 0.0108\n",
      "epoch 19 batch 36/185 loss = 0.0103\n",
      "epoch 19 batch 37/185 loss = 0.0110\n",
      "epoch 19 batch 38/185 loss = 0.0104\n",
      "epoch 19 batch 39/185 loss = 0.0117\n",
      "epoch 19 batch 40/185 loss = 0.0093\n",
      "epoch 19 batch 41/185 loss = 0.0086\n",
      "epoch 19 batch 42/185 loss = 0.0095\n",
      "epoch 19 batch 43/185 loss = 0.0114\n",
      "epoch 19 batch 44/185 loss = 0.0099\n",
      "epoch 19 batch 45/185 loss = 0.0126\n",
      "epoch 19 batch 46/185 loss = 0.0090\n",
      "epoch 19 batch 47/185 loss = 0.0112\n",
      "epoch 19 batch 48/185 loss = 0.0114\n",
      "epoch 19 batch 49/185 loss = 0.0109\n",
      "epoch 19 batch 50/185 loss = 0.0117\n",
      "epoch 19 batch 51/185 loss = 0.0086\n",
      "epoch 19 batch 52/185 loss = 0.0137\n",
      "epoch 19 batch 53/185 loss = 0.0111\n",
      "epoch 19 batch 54/185 loss = 0.0102\n",
      "epoch 19 batch 55/185 loss = 0.0103\n",
      "epoch 19 batch 56/185 loss = 0.0135\n",
      "epoch 19 batch 57/185 loss = 0.0144\n",
      "epoch 19 batch 58/185 loss = 0.0119\n",
      "epoch 19 batch 59/185 loss = 0.0100\n",
      "epoch 19 batch 60/185 loss = 0.0123\n",
      "epoch 19 batch 61/185 loss = 0.0111\n",
      "epoch 19 batch 62/185 loss = 0.0115\n",
      "epoch 19 batch 63/185 loss = 0.0113\n",
      "epoch 19 batch 64/185 loss = 0.0093\n",
      "epoch 19 batch 65/185 loss = 0.0109\n",
      "epoch 19 batch 66/185 loss = 0.0094\n",
      "epoch 19 batch 67/185 loss = 0.0086\n",
      "epoch 19 batch 68/185 loss = 0.0119\n",
      "epoch 19 batch 69/185 loss = 0.0098\n",
      "epoch 19 batch 70/185 loss = 0.0125\n",
      "epoch 19 batch 71/185 loss = 0.0085\n",
      "epoch 19 batch 72/185 loss = 0.0108\n",
      "epoch 19 batch 73/185 loss = 0.0125\n",
      "epoch 19 batch 74/185 loss = 0.0121\n",
      "epoch 19 batch 75/185 loss = 0.0128\n",
      "epoch 19 batch 76/185 loss = 0.0095\n",
      "epoch 19 batch 77/185 loss = 0.0110\n",
      "epoch 19 batch 78/185 loss = 0.0110\n",
      "epoch 19 batch 79/185 loss = 0.0107\n",
      "epoch 19 batch 80/185 loss = 0.0098\n",
      "epoch 19 batch 81/185 loss = 0.0126\n",
      "epoch 19 batch 82/185 loss = 0.0110\n",
      "epoch 19 batch 83/185 loss = 0.0103\n",
      "epoch 19 batch 84/185 loss = 0.0108\n",
      "epoch 19 batch 85/185 loss = 0.0112\n",
      "epoch 19 batch 86/185 loss = 0.0100\n",
      "epoch 19 batch 87/185 loss = 0.0124\n",
      "epoch 19 batch 88/185 loss = 0.0141\n",
      "epoch 19 batch 89/185 loss = 0.0098\n",
      "epoch 19 batch 90/185 loss = 0.0099\n",
      "epoch 19 batch 91/185 loss = 0.0113\n",
      "epoch 19 batch 92/185 loss = 0.0134\n",
      "epoch 19 batch 93/185 loss = 0.0129\n",
      "epoch 19 batch 94/185 loss = 0.0101\n",
      "epoch 19 batch 95/185 loss = 0.0116\n",
      "epoch 19 batch 96/185 loss = 0.0100\n",
      "epoch 19 batch 97/185 loss = 0.0109\n",
      "epoch 19 batch 98/185 loss = 0.0143\n",
      "epoch 19 batch 99/185 loss = 0.0132\n",
      "epoch 19 batch 100/185 loss = 0.0158\n",
      "epoch 19 batch 101/185 loss = 0.0117\n",
      "epoch 19 batch 102/185 loss = 0.0123\n",
      "epoch 19 batch 103/185 loss = 0.0131\n",
      "epoch 19 batch 104/185 loss = 0.0119\n",
      "epoch 19 batch 105/185 loss = 0.0132\n",
      "epoch 19 batch 106/185 loss = 0.0115\n",
      "epoch 19 batch 107/185 loss = 0.0112\n",
      "epoch 19 batch 108/185 loss = 0.0098\n",
      "epoch 19 batch 109/185 loss = 0.0154\n",
      "epoch 19 batch 110/185 loss = 0.0132\n",
      "epoch 19 batch 111/185 loss = 0.0123\n",
      "epoch 19 batch 112/185 loss = 0.0128\n",
      "epoch 19 batch 113/185 loss = 0.0116\n",
      "epoch 19 batch 114/185 loss = 0.0120\n",
      "epoch 19 batch 115/185 loss = 0.0111\n",
      "epoch 19 batch 116/185 loss = 0.0110\n",
      "epoch 19 batch 117/185 loss = 0.0120\n",
      "epoch 19 batch 118/185 loss = 0.0097\n",
      "epoch 19 batch 119/185 loss = 0.0113\n",
      "epoch 19 batch 120/185 loss = 0.0079\n",
      "epoch 19 batch 121/185 loss = 0.0126\n",
      "epoch 19 batch 122/185 loss = 0.0121\n",
      "epoch 19 batch 123/185 loss = 0.0119\n",
      "epoch 19 batch 124/185 loss = 0.0137\n",
      "epoch 19 batch 125/185 loss = 0.0173\n",
      "epoch 19 batch 126/185 loss = 0.0112\n",
      "epoch 19 batch 127/185 loss = 0.0089\n",
      "epoch 19 batch 128/185 loss = 0.0121\n",
      "epoch 19 batch 129/185 loss = 0.0109\n",
      "epoch 19 batch 130/185 loss = 0.0105\n",
      "epoch 19 batch 131/185 loss = 0.0133\n",
      "epoch 19 batch 132/185 loss = 0.0103\n",
      "epoch 19 batch 133/185 loss = 0.0122\n",
      "epoch 19 batch 134/185 loss = 0.0117\n",
      "epoch 19 batch 135/185 loss = 0.0155\n",
      "epoch 19 batch 136/185 loss = 0.0118\n",
      "epoch 19 batch 137/185 loss = 0.0120\n",
      "epoch 19 batch 138/185 loss = 0.0097\n",
      "epoch 19 batch 139/185 loss = 0.0124\n",
      "epoch 19 batch 140/185 loss = 0.0120\n",
      "epoch 19 batch 141/185 loss = 0.0115\n",
      "epoch 19 batch 142/185 loss = 0.0103\n",
      "epoch 19 batch 143/185 loss = 0.0105\n",
      "epoch 19 batch 144/185 loss = 0.0086\n",
      "epoch 19 batch 145/185 loss = 0.0124\n",
      "epoch 19 batch 146/185 loss = 0.0104\n",
      "epoch 19 batch 147/185 loss = 0.0119\n",
      "epoch 19 batch 148/185 loss = 0.0096\n",
      "epoch 19 batch 149/185 loss = 0.0137\n",
      "epoch 19 batch 150/185 loss = 0.0121\n",
      "epoch 19 batch 151/185 loss = 0.0094\n",
      "epoch 19 batch 152/185 loss = 0.0117\n",
      "epoch 19 batch 153/185 loss = 0.0114\n",
      "epoch 19 batch 154/185 loss = 0.0099\n",
      "epoch 19 batch 155/185 loss = 0.0121\n",
      "epoch 19 batch 156/185 loss = 0.0120\n",
      "epoch 19 batch 157/185 loss = 0.0084\n",
      "epoch 19 batch 158/185 loss = 0.0119\n",
      "epoch 19 batch 159/185 loss = 0.0109\n",
      "epoch 19 batch 160/185 loss = 0.0111\n",
      "epoch 19 batch 161/185 loss = 0.0110\n",
      "epoch 19 batch 162/185 loss = 0.0102\n",
      "epoch 19 batch 163/185 loss = 0.0103\n",
      "epoch 19 batch 164/185 loss = 0.0114\n",
      "epoch 19 batch 165/185 loss = 0.0114\n",
      "epoch 19 batch 166/185 loss = 0.0090\n",
      "epoch 19 batch 167/185 loss = 0.0117\n",
      "epoch 19 batch 168/185 loss = 0.0104\n",
      "epoch 19 batch 169/185 loss = 0.0130\n",
      "epoch 19 batch 170/185 loss = 0.0142\n",
      "epoch 19 batch 171/185 loss = 0.0122\n",
      "epoch 19 batch 172/185 loss = 0.0104\n",
      "epoch 19 batch 173/185 loss = 0.0110\n",
      "epoch 19 batch 174/185 loss = 0.0105\n",
      "epoch 19 batch 175/185 loss = 0.0122\n",
      "epoch 19 batch 176/185 loss = 0.0130\n",
      "epoch 19 batch 177/185 loss = 0.0122\n",
      "epoch 19 batch 178/185 loss = 0.0122\n",
      "epoch 19 batch 179/185 loss = 0.0093\n",
      "epoch 19 batch 180/185 loss = 0.0125\n",
      "epoch 19 batch 181/185 loss = 0.0105\n",
      "epoch 19 batch 182/185 loss = 0.0087\n",
      "epoch 19 batch 183/185 loss = 0.0113\n",
      "epoch 19 batch 184/185 loss = 0.0124\n",
      "epoch 19 batch 185/185 loss = 0.0125\n",
      "epoch 19 train loss = 0.0113 valid loss = 0.0191\n",
      "performance reducing: counter 6\n",
      "epoch 20 batch 1/185 loss = 0.0110\n",
      "epoch 20 batch 2/185 loss = 0.0107\n",
      "epoch 20 batch 3/185 loss = 0.0128\n",
      "epoch 20 batch 4/185 loss = 0.0097\n",
      "epoch 20 batch 5/185 loss = 0.0105\n",
      "epoch 20 batch 6/185 loss = 0.0110\n",
      "epoch 20 batch 7/185 loss = 0.0097\n",
      "epoch 20 batch 8/185 loss = 0.0098\n",
      "epoch 20 batch 9/185 loss = 0.0084\n",
      "epoch 20 batch 10/185 loss = 0.0088\n",
      "epoch 20 batch 11/185 loss = 0.0106\n",
      "epoch 20 batch 12/185 loss = 0.0126\n",
      "epoch 20 batch 13/185 loss = 0.0101\n",
      "epoch 20 batch 14/185 loss = 0.0125\n",
      "epoch 20 batch 15/185 loss = 0.0108\n",
      "epoch 20 batch 16/185 loss = 0.0100\n",
      "epoch 20 batch 17/185 loss = 0.0092\n",
      "epoch 20 batch 18/185 loss = 0.0108\n",
      "epoch 20 batch 19/185 loss = 0.0113\n",
      "epoch 20 batch 20/185 loss = 0.0103\n",
      "epoch 20 batch 21/185 loss = 0.0119\n",
      "epoch 20 batch 22/185 loss = 0.0105\n",
      "epoch 20 batch 23/185 loss = 0.0109\n",
      "epoch 20 batch 24/185 loss = 0.0098\n",
      "epoch 20 batch 25/185 loss = 0.0122\n",
      "epoch 20 batch 26/185 loss = 0.0124\n",
      "epoch 20 batch 27/185 loss = 0.0124\n",
      "epoch 20 batch 28/185 loss = 0.0108\n",
      "epoch 20 batch 29/185 loss = 0.0123\n",
      "epoch 20 batch 30/185 loss = 0.0099\n",
      "epoch 20 batch 31/185 loss = 0.0138\n",
      "epoch 20 batch 32/185 loss = 0.0114\n",
      "epoch 20 batch 33/185 loss = 0.0132\n",
      "epoch 20 batch 34/185 loss = 0.0144\n",
      "epoch 20 batch 35/185 loss = 0.0108\n",
      "epoch 20 batch 36/185 loss = 0.0113\n",
      "epoch 20 batch 37/185 loss = 0.0099\n",
      "epoch 20 batch 38/185 loss = 0.0101\n",
      "epoch 20 batch 39/185 loss = 0.0083\n",
      "epoch 20 batch 40/185 loss = 0.0120\n",
      "epoch 20 batch 41/185 loss = 0.0087\n",
      "epoch 20 batch 42/185 loss = 0.0113\n",
      "epoch 20 batch 43/185 loss = 0.0097\n",
      "epoch 20 batch 44/185 loss = 0.0112\n",
      "epoch 20 batch 45/185 loss = 0.0101\n",
      "epoch 20 batch 46/185 loss = 0.0126\n",
      "epoch 20 batch 47/185 loss = 0.0095\n",
      "epoch 20 batch 48/185 loss = 0.0105\n",
      "epoch 20 batch 49/185 loss = 0.0119\n",
      "epoch 20 batch 50/185 loss = 0.0123\n",
      "epoch 20 batch 51/185 loss = 0.0107\n",
      "epoch 20 batch 52/185 loss = 0.0123\n",
      "epoch 20 batch 53/185 loss = 0.0099\n",
      "epoch 20 batch 54/185 loss = 0.0121\n",
      "epoch 20 batch 55/185 loss = 0.0099\n",
      "epoch 20 batch 56/185 loss = 0.0125\n",
      "epoch 20 batch 57/185 loss = 0.0110\n",
      "epoch 20 batch 58/185 loss = 0.0141\n",
      "epoch 20 batch 59/185 loss = 0.0124\n",
      "epoch 20 batch 60/185 loss = 0.0111\n",
      "epoch 20 batch 61/185 loss = 0.0128\n",
      "epoch 20 batch 62/185 loss = 0.0125\n",
      "epoch 20 batch 63/185 loss = 0.0114\n",
      "epoch 20 batch 64/185 loss = 0.0132\n",
      "epoch 20 batch 65/185 loss = 0.0109\n",
      "epoch 20 batch 66/185 loss = 0.0112\n",
      "epoch 20 batch 67/185 loss = 0.0107\n",
      "epoch 20 batch 68/185 loss = 0.0115\n",
      "epoch 20 batch 69/185 loss = 0.0104\n",
      "epoch 20 batch 70/185 loss = 0.0125\n",
      "epoch 20 batch 71/185 loss = 0.0126\n",
      "epoch 20 batch 72/185 loss = 0.0111\n",
      "epoch 20 batch 73/185 loss = 0.0124\n",
      "epoch 20 batch 74/185 loss = 0.0112\n",
      "epoch 20 batch 75/185 loss = 0.0093\n",
      "epoch 20 batch 76/185 loss = 0.0123\n",
      "epoch 20 batch 77/185 loss = 0.0095\n",
      "epoch 20 batch 78/185 loss = 0.0091\n",
      "epoch 20 batch 79/185 loss = 0.0107\n",
      "epoch 20 batch 80/185 loss = 0.0099\n",
      "epoch 20 batch 81/185 loss = 0.0121\n",
      "epoch 20 batch 82/185 loss = 0.0128\n",
      "epoch 20 batch 83/185 loss = 0.0090\n",
      "epoch 20 batch 84/185 loss = 0.0108\n",
      "epoch 20 batch 85/185 loss = 0.0108\n",
      "epoch 20 batch 86/185 loss = 0.0100\n",
      "epoch 20 batch 87/185 loss = 0.0113\n",
      "epoch 20 batch 88/185 loss = 0.0108\n",
      "epoch 20 batch 89/185 loss = 0.0092\n",
      "epoch 20 batch 90/185 loss = 0.0114\n",
      "epoch 20 batch 91/185 loss = 0.0101\n",
      "epoch 20 batch 92/185 loss = 0.0111\n",
      "epoch 20 batch 93/185 loss = 0.0084\n",
      "epoch 20 batch 94/185 loss = 0.0095\n",
      "epoch 20 batch 95/185 loss = 0.0109\n",
      "epoch 20 batch 96/185 loss = 0.0095\n",
      "epoch 20 batch 97/185 loss = 0.0134\n",
      "epoch 20 batch 98/185 loss = 0.0115\n",
      "epoch 20 batch 99/185 loss = 0.0097\n",
      "epoch 20 batch 100/185 loss = 0.0109\n",
      "epoch 20 batch 101/185 loss = 0.0083\n",
      "epoch 20 batch 102/185 loss = 0.0086\n",
      "epoch 20 batch 103/185 loss = 0.0106\n",
      "epoch 20 batch 104/185 loss = 0.0116\n",
      "epoch 20 batch 105/185 loss = 0.0099\n",
      "epoch 20 batch 106/185 loss = 0.0101\n",
      "epoch 20 batch 107/185 loss = 0.0113\n",
      "epoch 20 batch 108/185 loss = 0.0105\n",
      "epoch 20 batch 109/185 loss = 0.0108\n",
      "epoch 20 batch 110/185 loss = 0.0111\n",
      "epoch 20 batch 111/185 loss = 0.0100\n",
      "epoch 20 batch 112/185 loss = 0.0096\n",
      "epoch 20 batch 113/185 loss = 0.0105\n",
      "epoch 20 batch 114/185 loss = 0.0100\n",
      "epoch 20 batch 115/185 loss = 0.0089\n",
      "epoch 20 batch 116/185 loss = 0.0147\n",
      "epoch 20 batch 117/185 loss = 0.0122\n",
      "epoch 20 batch 118/185 loss = 0.0088\n",
      "epoch 20 batch 119/185 loss = 0.0109\n",
      "epoch 20 batch 120/185 loss = 0.0119\n",
      "epoch 20 batch 121/185 loss = 0.0114\n",
      "epoch 20 batch 122/185 loss = 0.0096\n",
      "epoch 20 batch 123/185 loss = 0.0081\n",
      "epoch 20 batch 124/185 loss = 0.0123\n",
      "epoch 20 batch 125/185 loss = 0.0083\n",
      "epoch 20 batch 126/185 loss = 0.0091\n",
      "epoch 20 batch 127/185 loss = 0.0090\n",
      "epoch 20 batch 128/185 loss = 0.0111\n",
      "epoch 20 batch 129/185 loss = 0.0105\n",
      "epoch 20 batch 130/185 loss = 0.0096\n",
      "epoch 20 batch 131/185 loss = 0.0121\n",
      "epoch 20 batch 132/185 loss = 0.0088\n",
      "epoch 20 batch 133/185 loss = 0.0093\n",
      "epoch 20 batch 134/185 loss = 0.0092\n",
      "epoch 20 batch 135/185 loss = 0.0102\n",
      "epoch 20 batch 136/185 loss = 0.0114\n",
      "epoch 20 batch 137/185 loss = 0.0139\n",
      "epoch 20 batch 138/185 loss = 0.0088\n",
      "epoch 20 batch 139/185 loss = 0.0095\n",
      "epoch 20 batch 140/185 loss = 0.0100\n",
      "epoch 20 batch 141/185 loss = 0.0097\n",
      "epoch 20 batch 142/185 loss = 0.0110\n",
      "epoch 20 batch 143/185 loss = 0.0103\n",
      "epoch 20 batch 144/185 loss = 0.0096\n",
      "epoch 20 batch 145/185 loss = 0.0128\n",
      "epoch 20 batch 146/185 loss = 0.0111\n",
      "epoch 20 batch 147/185 loss = 0.0104\n",
      "epoch 20 batch 148/185 loss = 0.0085\n",
      "epoch 20 batch 149/185 loss = 0.0138\n",
      "epoch 20 batch 150/185 loss = 0.0100\n",
      "epoch 20 batch 151/185 loss = 0.0103\n",
      "epoch 20 batch 152/185 loss = 0.0124\n",
      "epoch 20 batch 153/185 loss = 0.0114\n",
      "epoch 20 batch 154/185 loss = 0.0128\n",
      "epoch 20 batch 155/185 loss = 0.0095\n",
      "epoch 20 batch 156/185 loss = 0.0107\n",
      "epoch 20 batch 157/185 loss = 0.0089\n",
      "epoch 20 batch 158/185 loss = 0.0100\n",
      "epoch 20 batch 159/185 loss = 0.0129\n",
      "epoch 20 batch 160/185 loss = 0.0117\n",
      "epoch 20 batch 161/185 loss = 0.0108\n",
      "epoch 20 batch 162/185 loss = 0.0090\n",
      "epoch 20 batch 163/185 loss = 0.0130\n",
      "epoch 20 batch 164/185 loss = 0.0109\n",
      "epoch 20 batch 165/185 loss = 0.0103\n",
      "epoch 20 batch 166/185 loss = 0.0116\n",
      "epoch 20 batch 167/185 loss = 0.0124\n",
      "epoch 20 batch 168/185 loss = 0.0105\n",
      "epoch 20 batch 169/185 loss = 0.0095\n",
      "epoch 20 batch 170/185 loss = 0.0113\n",
      "epoch 20 batch 171/185 loss = 0.0096\n",
      "epoch 20 batch 172/185 loss = 0.0104\n",
      "epoch 20 batch 173/185 loss = 0.0096\n",
      "epoch 20 batch 174/185 loss = 0.0128\n",
      "epoch 20 batch 175/185 loss = 0.0118\n",
      "epoch 20 batch 176/185 loss = 0.0121\n",
      "epoch 20 batch 177/185 loss = 0.0106\n",
      "epoch 20 batch 178/185 loss = 0.0103\n",
      "epoch 20 batch 179/185 loss = 0.0140\n",
      "epoch 20 batch 180/185 loss = 0.0127\n",
      "epoch 20 batch 181/185 loss = 0.0089\n",
      "epoch 20 batch 182/185 loss = 0.0115\n",
      "epoch 20 batch 183/185 loss = 0.0116\n",
      "epoch 20 batch 184/185 loss = 0.0107\n",
      "epoch 20 batch 185/185 loss = 0.0099\n",
      "epoch 20 train loss = 0.0109 valid loss = 0.0177\n",
      "epoch 21 batch 1/185 loss = 0.0113\n",
      "epoch 21 batch 2/185 loss = 0.0108\n",
      "epoch 21 batch 3/185 loss = 0.0121\n",
      "epoch 21 batch 4/185 loss = 0.0100\n",
      "epoch 21 batch 5/185 loss = 0.0097\n",
      "epoch 21 batch 6/185 loss = 0.0125\n",
      "epoch 21 batch 7/185 loss = 0.0117\n",
      "epoch 21 batch 8/185 loss = 0.0090\n",
      "epoch 21 batch 9/185 loss = 0.0106\n",
      "epoch 21 batch 10/185 loss = 0.0093\n",
      "epoch 21 batch 11/185 loss = 0.0111\n",
      "epoch 21 batch 12/185 loss = 0.0104\n",
      "epoch 21 batch 13/185 loss = 0.0093\n",
      "epoch 21 batch 14/185 loss = 0.0099\n",
      "epoch 21 batch 15/185 loss = 0.0109\n",
      "epoch 21 batch 16/185 loss = 0.0117\n",
      "epoch 21 batch 17/185 loss = 0.0095\n",
      "epoch 21 batch 18/185 loss = 0.0106\n",
      "epoch 21 batch 19/185 loss = 0.0102\n",
      "epoch 21 batch 20/185 loss = 0.0101\n",
      "epoch 21 batch 21/185 loss = 0.0095\n",
      "epoch 21 batch 22/185 loss = 0.0119\n",
      "epoch 21 batch 23/185 loss = 0.0149\n",
      "epoch 21 batch 24/185 loss = 0.0125\n",
      "epoch 21 batch 25/185 loss = 0.0098\n",
      "epoch 21 batch 26/185 loss = 0.0113\n",
      "epoch 21 batch 27/185 loss = 0.0096\n",
      "epoch 21 batch 28/185 loss = 0.0114\n",
      "epoch 21 batch 29/185 loss = 0.0093\n",
      "epoch 21 batch 30/185 loss = 0.0110\n",
      "epoch 21 batch 31/185 loss = 0.0078\n",
      "epoch 21 batch 32/185 loss = 0.0122\n",
      "epoch 21 batch 33/185 loss = 0.0111\n",
      "epoch 21 batch 34/185 loss = 0.0107\n",
      "epoch 21 batch 35/185 loss = 0.0097\n",
      "epoch 21 batch 36/185 loss = 0.0096\n",
      "epoch 21 batch 37/185 loss = 0.0101\n",
      "epoch 21 batch 38/185 loss = 0.0087\n",
      "epoch 21 batch 39/185 loss = 0.0080\n",
      "epoch 21 batch 40/185 loss = 0.0098\n",
      "epoch 21 batch 41/185 loss = 0.0101\n",
      "epoch 21 batch 42/185 loss = 0.0140\n",
      "epoch 21 batch 43/185 loss = 0.0099\n",
      "epoch 21 batch 44/185 loss = 0.0108\n",
      "epoch 21 batch 45/185 loss = 0.0095\n",
      "epoch 21 batch 46/185 loss = 0.0129\n",
      "epoch 21 batch 47/185 loss = 0.0101\n",
      "epoch 21 batch 48/185 loss = 0.0107\n",
      "epoch 21 batch 49/185 loss = 0.0127\n",
      "epoch 21 batch 50/185 loss = 0.0098\n",
      "epoch 21 batch 51/185 loss = 0.0111\n",
      "epoch 21 batch 52/185 loss = 0.0095\n",
      "epoch 21 batch 53/185 loss = 0.0146\n",
      "epoch 21 batch 54/185 loss = 0.0111\n",
      "epoch 21 batch 55/185 loss = 0.0127\n",
      "epoch 21 batch 56/185 loss = 0.0101\n",
      "epoch 21 batch 57/185 loss = 0.0122\n",
      "epoch 21 batch 58/185 loss = 0.0083\n",
      "epoch 21 batch 59/185 loss = 0.0128\n",
      "epoch 21 batch 60/185 loss = 0.0102\n",
      "epoch 21 batch 61/185 loss = 0.0113\n",
      "epoch 21 batch 62/185 loss = 0.0100\n",
      "epoch 21 batch 63/185 loss = 0.0086\n",
      "epoch 21 batch 64/185 loss = 0.0089\n",
      "epoch 21 batch 65/185 loss = 0.0133\n",
      "epoch 21 batch 66/185 loss = 0.0127\n",
      "epoch 21 batch 67/185 loss = 0.0115\n",
      "epoch 21 batch 68/185 loss = 0.0108\n",
      "epoch 21 batch 69/185 loss = 0.0110\n",
      "epoch 21 batch 70/185 loss = 0.0147\n",
      "epoch 21 batch 71/185 loss = 0.0095\n",
      "epoch 21 batch 72/185 loss = 0.0104\n",
      "epoch 21 batch 73/185 loss = 0.0104\n",
      "epoch 21 batch 74/185 loss = 0.0100\n",
      "epoch 21 batch 75/185 loss = 0.0099\n",
      "epoch 21 batch 76/185 loss = 0.0085\n",
      "epoch 21 batch 77/185 loss = 0.0116\n",
      "epoch 21 batch 78/185 loss = 0.0088\n",
      "epoch 21 batch 79/185 loss = 0.0118\n",
      "epoch 21 batch 80/185 loss = 0.0112\n",
      "epoch 21 batch 81/185 loss = 0.0099\n",
      "epoch 21 batch 82/185 loss = 0.0119\n",
      "epoch 21 batch 83/185 loss = 0.0106\n",
      "epoch 21 batch 84/185 loss = 0.0111\n",
      "epoch 21 batch 85/185 loss = 0.0098\n",
      "epoch 21 batch 86/185 loss = 0.0128\n",
      "epoch 21 batch 87/185 loss = 0.0110\n",
      "epoch 21 batch 88/185 loss = 0.0113\n",
      "epoch 21 batch 89/185 loss = 0.0096\n",
      "epoch 21 batch 90/185 loss = 0.0105\n",
      "epoch 21 batch 91/185 loss = 0.0112\n",
      "epoch 21 batch 92/185 loss = 0.0107\n",
      "epoch 21 batch 93/185 loss = 0.0113\n",
      "epoch 21 batch 94/185 loss = 0.0114\n",
      "epoch 21 batch 95/185 loss = 0.0127\n",
      "epoch 21 batch 96/185 loss = 0.0118\n",
      "epoch 21 batch 97/185 loss = 0.0116\n",
      "epoch 21 batch 98/185 loss = 0.0140\n",
      "epoch 21 batch 99/185 loss = 0.0108\n",
      "epoch 21 batch 100/185 loss = 0.0136\n",
      "epoch 21 batch 101/185 loss = 0.0092\n",
      "epoch 21 batch 102/185 loss = 0.0107\n",
      "epoch 21 batch 103/185 loss = 0.0144\n",
      "epoch 21 batch 104/185 loss = 0.0113\n",
      "epoch 21 batch 105/185 loss = 0.0120\n",
      "epoch 21 batch 106/185 loss = 0.0104\n",
      "epoch 21 batch 107/185 loss = 0.0099\n",
      "epoch 21 batch 108/185 loss = 0.0134\n",
      "epoch 21 batch 109/185 loss = 0.0097\n",
      "epoch 21 batch 110/185 loss = 0.0114\n",
      "epoch 21 batch 111/185 loss = 0.0120\n",
      "epoch 21 batch 112/185 loss = 0.0098\n",
      "epoch 21 batch 113/185 loss = 0.0124\n",
      "epoch 21 batch 114/185 loss = 0.0108\n",
      "epoch 21 batch 115/185 loss = 0.0106\n",
      "epoch 21 batch 116/185 loss = 0.0117\n",
      "epoch 21 batch 117/185 loss = 0.0112\n",
      "epoch 21 batch 118/185 loss = 0.0091\n",
      "epoch 21 batch 119/185 loss = 0.0089\n",
      "epoch 21 batch 120/185 loss = 0.0129\n",
      "epoch 21 batch 121/185 loss = 0.0116\n",
      "epoch 21 batch 122/185 loss = 0.0135\n",
      "epoch 21 batch 123/185 loss = 0.0107\n",
      "epoch 21 batch 124/185 loss = 0.0097\n",
      "epoch 21 batch 125/185 loss = 0.0108\n",
      "epoch 21 batch 126/185 loss = 0.0090\n",
      "epoch 21 batch 127/185 loss = 0.0131\n",
      "epoch 21 batch 128/185 loss = 0.0105\n",
      "epoch 21 batch 129/185 loss = 0.0145\n",
      "epoch 21 batch 130/185 loss = 0.0100\n",
      "epoch 21 batch 131/185 loss = 0.0105\n",
      "epoch 21 batch 132/185 loss = 0.0088\n",
      "epoch 21 batch 133/185 loss = 0.0095\n",
      "epoch 21 batch 134/185 loss = 0.0108\n",
      "epoch 21 batch 135/185 loss = 0.0138\n",
      "epoch 21 batch 136/185 loss = 0.0103\n",
      "epoch 21 batch 137/185 loss = 0.0100\n",
      "epoch 21 batch 138/185 loss = 0.0113\n",
      "epoch 21 batch 139/185 loss = 0.0135\n",
      "epoch 21 batch 140/185 loss = 0.0103\n",
      "epoch 21 batch 141/185 loss = 0.0116\n",
      "epoch 21 batch 142/185 loss = 0.0089\n",
      "epoch 21 batch 143/185 loss = 0.0113\n",
      "epoch 21 batch 144/185 loss = 0.0111\n",
      "epoch 21 batch 145/185 loss = 0.0102\n",
      "epoch 21 batch 146/185 loss = 0.0100\n",
      "epoch 21 batch 147/185 loss = 0.0124\n",
      "epoch 21 batch 148/185 loss = 0.0112\n",
      "epoch 21 batch 149/185 loss = 0.0119\n",
      "epoch 21 batch 150/185 loss = 0.0114\n",
      "epoch 21 batch 151/185 loss = 0.0108\n",
      "epoch 21 batch 152/185 loss = 0.0109\n",
      "epoch 21 batch 153/185 loss = 0.0120\n",
      "epoch 21 batch 154/185 loss = 0.0106\n",
      "epoch 21 batch 155/185 loss = 0.0095\n",
      "epoch 21 batch 156/185 loss = 0.0087\n",
      "epoch 21 batch 157/185 loss = 0.0091\n",
      "epoch 21 batch 158/185 loss = 0.0124\n",
      "epoch 21 batch 159/185 loss = 0.0100\n",
      "epoch 21 batch 160/185 loss = 0.0100\n",
      "epoch 21 batch 161/185 loss = 0.0122\n",
      "epoch 21 batch 162/185 loss = 0.0116\n",
      "epoch 21 batch 163/185 loss = 0.0087\n",
      "epoch 21 batch 164/185 loss = 0.0085\n",
      "epoch 21 batch 165/185 loss = 0.0105\n",
      "epoch 21 batch 166/185 loss = 0.0104\n",
      "epoch 21 batch 167/185 loss = 0.0116\n",
      "epoch 21 batch 168/185 loss = 0.0106\n",
      "epoch 21 batch 169/185 loss = 0.0093\n",
      "epoch 21 batch 170/185 loss = 0.0108\n",
      "epoch 21 batch 171/185 loss = 0.0113\n",
      "epoch 21 batch 172/185 loss = 0.0096\n",
      "epoch 21 batch 173/185 loss = 0.0108\n",
      "epoch 21 batch 174/185 loss = 0.0095\n",
      "epoch 21 batch 175/185 loss = 0.0146\n",
      "epoch 21 batch 176/185 loss = 0.0108\n",
      "epoch 21 batch 177/185 loss = 0.0083\n",
      "epoch 21 batch 178/185 loss = 0.0102\n",
      "epoch 21 batch 179/185 loss = 0.0104\n",
      "epoch 21 batch 180/185 loss = 0.0138\n",
      "epoch 21 batch 181/185 loss = 0.0115\n",
      "epoch 21 batch 182/185 loss = 0.0092\n",
      "epoch 21 batch 183/185 loss = 0.0104\n",
      "epoch 21 batch 184/185 loss = 0.0106\n",
      "epoch 21 batch 185/185 loss = 0.0099\n",
      "epoch 21 train loss = 0.0109 valid loss = 0.0256\n",
      "performance reducing: counter 1\n",
      "epoch 22 batch 1/185 loss = 0.0094\n",
      "epoch 22 batch 2/185 loss = 0.0096\n",
      "epoch 22 batch 3/185 loss = 0.0113\n",
      "epoch 22 batch 4/185 loss = 0.0108\n",
      "epoch 22 batch 5/185 loss = 0.0097\n",
      "epoch 22 batch 6/185 loss = 0.0111\n",
      "epoch 22 batch 7/185 loss = 0.0093\n",
      "epoch 22 batch 8/185 loss = 0.0113\n",
      "epoch 22 batch 9/185 loss = 0.0093\n",
      "epoch 22 batch 10/185 loss = 0.0088\n",
      "epoch 22 batch 11/185 loss = 0.0121\n",
      "epoch 22 batch 12/185 loss = 0.0085\n",
      "epoch 22 batch 13/185 loss = 0.0099\n",
      "epoch 22 batch 14/185 loss = 0.0086\n",
      "epoch 22 batch 15/185 loss = 0.0087\n",
      "epoch 22 batch 16/185 loss = 0.0116\n",
      "epoch 22 batch 17/185 loss = 0.0097\n",
      "epoch 22 batch 18/185 loss = 0.0095\n",
      "epoch 22 batch 19/185 loss = 0.0087\n",
      "epoch 22 batch 20/185 loss = 0.0126\n",
      "epoch 22 batch 21/185 loss = 0.0092\n",
      "epoch 22 batch 22/185 loss = 0.0091\n",
      "epoch 22 batch 23/185 loss = 0.0111\n",
      "epoch 22 batch 24/185 loss = 0.0113\n",
      "epoch 22 batch 25/185 loss = 0.0102\n",
      "epoch 22 batch 26/185 loss = 0.0102\n",
      "epoch 22 batch 27/185 loss = 0.0126\n",
      "epoch 22 batch 28/185 loss = 0.0105\n",
      "epoch 22 batch 29/185 loss = 0.0090\n",
      "epoch 22 batch 30/185 loss = 0.0105\n",
      "epoch 22 batch 31/185 loss = 0.0114\n",
      "epoch 22 batch 32/185 loss = 0.0127\n",
      "epoch 22 batch 33/185 loss = 0.0107\n",
      "epoch 22 batch 34/185 loss = 0.0092\n",
      "epoch 22 batch 35/185 loss = 0.0106\n",
      "epoch 22 batch 36/185 loss = 0.0100\n",
      "epoch 22 batch 37/185 loss = 0.0140\n",
      "epoch 22 batch 38/185 loss = 0.0107\n",
      "epoch 22 batch 39/185 loss = 0.0125\n",
      "epoch 22 batch 40/185 loss = 0.0103\n",
      "epoch 22 batch 41/185 loss = 0.0122\n",
      "epoch 22 batch 42/185 loss = 0.0091\n",
      "epoch 22 batch 43/185 loss = 0.0108\n",
      "epoch 22 batch 44/185 loss = 0.0090\n",
      "epoch 22 batch 45/185 loss = 0.0109\n",
      "epoch 22 batch 46/185 loss = 0.0107\n",
      "epoch 22 batch 47/185 loss = 0.0112\n",
      "epoch 22 batch 48/185 loss = 0.0112\n",
      "epoch 22 batch 49/185 loss = 0.0098\n",
      "epoch 22 batch 50/185 loss = 0.0095\n",
      "epoch 22 batch 51/185 loss = 0.0102\n",
      "epoch 22 batch 52/185 loss = 0.0107\n",
      "epoch 22 batch 53/185 loss = 0.0103\n",
      "epoch 22 batch 54/185 loss = 0.0104\n",
      "epoch 22 batch 55/185 loss = 0.0101\n",
      "epoch 22 batch 56/185 loss = 0.0093\n",
      "epoch 22 batch 57/185 loss = 0.0097\n",
      "epoch 22 batch 58/185 loss = 0.0094\n",
      "epoch 22 batch 59/185 loss = 0.0105\n",
      "epoch 22 batch 60/185 loss = 0.0111\n",
      "epoch 22 batch 61/185 loss = 0.0106\n",
      "epoch 22 batch 62/185 loss = 0.0099\n",
      "epoch 22 batch 63/185 loss = 0.0102\n",
      "epoch 22 batch 64/185 loss = 0.0112\n",
      "epoch 22 batch 65/185 loss = 0.0099\n",
      "epoch 22 batch 66/185 loss = 0.0101\n",
      "epoch 22 batch 67/185 loss = 0.0107\n",
      "epoch 22 batch 68/185 loss = 0.0109\n",
      "epoch 22 batch 69/185 loss = 0.0119\n",
      "epoch 22 batch 70/185 loss = 0.0095\n",
      "epoch 22 batch 71/185 loss = 0.0079\n",
      "epoch 22 batch 72/185 loss = 0.0102\n",
      "epoch 22 batch 73/185 loss = 0.0092\n",
      "epoch 22 batch 74/185 loss = 0.0119\n",
      "epoch 22 batch 75/185 loss = 0.0106\n",
      "epoch 22 batch 76/185 loss = 0.0097\n",
      "epoch 22 batch 77/185 loss = 0.0107\n",
      "epoch 22 batch 78/185 loss = 0.0107\n",
      "epoch 22 batch 79/185 loss = 0.0088\n",
      "epoch 22 batch 80/185 loss = 0.0124\n",
      "epoch 22 batch 81/185 loss = 0.0103\n",
      "epoch 22 batch 82/185 loss = 0.0123\n",
      "epoch 22 batch 83/185 loss = 0.0097\n",
      "epoch 22 batch 84/185 loss = 0.0097\n",
      "epoch 22 batch 85/185 loss = 0.0117\n",
      "epoch 22 batch 86/185 loss = 0.0089\n",
      "epoch 22 batch 87/185 loss = 0.0102\n",
      "epoch 22 batch 88/185 loss = 0.0118\n",
      "epoch 22 batch 89/185 loss = 0.0101\n",
      "epoch 22 batch 90/185 loss = 0.0115\n",
      "epoch 22 batch 91/185 loss = 0.0114\n",
      "epoch 22 batch 92/185 loss = 0.0134\n",
      "epoch 22 batch 93/185 loss = 0.0098\n",
      "epoch 22 batch 94/185 loss = 0.0124\n",
      "epoch 22 batch 95/185 loss = 0.0083\n",
      "epoch 22 batch 96/185 loss = 0.0084\n",
      "epoch 22 batch 97/185 loss = 0.0106\n",
      "epoch 22 batch 98/185 loss = 0.0128\n",
      "epoch 22 batch 99/185 loss = 0.0084\n",
      "epoch 22 batch 100/185 loss = 0.0093\n",
      "epoch 22 batch 101/185 loss = 0.0139\n",
      "epoch 22 batch 102/185 loss = 0.0108\n",
      "epoch 22 batch 103/185 loss = 0.0109\n",
      "epoch 22 batch 104/185 loss = 0.0092\n",
      "epoch 22 batch 105/185 loss = 0.0115\n",
      "epoch 22 batch 106/185 loss = 0.0085\n",
      "epoch 22 batch 107/185 loss = 0.0111\n",
      "epoch 22 batch 108/185 loss = 0.0100\n",
      "epoch 22 batch 109/185 loss = 0.0104\n",
      "epoch 22 batch 110/185 loss = 0.0114\n",
      "epoch 22 batch 111/185 loss = 0.0105\n",
      "epoch 22 batch 112/185 loss = 0.0106\n",
      "epoch 22 batch 113/185 loss = 0.0112\n",
      "epoch 22 batch 114/185 loss = 0.0111\n",
      "epoch 22 batch 115/185 loss = 0.0108\n",
      "epoch 22 batch 116/185 loss = 0.0089\n",
      "epoch 22 batch 117/185 loss = 0.0102\n",
      "epoch 22 batch 118/185 loss = 0.0097\n",
      "epoch 22 batch 119/185 loss = 0.0104\n",
      "epoch 22 batch 120/185 loss = 0.0088\n",
      "epoch 22 batch 121/185 loss = 0.0081\n",
      "epoch 22 batch 122/185 loss = 0.0131\n",
      "epoch 22 batch 123/185 loss = 0.0107\n",
      "epoch 22 batch 124/185 loss = 0.0117\n",
      "epoch 22 batch 125/185 loss = 0.0141\n",
      "epoch 22 batch 126/185 loss = 0.0110\n",
      "epoch 22 batch 127/185 loss = 0.0110\n",
      "epoch 22 batch 128/185 loss = 0.0125\n",
      "epoch 22 batch 129/185 loss = 0.0127\n",
      "epoch 22 batch 130/185 loss = 0.0102\n",
      "epoch 22 batch 131/185 loss = 0.0111\n",
      "epoch 22 batch 132/185 loss = 0.0092\n",
      "epoch 22 batch 133/185 loss = 0.0107\n",
      "epoch 22 batch 134/185 loss = 0.0100\n",
      "epoch 22 batch 135/185 loss = 0.0093\n",
      "epoch 22 batch 136/185 loss = 0.0133\n",
      "epoch 22 batch 137/185 loss = 0.0097\n",
      "epoch 22 batch 138/185 loss = 0.0080\n",
      "epoch 22 batch 139/185 loss = 0.0093\n",
      "epoch 22 batch 140/185 loss = 0.0110\n",
      "epoch 22 batch 141/185 loss = 0.0113\n",
      "epoch 22 batch 142/185 loss = 0.0096\n",
      "epoch 22 batch 143/185 loss = 0.0121\n",
      "epoch 22 batch 144/185 loss = 0.0144\n",
      "epoch 22 batch 145/185 loss = 0.0137\n",
      "epoch 22 batch 146/185 loss = 0.0137\n",
      "epoch 22 batch 147/185 loss = 0.0112\n",
      "epoch 22 batch 148/185 loss = 0.0139\n",
      "epoch 22 batch 149/185 loss = 0.0090\n",
      "epoch 22 batch 150/185 loss = 0.0097\n",
      "epoch 22 batch 151/185 loss = 0.0102\n",
      "epoch 22 batch 152/185 loss = 0.0115\n",
      "epoch 22 batch 153/185 loss = 0.0133\n",
      "epoch 22 batch 154/185 loss = 0.0110\n",
      "epoch 22 batch 155/185 loss = 0.0103\n",
      "epoch 22 batch 156/185 loss = 0.0089\n",
      "epoch 22 batch 157/185 loss = 0.0120\n",
      "epoch 22 batch 158/185 loss = 0.0099\n",
      "epoch 22 batch 159/185 loss = 0.0116\n",
      "epoch 22 batch 160/185 loss = 0.0117\n",
      "epoch 22 batch 161/185 loss = 0.0127\n",
      "epoch 22 batch 162/185 loss = 0.0135\n",
      "epoch 22 batch 163/185 loss = 0.0116\n",
      "epoch 22 batch 164/185 loss = 0.0112\n",
      "epoch 22 batch 165/185 loss = 0.0126\n",
      "epoch 22 batch 166/185 loss = 0.0099\n",
      "epoch 22 batch 167/185 loss = 0.0094\n",
      "epoch 22 batch 168/185 loss = 0.0126\n",
      "epoch 22 batch 169/185 loss = 0.0101\n",
      "epoch 22 batch 170/185 loss = 0.0084\n",
      "epoch 22 batch 171/185 loss = 0.0111\n",
      "epoch 22 batch 172/185 loss = 0.0100\n",
      "epoch 22 batch 173/185 loss = 0.0091\n",
      "epoch 22 batch 174/185 loss = 0.0114\n",
      "epoch 22 batch 175/185 loss = 0.0105\n",
      "epoch 22 batch 176/185 loss = 0.0130\n",
      "epoch 22 batch 177/185 loss = 0.0113\n",
      "epoch 22 batch 178/185 loss = 0.0112\n",
      "epoch 22 batch 179/185 loss = 0.0148\n",
      "epoch 22 batch 180/185 loss = 0.0103\n",
      "epoch 22 batch 181/185 loss = 0.0107\n",
      "epoch 22 batch 182/185 loss = 0.0116\n",
      "epoch 22 batch 183/185 loss = 0.0115\n",
      "epoch 22 batch 184/185 loss = 0.0114\n",
      "epoch 22 batch 185/185 loss = 0.0119\n",
      "epoch 22 train loss = 0.0107 valid loss = 0.0200\n",
      "performance reducing: counter 2\n",
      "epoch 23 batch 1/185 loss = 0.0108\n",
      "epoch 23 batch 2/185 loss = 0.0096\n",
      "epoch 23 batch 3/185 loss = 0.0153\n",
      "epoch 23 batch 4/185 loss = 0.0100\n",
      "epoch 23 batch 5/185 loss = 0.0101\n",
      "epoch 23 batch 6/185 loss = 0.0094\n",
      "epoch 23 batch 7/185 loss = 0.0105\n",
      "epoch 23 batch 8/185 loss = 0.0093\n",
      "epoch 23 batch 9/185 loss = 0.0111\n",
      "epoch 23 batch 10/185 loss = 0.0114\n",
      "epoch 23 batch 11/185 loss = 0.0100\n",
      "epoch 23 batch 12/185 loss = 0.0090\n",
      "epoch 23 batch 13/185 loss = 0.0097\n",
      "epoch 23 batch 14/185 loss = 0.0092\n",
      "epoch 23 batch 15/185 loss = 0.0093\n",
      "epoch 23 batch 16/185 loss = 0.0104\n",
      "epoch 23 batch 17/185 loss = 0.0073\n",
      "epoch 23 batch 18/185 loss = 0.0107\n",
      "epoch 23 batch 19/185 loss = 0.0102\n",
      "epoch 23 batch 20/185 loss = 0.0092\n",
      "epoch 23 batch 21/185 loss = 0.0086\n",
      "epoch 23 batch 22/185 loss = 0.0094\n",
      "epoch 23 batch 23/185 loss = 0.0130\n",
      "epoch 23 batch 24/185 loss = 0.0107\n",
      "epoch 23 batch 25/185 loss = 0.0106\n",
      "epoch 23 batch 26/185 loss = 0.0098\n",
      "epoch 23 batch 27/185 loss = 0.0109\n",
      "epoch 23 batch 28/185 loss = 0.0095\n",
      "epoch 23 batch 29/185 loss = 0.0098\n",
      "epoch 23 batch 30/185 loss = 0.0096\n",
      "epoch 23 batch 31/185 loss = 0.0086\n",
      "epoch 23 batch 32/185 loss = 0.0111\n",
      "epoch 23 batch 33/185 loss = 0.0080\n",
      "epoch 23 batch 34/185 loss = 0.0102\n",
      "epoch 23 batch 35/185 loss = 0.0098\n",
      "epoch 23 batch 36/185 loss = 0.0117\n",
      "epoch 23 batch 37/185 loss = 0.0110\n",
      "epoch 23 batch 38/185 loss = 0.0099\n",
      "epoch 23 batch 39/185 loss = 0.0137\n",
      "epoch 23 batch 40/185 loss = 0.0112\n",
      "epoch 23 batch 41/185 loss = 0.0103\n",
      "epoch 23 batch 42/185 loss = 0.0089\n",
      "epoch 23 batch 43/185 loss = 0.0095\n",
      "epoch 23 batch 44/185 loss = 0.0094\n",
      "epoch 23 batch 45/185 loss = 0.0095\n",
      "epoch 23 batch 46/185 loss = 0.0123\n",
      "epoch 23 batch 47/185 loss = 0.0110\n",
      "epoch 23 batch 48/185 loss = 0.0111\n",
      "epoch 23 batch 49/185 loss = 0.0111\n",
      "epoch 23 batch 50/185 loss = 0.0112\n",
      "epoch 23 batch 51/185 loss = 0.0103\n",
      "epoch 23 batch 52/185 loss = 0.0126\n",
      "epoch 23 batch 53/185 loss = 0.0090\n",
      "epoch 23 batch 54/185 loss = 0.0090\n",
      "epoch 23 batch 55/185 loss = 0.0103\n",
      "epoch 23 batch 56/185 loss = 0.0128\n",
      "epoch 23 batch 57/185 loss = 0.0119\n",
      "epoch 23 batch 58/185 loss = 0.0094\n",
      "epoch 23 batch 59/185 loss = 0.0131\n",
      "epoch 23 batch 60/185 loss = 0.0113\n",
      "epoch 23 batch 61/185 loss = 0.0108\n",
      "epoch 23 batch 62/185 loss = 0.0098\n",
      "epoch 23 batch 63/185 loss = 0.0136\n",
      "epoch 23 batch 64/185 loss = 0.0092\n",
      "epoch 23 batch 65/185 loss = 0.0101\n",
      "epoch 23 batch 66/185 loss = 0.0104\n",
      "epoch 23 batch 67/185 loss = 0.0121\n",
      "epoch 23 batch 68/185 loss = 0.0085\n",
      "epoch 23 batch 69/185 loss = 0.0092\n",
      "epoch 23 batch 70/185 loss = 0.0120\n",
      "epoch 23 batch 71/185 loss = 0.0095\n",
      "epoch 23 batch 72/185 loss = 0.0104\n",
      "epoch 23 batch 73/185 loss = 0.0096\n",
      "epoch 23 batch 74/185 loss = 0.0092\n",
      "epoch 23 batch 75/185 loss = 0.0118\n",
      "epoch 23 batch 76/185 loss = 0.0094\n",
      "epoch 23 batch 77/185 loss = 0.0129\n",
      "epoch 23 batch 78/185 loss = 0.0130\n",
      "epoch 23 batch 79/185 loss = 0.0108\n",
      "epoch 23 batch 80/185 loss = 0.0098\n",
      "epoch 23 batch 81/185 loss = 0.0116\n",
      "epoch 23 batch 82/185 loss = 0.0095\n",
      "epoch 23 batch 83/185 loss = 0.0092\n",
      "epoch 23 batch 84/185 loss = 0.0085\n",
      "epoch 23 batch 85/185 loss = 0.0099\n",
      "epoch 23 batch 86/185 loss = 0.0102\n",
      "epoch 23 batch 87/185 loss = 0.0116\n",
      "epoch 23 batch 88/185 loss = 0.0104\n",
      "epoch 23 batch 89/185 loss = 0.0101\n",
      "epoch 23 batch 90/185 loss = 0.0096\n",
      "epoch 23 batch 91/185 loss = 0.0103\n",
      "epoch 23 batch 92/185 loss = 0.0102\n",
      "epoch 23 batch 93/185 loss = 0.0108\n",
      "epoch 23 batch 94/185 loss = 0.0089\n",
      "epoch 23 batch 95/185 loss = 0.0130\n",
      "epoch 23 batch 96/185 loss = 0.0107\n",
      "epoch 23 batch 97/185 loss = 0.0091\n",
      "epoch 23 batch 98/185 loss = 0.0136\n",
      "epoch 23 batch 99/185 loss = 0.0091\n",
      "epoch 23 batch 100/185 loss = 0.0093\n",
      "epoch 23 batch 101/185 loss = 0.0083\n",
      "epoch 23 batch 102/185 loss = 0.0112\n",
      "epoch 23 batch 103/185 loss = 0.0085\n",
      "epoch 23 batch 104/185 loss = 0.0117\n",
      "epoch 23 batch 105/185 loss = 0.0095\n",
      "epoch 23 batch 106/185 loss = 0.0086\n",
      "epoch 23 batch 107/185 loss = 0.0092\n",
      "epoch 23 batch 108/185 loss = 0.0098\n",
      "epoch 23 batch 109/185 loss = 0.0114\n",
      "epoch 23 batch 110/185 loss = 0.0104\n",
      "epoch 23 batch 111/185 loss = 0.0090\n",
      "epoch 23 batch 112/185 loss = 0.0075\n",
      "epoch 23 batch 113/185 loss = 0.0115\n",
      "epoch 23 batch 114/185 loss = 0.0100\n",
      "epoch 23 batch 115/185 loss = 0.0114\n",
      "epoch 23 batch 116/185 loss = 0.0110\n",
      "epoch 23 batch 117/185 loss = 0.0103\n",
      "epoch 23 batch 118/185 loss = 0.0089\n",
      "epoch 23 batch 119/185 loss = 0.0094\n",
      "epoch 23 batch 120/185 loss = 0.0087\n",
      "epoch 23 batch 121/185 loss = 0.0098\n",
      "epoch 23 batch 122/185 loss = 0.0096\n",
      "epoch 23 batch 123/185 loss = 0.0118\n",
      "epoch 23 batch 124/185 loss = 0.0104\n",
      "epoch 23 batch 125/185 loss = 0.0112\n",
      "epoch 23 batch 126/185 loss = 0.0099\n",
      "epoch 23 batch 127/185 loss = 0.0090\n",
      "epoch 23 batch 128/185 loss = 0.0104\n",
      "epoch 23 batch 129/185 loss = 0.0100\n",
      "epoch 23 batch 130/185 loss = 0.0093\n",
      "epoch 23 batch 131/185 loss = 0.0121\n",
      "epoch 23 batch 132/185 loss = 0.0113\n",
      "epoch 23 batch 133/185 loss = 0.0089\n",
      "epoch 23 batch 134/185 loss = 0.0111\n",
      "epoch 23 batch 135/185 loss = 0.0099\n",
      "epoch 23 batch 136/185 loss = 0.0106\n",
      "epoch 23 batch 137/185 loss = 0.0130\n",
      "epoch 23 batch 138/185 loss = 0.0104\n",
      "epoch 23 batch 139/185 loss = 0.0095\n",
      "epoch 23 batch 140/185 loss = 0.0099\n",
      "epoch 23 batch 141/185 loss = 0.0120\n",
      "epoch 23 batch 142/185 loss = 0.0081\n",
      "epoch 23 batch 143/185 loss = 0.0100\n",
      "epoch 23 batch 144/185 loss = 0.0131\n",
      "epoch 23 batch 145/185 loss = 0.0108\n",
      "epoch 23 batch 146/185 loss = 0.0087\n",
      "epoch 23 batch 147/185 loss = 0.0126\n",
      "epoch 23 batch 148/185 loss = 0.0140\n",
      "epoch 23 batch 149/185 loss = 0.0103\n",
      "epoch 23 batch 150/185 loss = 0.0120\n",
      "epoch 23 batch 151/185 loss = 0.0093\n",
      "epoch 23 batch 152/185 loss = 0.0090\n",
      "epoch 23 batch 153/185 loss = 0.0091\n",
      "epoch 23 batch 154/185 loss = 0.0130\n",
      "epoch 23 batch 155/185 loss = 0.0117\n",
      "epoch 23 batch 156/185 loss = 0.0122\n",
      "epoch 23 batch 157/185 loss = 0.0094\n",
      "epoch 23 batch 158/185 loss = 0.0162\n",
      "epoch 23 batch 159/185 loss = 0.0133\n",
      "epoch 23 batch 160/185 loss = 0.0097\n",
      "epoch 23 batch 161/185 loss = 0.0101\n",
      "epoch 23 batch 162/185 loss = 0.0112\n",
      "epoch 23 batch 163/185 loss = 0.0110\n",
      "epoch 23 batch 164/185 loss = 0.0107\n",
      "epoch 23 batch 165/185 loss = 0.0105\n",
      "epoch 23 batch 166/185 loss = 0.0098\n",
      "epoch 23 batch 167/185 loss = 0.0124\n",
      "epoch 23 batch 168/185 loss = 0.0113\n",
      "epoch 23 batch 169/185 loss = 0.0112\n",
      "epoch 23 batch 170/185 loss = 0.0113\n",
      "epoch 23 batch 171/185 loss = 0.0093\n",
      "epoch 23 batch 172/185 loss = 0.0145\n",
      "epoch 23 batch 173/185 loss = 0.0110\n",
      "epoch 23 batch 174/185 loss = 0.0119\n",
      "epoch 23 batch 175/185 loss = 0.0102\n",
      "epoch 23 batch 176/185 loss = 0.0102\n",
      "epoch 23 batch 177/185 loss = 0.0104\n",
      "epoch 23 batch 178/185 loss = 0.0117\n",
      "epoch 23 batch 179/185 loss = 0.0103\n",
      "epoch 23 batch 180/185 loss = 0.0092\n",
      "epoch 23 batch 181/185 loss = 0.0116\n",
      "epoch 23 batch 182/185 loss = 0.0112\n",
      "epoch 23 batch 183/185 loss = 0.0101\n",
      "epoch 23 batch 184/185 loss = 0.0110\n",
      "epoch 23 batch 185/185 loss = 0.0128\n",
      "epoch 23 train loss = 0.0105 valid loss = 0.0222\n",
      "performance reducing: counter 3\n",
      "epoch 24 batch 1/185 loss = 0.0128\n",
      "epoch 24 batch 2/185 loss = 0.0103\n",
      "epoch 24 batch 3/185 loss = 0.0117\n",
      "epoch 24 batch 4/185 loss = 0.0085\n",
      "epoch 24 batch 5/185 loss = 0.0100\n",
      "epoch 24 batch 6/185 loss = 0.0102\n",
      "epoch 24 batch 7/185 loss = 0.0095\n",
      "epoch 24 batch 8/185 loss = 0.0109\n",
      "epoch 24 batch 9/185 loss = 0.0107\n",
      "epoch 24 batch 10/185 loss = 0.0094\n",
      "epoch 24 batch 11/185 loss = 0.0097\n",
      "epoch 24 batch 12/185 loss = 0.0118\n",
      "epoch 24 batch 13/185 loss = 0.0130\n",
      "epoch 24 batch 14/185 loss = 0.0098\n",
      "epoch 24 batch 15/185 loss = 0.0100\n",
      "epoch 24 batch 16/185 loss = 0.0085\n",
      "epoch 24 batch 17/185 loss = 0.0094\n",
      "epoch 24 batch 18/185 loss = 0.0095\n",
      "epoch 24 batch 19/185 loss = 0.0100\n",
      "epoch 24 batch 20/185 loss = 0.0101\n",
      "epoch 24 batch 21/185 loss = 0.0102\n",
      "epoch 24 batch 22/185 loss = 0.0105\n",
      "epoch 24 batch 23/185 loss = 0.0095\n",
      "epoch 24 batch 24/185 loss = 0.0132\n",
      "epoch 24 batch 25/185 loss = 0.0117\n",
      "epoch 24 batch 26/185 loss = 0.0129\n",
      "epoch 24 batch 27/185 loss = 0.0117\n",
      "epoch 24 batch 28/185 loss = 0.0111\n",
      "epoch 24 batch 29/185 loss = 0.0103\n",
      "epoch 24 batch 30/185 loss = 0.0103\n",
      "epoch 24 batch 31/185 loss = 0.0144\n",
      "epoch 24 batch 32/185 loss = 0.0108\n",
      "epoch 24 batch 33/185 loss = 0.0084\n",
      "epoch 24 batch 34/185 loss = 0.0101\n",
      "epoch 24 batch 35/185 loss = 0.0113\n",
      "epoch 24 batch 36/185 loss = 0.0083\n",
      "epoch 24 batch 37/185 loss = 0.0115\n",
      "epoch 24 batch 38/185 loss = 0.0117\n",
      "epoch 24 batch 39/185 loss = 0.0113\n",
      "epoch 24 batch 40/185 loss = 0.0098\n",
      "epoch 24 batch 41/185 loss = 0.0103\n",
      "epoch 24 batch 42/185 loss = 0.0105\n",
      "epoch 24 batch 43/185 loss = 0.0101\n",
      "epoch 24 batch 44/185 loss = 0.0111\n",
      "epoch 24 batch 45/185 loss = 0.0116\n",
      "epoch 24 batch 46/185 loss = 0.0111\n",
      "epoch 24 batch 47/185 loss = 0.0079\n",
      "epoch 24 batch 48/185 loss = 0.0106\n",
      "epoch 24 batch 49/185 loss = 0.0104\n",
      "epoch 24 batch 50/185 loss = 0.0103\n",
      "epoch 24 batch 51/185 loss = 0.0112\n",
      "epoch 24 batch 52/185 loss = 0.0130\n",
      "epoch 24 batch 53/185 loss = 0.0103\n",
      "epoch 24 batch 54/185 loss = 0.0117\n",
      "epoch 24 batch 55/185 loss = 0.0103\n",
      "epoch 24 batch 56/185 loss = 0.0096\n",
      "epoch 24 batch 57/185 loss = 0.0100\n",
      "epoch 24 batch 58/185 loss = 0.0104\n",
      "epoch 24 batch 59/185 loss = 0.0097\n",
      "epoch 24 batch 60/185 loss = 0.0084\n",
      "epoch 24 batch 61/185 loss = 0.0108\n",
      "epoch 24 batch 62/185 loss = 0.0080\n",
      "epoch 24 batch 63/185 loss = 0.0100\n",
      "epoch 24 batch 64/185 loss = 0.0107\n",
      "epoch 24 batch 65/185 loss = 0.0112\n",
      "epoch 24 batch 66/185 loss = 0.0094\n",
      "epoch 24 batch 67/185 loss = 0.0094\n",
      "epoch 24 batch 68/185 loss = 0.0090\n",
      "epoch 24 batch 69/185 loss = 0.0090\n",
      "epoch 24 batch 70/185 loss = 0.0096\n",
      "epoch 24 batch 71/185 loss = 0.0108\n",
      "epoch 24 batch 72/185 loss = 0.0092\n",
      "epoch 24 batch 73/185 loss = 0.0102\n",
      "epoch 24 batch 74/185 loss = 0.0085\n",
      "epoch 24 batch 75/185 loss = 0.0101\n",
      "epoch 24 batch 76/185 loss = 0.0115\n",
      "epoch 24 batch 77/185 loss = 0.0090\n",
      "epoch 24 batch 78/185 loss = 0.0111\n",
      "epoch 24 batch 79/185 loss = 0.0106\n",
      "epoch 24 batch 80/185 loss = 0.0096\n",
      "epoch 24 batch 81/185 loss = 0.0112\n",
      "epoch 24 batch 82/185 loss = 0.0120\n",
      "epoch 24 batch 83/185 loss = 0.0082\n",
      "epoch 24 batch 84/185 loss = 0.0095\n",
      "epoch 24 batch 85/185 loss = 0.0110\n",
      "epoch 24 batch 86/185 loss = 0.0095\n",
      "epoch 24 batch 87/185 loss = 0.0111\n",
      "epoch 24 batch 88/185 loss = 0.0102\n",
      "epoch 24 batch 89/185 loss = 0.0079\n",
      "epoch 24 batch 90/185 loss = 0.0089\n",
      "epoch 24 batch 91/185 loss = 0.0102\n",
      "epoch 24 batch 92/185 loss = 0.0109\n",
      "epoch 24 batch 93/185 loss = 0.0086\n",
      "epoch 24 batch 94/185 loss = 0.0103\n",
      "epoch 24 batch 95/185 loss = 0.0109\n",
      "epoch 24 batch 96/185 loss = 0.0089\n",
      "epoch 24 batch 97/185 loss = 0.0083\n",
      "epoch 24 batch 98/185 loss = 0.0096\n",
      "epoch 24 batch 99/185 loss = 0.0097\n",
      "epoch 24 batch 100/185 loss = 0.0099\n",
      "epoch 24 batch 101/185 loss = 0.0098\n",
      "epoch 24 batch 102/185 loss = 0.0108\n",
      "epoch 24 batch 103/185 loss = 0.0114\n",
      "epoch 24 batch 104/185 loss = 0.0110\n",
      "epoch 24 batch 105/185 loss = 0.0094\n",
      "epoch 24 batch 106/185 loss = 0.0112\n",
      "epoch 24 batch 107/185 loss = 0.0123\n",
      "epoch 24 batch 108/185 loss = 0.0094\n",
      "epoch 24 batch 109/185 loss = 0.0098\n",
      "epoch 24 batch 110/185 loss = 0.0104\n",
      "epoch 24 batch 111/185 loss = 0.0087\n",
      "epoch 24 batch 112/185 loss = 0.0132\n",
      "epoch 24 batch 113/185 loss = 0.0096\n",
      "epoch 24 batch 114/185 loss = 0.0093\n",
      "epoch 24 batch 115/185 loss = 0.0105\n",
      "epoch 24 batch 116/185 loss = 0.0095\n",
      "epoch 24 batch 117/185 loss = 0.0098\n",
      "epoch 24 batch 118/185 loss = 0.0104\n",
      "epoch 24 batch 119/185 loss = 0.0098\n",
      "epoch 24 batch 120/185 loss = 0.0118\n",
      "epoch 24 batch 121/185 loss = 0.0103\n",
      "epoch 24 batch 122/185 loss = 0.0096\n",
      "epoch 24 batch 123/185 loss = 0.0118\n",
      "epoch 24 batch 124/185 loss = 0.0107\n",
      "epoch 24 batch 125/185 loss = 0.0121\n",
      "epoch 24 batch 126/185 loss = 0.0102\n",
      "epoch 24 batch 127/185 loss = 0.0102\n",
      "epoch 24 batch 128/185 loss = 0.0106\n",
      "epoch 24 batch 129/185 loss = 0.0095\n",
      "epoch 24 batch 130/185 loss = 0.0128\n",
      "epoch 24 batch 131/185 loss = 0.0092\n",
      "epoch 24 batch 132/185 loss = 0.0107\n",
      "epoch 24 batch 133/185 loss = 0.0125\n",
      "epoch 24 batch 134/185 loss = 0.0099\n",
      "epoch 24 batch 135/185 loss = 0.0093\n",
      "epoch 24 batch 136/185 loss = 0.0103\n",
      "epoch 24 batch 137/185 loss = 0.0104\n",
      "epoch 24 batch 138/185 loss = 0.0112\n",
      "epoch 24 batch 139/185 loss = 0.0123\n",
      "epoch 24 batch 140/185 loss = 0.0146\n",
      "epoch 24 batch 141/185 loss = 0.0085\n",
      "epoch 24 batch 142/185 loss = 0.0097\n",
      "epoch 24 batch 143/185 loss = 0.0127\n",
      "epoch 24 batch 144/185 loss = 0.0130\n",
      "epoch 24 batch 145/185 loss = 0.0112\n",
      "epoch 24 batch 146/185 loss = 0.0097\n",
      "epoch 24 batch 147/185 loss = 0.0096\n",
      "epoch 24 batch 148/185 loss = 0.0093\n",
      "epoch 24 batch 149/185 loss = 0.0099\n",
      "epoch 24 batch 150/185 loss = 0.0085\n",
      "epoch 24 batch 151/185 loss = 0.0105\n",
      "epoch 24 batch 152/185 loss = 0.0107\n",
      "epoch 24 batch 153/185 loss = 0.0111\n",
      "epoch 24 batch 154/185 loss = 0.0106\n",
      "epoch 24 batch 155/185 loss = 0.0086\n",
      "epoch 24 batch 156/185 loss = 0.0116\n",
      "epoch 24 batch 157/185 loss = 0.0086\n",
      "epoch 24 batch 158/185 loss = 0.0098\n",
      "epoch 24 batch 159/185 loss = 0.0098\n",
      "epoch 24 batch 160/185 loss = 0.0095\n",
      "epoch 24 batch 161/185 loss = 0.0103\n",
      "epoch 24 batch 162/185 loss = 0.0120\n",
      "epoch 24 batch 163/185 loss = 0.0098\n",
      "epoch 24 batch 164/185 loss = 0.0105\n",
      "epoch 24 batch 165/185 loss = 0.0088\n",
      "epoch 24 batch 166/185 loss = 0.0087\n",
      "epoch 24 batch 167/185 loss = 0.0101\n",
      "epoch 24 batch 168/185 loss = 0.0113\n",
      "epoch 24 batch 169/185 loss = 0.0109\n",
      "epoch 24 batch 170/185 loss = 0.0081\n",
      "epoch 24 batch 171/185 loss = 0.0114\n",
      "epoch 24 batch 172/185 loss = 0.0101\n",
      "epoch 24 batch 173/185 loss = 0.0116\n",
      "epoch 24 batch 174/185 loss = 0.0109\n",
      "epoch 24 batch 175/185 loss = 0.0116\n",
      "epoch 24 batch 176/185 loss = 0.0119\n",
      "epoch 24 batch 177/185 loss = 0.0108\n",
      "epoch 24 batch 178/185 loss = 0.0114\n",
      "epoch 24 batch 179/185 loss = 0.0084\n",
      "epoch 24 batch 180/185 loss = 0.0110\n",
      "epoch 24 batch 181/185 loss = 0.0106\n",
      "epoch 24 batch 182/185 loss = 0.0089\n",
      "epoch 24 batch 183/185 loss = 0.0098\n",
      "epoch 24 batch 184/185 loss = 0.0101\n",
      "epoch 24 batch 185/185 loss = 0.0101\n",
      "epoch 24 train loss = 0.0104 valid loss = 0.0181\n",
      "performance reducing: counter 4\n",
      "epoch 25 batch 1/185 loss = 0.0119\n",
      "epoch 25 batch 2/185 loss = 0.0141\n",
      "epoch 25 batch 3/185 loss = 0.0107\n",
      "epoch 25 batch 4/185 loss = 0.0087\n",
      "epoch 25 batch 5/185 loss = 0.0085\n",
      "epoch 25 batch 6/185 loss = 0.0105\n",
      "epoch 25 batch 7/185 loss = 0.0116\n",
      "epoch 25 batch 8/185 loss = 0.0084\n",
      "epoch 25 batch 9/185 loss = 0.0090\n",
      "epoch 25 batch 10/185 loss = 0.0116\n",
      "epoch 25 batch 11/185 loss = 0.0100\n",
      "epoch 25 batch 12/185 loss = 0.0126\n",
      "epoch 25 batch 13/185 loss = 0.0121\n",
      "epoch 25 batch 14/185 loss = 0.0111\n",
      "epoch 25 batch 15/185 loss = 0.0124\n",
      "epoch 25 batch 16/185 loss = 0.0122\n",
      "epoch 25 batch 17/185 loss = 0.0083\n",
      "epoch 25 batch 18/185 loss = 0.0092\n",
      "epoch 25 batch 19/185 loss = 0.0096\n",
      "epoch 25 batch 20/185 loss = 0.0093\n",
      "epoch 25 batch 21/185 loss = 0.0086\n",
      "epoch 25 batch 22/185 loss = 0.0093\n",
      "epoch 25 batch 23/185 loss = 0.0125\n",
      "epoch 25 batch 24/185 loss = 0.0085\n",
      "epoch 25 batch 25/185 loss = 0.0108\n",
      "epoch 25 batch 26/185 loss = 0.0082\n",
      "epoch 25 batch 27/185 loss = 0.0111\n",
      "epoch 25 batch 28/185 loss = 0.0115\n",
      "epoch 25 batch 29/185 loss = 0.0095\n",
      "epoch 25 batch 30/185 loss = 0.0104\n",
      "epoch 25 batch 31/185 loss = 0.0105\n",
      "epoch 25 batch 32/185 loss = 0.0091\n",
      "epoch 25 batch 33/185 loss = 0.0099\n",
      "epoch 25 batch 34/185 loss = 0.0121\n",
      "epoch 25 batch 35/185 loss = 0.0120\n",
      "epoch 25 batch 36/185 loss = 0.0089\n",
      "epoch 25 batch 37/185 loss = 0.0120\n",
      "epoch 25 batch 38/185 loss = 0.0108\n",
      "epoch 25 batch 39/185 loss = 0.0095\n",
      "epoch 25 batch 40/185 loss = 0.0111\n",
      "epoch 25 batch 41/185 loss = 0.0104\n",
      "epoch 25 batch 42/185 loss = 0.0094\n",
      "epoch 25 batch 43/185 loss = 0.0103\n",
      "epoch 25 batch 44/185 loss = 0.0075\n",
      "epoch 25 batch 45/185 loss = 0.0108\n",
      "epoch 25 batch 46/185 loss = 0.0093\n",
      "epoch 25 batch 47/185 loss = 0.0100\n",
      "epoch 25 batch 48/185 loss = 0.0103\n",
      "epoch 25 batch 49/185 loss = 0.0105\n",
      "epoch 25 batch 50/185 loss = 0.0103\n",
      "epoch 25 batch 51/185 loss = 0.0107\n",
      "epoch 25 batch 52/185 loss = 0.0083\n",
      "epoch 25 batch 53/185 loss = 0.0126\n",
      "epoch 25 batch 54/185 loss = 0.0114\n",
      "epoch 25 batch 55/185 loss = 0.0119\n",
      "epoch 25 batch 56/185 loss = 0.0091\n",
      "epoch 25 batch 57/185 loss = 0.0110\n",
      "epoch 25 batch 58/185 loss = 0.0082\n",
      "epoch 25 batch 59/185 loss = 0.0095\n",
      "epoch 25 batch 60/185 loss = 0.0086\n",
      "epoch 25 batch 61/185 loss = 0.0108\n",
      "epoch 25 batch 62/185 loss = 0.0095\n",
      "epoch 25 batch 63/185 loss = 0.0092\n",
      "epoch 25 batch 64/185 loss = 0.0083\n",
      "epoch 25 batch 65/185 loss = 0.0095\n",
      "epoch 25 batch 66/185 loss = 0.0082\n",
      "epoch 25 batch 67/185 loss = 0.0083\n",
      "epoch 25 batch 68/185 loss = 0.0103\n",
      "epoch 25 batch 69/185 loss = 0.0085\n",
      "epoch 25 batch 70/185 loss = 0.0098\n",
      "epoch 25 batch 71/185 loss = 0.0107\n",
      "epoch 25 batch 72/185 loss = 0.0089\n",
      "epoch 25 batch 73/185 loss = 0.0111\n",
      "epoch 25 batch 74/185 loss = 0.0097\n",
      "epoch 25 batch 75/185 loss = 0.0105\n",
      "epoch 25 batch 76/185 loss = 0.0118\n",
      "epoch 25 batch 77/185 loss = 0.0097\n",
      "epoch 25 batch 78/185 loss = 0.0098\n",
      "epoch 25 batch 79/185 loss = 0.0098\n",
      "epoch 25 batch 80/185 loss = 0.0086\n",
      "epoch 25 batch 81/185 loss = 0.0111\n",
      "epoch 25 batch 82/185 loss = 0.0083\n",
      "epoch 25 batch 83/185 loss = 0.0100\n",
      "epoch 25 batch 84/185 loss = 0.0128\n",
      "epoch 25 batch 85/185 loss = 0.0093\n",
      "epoch 25 batch 86/185 loss = 0.0101\n",
      "epoch 25 batch 87/185 loss = 0.0088\n",
      "epoch 25 batch 88/185 loss = 0.0093\n",
      "epoch 25 batch 89/185 loss = 0.0097\n",
      "epoch 25 batch 90/185 loss = 0.0112\n",
      "epoch 25 batch 91/185 loss = 0.0116\n",
      "epoch 25 batch 92/185 loss = 0.0083\n",
      "epoch 25 batch 93/185 loss = 0.0110\n",
      "epoch 25 batch 94/185 loss = 0.0124\n",
      "epoch 25 batch 95/185 loss = 0.0086\n",
      "epoch 25 batch 96/185 loss = 0.0122\n",
      "epoch 25 batch 97/185 loss = 0.0108\n",
      "epoch 25 batch 98/185 loss = 0.0100\n",
      "epoch 25 batch 99/185 loss = 0.0087\n",
      "epoch 25 batch 100/185 loss = 0.0123\n",
      "epoch 25 batch 101/185 loss = 0.0099\n",
      "epoch 25 batch 102/185 loss = 0.0103\n",
      "epoch 25 batch 103/185 loss = 0.0122\n",
      "epoch 25 batch 104/185 loss = 0.0100\n",
      "epoch 25 batch 105/185 loss = 0.0144\n",
      "epoch 25 batch 106/185 loss = 0.0110\n",
      "epoch 25 batch 107/185 loss = 0.0127\n",
      "epoch 25 batch 108/185 loss = 0.0093\n",
      "epoch 25 batch 109/185 loss = 0.0090\n",
      "epoch 25 batch 110/185 loss = 0.0104\n",
      "epoch 25 batch 111/185 loss = 0.0093\n",
      "epoch 25 batch 112/185 loss = 0.0100\n",
      "epoch 25 batch 113/185 loss = 0.0095\n",
      "epoch 25 batch 114/185 loss = 0.0098\n",
      "epoch 25 batch 115/185 loss = 0.0082\n",
      "epoch 25 batch 116/185 loss = 0.0093\n",
      "epoch 25 batch 117/185 loss = 0.0116\n",
      "epoch 25 batch 118/185 loss = 0.0101\n",
      "epoch 25 batch 119/185 loss = 0.0084\n",
      "epoch 25 batch 120/185 loss = 0.0084\n",
      "epoch 25 batch 121/185 loss = 0.0100\n",
      "epoch 25 batch 122/185 loss = 0.0092\n",
      "epoch 25 batch 123/185 loss = 0.0117\n",
      "epoch 25 batch 124/185 loss = 0.0092\n",
      "epoch 25 batch 125/185 loss = 0.0109\n",
      "epoch 25 batch 126/185 loss = 0.0101\n",
      "epoch 25 batch 127/185 loss = 0.0118\n",
      "epoch 25 batch 128/185 loss = 0.0104\n",
      "epoch 25 batch 129/185 loss = 0.0124\n",
      "epoch 25 batch 130/185 loss = 0.0089\n",
      "epoch 25 batch 131/185 loss = 0.0096\n",
      "epoch 25 batch 132/185 loss = 0.0097\n",
      "epoch 25 batch 133/185 loss = 0.0105\n",
      "epoch 25 batch 134/185 loss = 0.0113\n",
      "epoch 25 batch 135/185 loss = 0.0108\n",
      "epoch 25 batch 136/185 loss = 0.0096\n",
      "epoch 25 batch 137/185 loss = 0.0097\n",
      "epoch 25 batch 138/185 loss = 0.0122\n",
      "epoch 25 batch 139/185 loss = 0.0091\n",
      "epoch 25 batch 140/185 loss = 0.0086\n",
      "epoch 25 batch 141/185 loss = 0.0079\n",
      "epoch 25 batch 142/185 loss = 0.0104\n",
      "epoch 25 batch 143/185 loss = 0.0105\n",
      "epoch 25 batch 144/185 loss = 0.0081\n",
      "epoch 25 batch 145/185 loss = 0.0093\n",
      "epoch 25 batch 146/185 loss = 0.0125\n",
      "epoch 25 batch 147/185 loss = 0.0095\n",
      "epoch 25 batch 148/185 loss = 0.0111\n",
      "epoch 25 batch 149/185 loss = 0.0098\n",
      "epoch 25 batch 150/185 loss = 0.0097\n",
      "epoch 25 batch 151/185 loss = 0.0117\n",
      "epoch 25 batch 152/185 loss = 0.0094\n",
      "epoch 25 batch 153/185 loss = 0.0104\n",
      "epoch 25 batch 154/185 loss = 0.0105\n",
      "epoch 25 batch 155/185 loss = 0.0110\n",
      "epoch 25 batch 156/185 loss = 0.0131\n",
      "epoch 25 batch 157/185 loss = 0.0114\n",
      "epoch 25 batch 158/185 loss = 0.0095\n",
      "epoch 25 batch 159/185 loss = 0.0100\n",
      "epoch 25 batch 160/185 loss = 0.0096\n",
      "epoch 25 batch 161/185 loss = 0.0086\n",
      "epoch 25 batch 162/185 loss = 0.0105\n",
      "epoch 25 batch 163/185 loss = 0.0099\n",
      "epoch 25 batch 164/185 loss = 0.0108\n",
      "epoch 25 batch 165/185 loss = 0.0107\n",
      "epoch 25 batch 166/185 loss = 0.0111\n",
      "epoch 25 batch 167/185 loss = 0.0110\n",
      "epoch 25 batch 168/185 loss = 0.0096\n",
      "epoch 25 batch 169/185 loss = 0.0098\n",
      "epoch 25 batch 170/185 loss = 0.0108\n",
      "epoch 25 batch 171/185 loss = 0.0106\n",
      "epoch 25 batch 172/185 loss = 0.0118\n",
      "epoch 25 batch 173/185 loss = 0.0101\n",
      "epoch 25 batch 174/185 loss = 0.0094\n",
      "epoch 25 batch 175/185 loss = 0.0094\n",
      "epoch 25 batch 176/185 loss = 0.0103\n",
      "epoch 25 batch 177/185 loss = 0.0099\n",
      "epoch 25 batch 178/185 loss = 0.0101\n",
      "epoch 25 batch 179/185 loss = 0.0095\n",
      "epoch 25 batch 180/185 loss = 0.0094\n",
      "epoch 25 batch 181/185 loss = 0.0130\n",
      "epoch 25 batch 182/185 loss = 0.0103\n",
      "epoch 25 batch 183/185 loss = 0.0091\n",
      "epoch 25 batch 184/185 loss = 0.0128\n",
      "epoch 25 batch 185/185 loss = 0.0119\n",
      "epoch 25 train loss = 0.0102 valid loss = 0.0197\n",
      "performance reducing: counter 5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    current_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    train_image_path = glob('../input/cityscapes-image-pairs/cityscapes_data/train/*')\n",
    "    valid_image_path = glob('../input/cityscapes-image-pairs/cityscapes_data/val/*')\n",
    "\n",
    "    image_transforms = transforms.Compose([\n",
    "#         transforms.ToPILImage(mode='RGB'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256),\n",
    "#         transforms.PILToTensor(),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.GaussianBlur((5,), (5, 15)),\n",
    "#         transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "    target_transforms = transforms.Compose([\n",
    "#         transforms.ToPILImage(mode='RGB'),\n",
    "#         transforms.Grayscale(),\n",
    "#         transforms.PILToTensor(),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "    valid_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.Normalize((0.5,), (0.5,)),\n",
    "#         transforms.ToPILImage(mode='RGB'),\n",
    "        transforms.Resize(256),\n",
    "#         transforms.PILToTensor(),\n",
    "#         transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "\n",
    "    train_cityscapes = Cityscapes(train_image_path, image_transforms, target_transforms)\n",
    "    valid_cityscapes = Cityscapes(valid_image_path, valid_transforms, target_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_cityscapes, batch_size=16, shuffle=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_cityscapes, batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "    unet = UNet().to(current_device)\n",
    "    ce_loss = nn.MSELoss().to(current_device)\n",
    "    optimizer_adam = optim.Adam(unet.parameters(), lr=0.001)\n",
    "    continue_train = False\n",
    "    if continue_train:\n",
    "        trained_model_params = torch.load('../input/cityscapes-unet/unet-last.pth')\n",
    "        unet.load_state_dict(trained_model_params['model_state_dict'])\n",
    "        optimizer_adam.load_state_dict(trained_model_params['optimizer_state_dict'])\n",
    "    train(train_loader, valid_loader, unet, optimizer_adam, ce_loss, epoch=25, device=current_device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3778.431916,
   "end_time": "2022-06-17T02:02:22.084763",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-17T00:59:23.652847",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
